{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-13T06:11:31.151328Z",
     "start_time": "2025-05-13T06:11:28.968094Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error # For evaluation\n",
    "\n",
    "# torch-pruning\n",
    "import torch_pruning as tp\n",
    "\n",
    "# Type Hinting (Optional but good practice)\n",
    "from typing import Tuple, List, Dict, Union, Optional"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " ### Data Loading and Preprocessing Functions (Using your provided code)",
   "id": "bae069a69d096056"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T06:11:31.177400Z",
     "start_time": "2025-05-13T06:11:31.166867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Functions from your provided code ---\n",
    "\n",
    "column_names = ['unit_number', 'time_in_cycles'] + [f'op_setting_{i}' for i in range(1, 4)] + [f'sensor_{i}' for i in range(1, 24)]\n",
    "\n",
    "def load_dataframe(file_path: str) -> pd.DataFrame | None:\n",
    "    \"\"\"Loads a single CMaps data file.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep=' ', header=None, names=column_names)\n",
    "        # Drop the last two columns if they are all NaNs (often artifacts of space delimiter)\n",
    "        df.dropna(axis=1, how='all', inplace=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def clean_data(df: pd.DataFrame) -> list:\n",
    "    \"\"\"Identifies columns to remove based on low std dev.\"\"\"\n",
    "    if df is None:\n",
    "        return []\n",
    "    # Columns with std dev < 0.02 (potential candidates for removal)\n",
    "    # Avoid removing unit_number or time_in_cycles here.\n",
    "    cols_to_check = [col for col in df.columns if 'sensor' in col or 'op_setting' in col]\n",
    "    low_std_cols = [col for col in cols_to_check if df[col].std() < 0.02]\n",
    "    print(f\"Columns with std < 0.02 (potential removal): {low_std_cols}\")\n",
    "    # You might decide which ones to actually remove based on domain knowledge or experiment\n",
    "    # For this example, let's remove them as identified.\n",
    "    return low_std_cols\n",
    "\n",
    "def add_rul(df: pd.DataFrame) -> pd.DataFrame | None:\n",
    "    \"\"\"Calculates and adds the Remaining Useful Life (RUL) column.\"\"\"\n",
    "    if df is None:\n",
    "        return None\n",
    "    max_cycles = df.groupby('unit_number')['time_in_cycles'].max().reset_index()\n",
    "    max_cycles.columns = ['unit_number', 'max_cycle']\n",
    "    df = df.merge(max_cycles, on='unit_number', how='left')\n",
    "    df['RUL'] = df['max_cycle'] - df['time_in_cycles']\n",
    "    df.drop(columns=['max_cycle'], inplace=True)\n",
    "    # Clip RUL (optional, common practice to limit max RUL)\n",
    "    df['RUL'] = df['RUL'].clip(upper=125)\n",
    "    return df\n",
    "\n",
    "def normalize_data(df: pd.DataFrame,\n",
    "                   columns_to_normalize: List[str], scaler: MinMaxScaler = None) -> Tuple[pd.DataFrame, MinMaxScaler] | Tuple[None, None]:\n",
    "    \"\"\"Normalizes specified columns using MinMaxScaler.\"\"\"\n",
    "    if df is None:\n",
    "        return None, None\n",
    "    data_to_scale = df[columns_to_normalize]\n",
    "    if scaler is None:\n",
    "        scaler = MinMaxScaler()\n",
    "        df[columns_to_normalize] = scaler.fit_transform(data_to_scale)\n",
    "    else:\n",
    "        # Ensure only columns present in the scaler are transformed\n",
    "        valid_cols = [col for col in columns_to_normalize if col in scaler.feature_names_in_]\n",
    "        if len(valid_cols) < len(columns_to_normalize):\n",
    "            print(\"Warning: Some columns not found in the provided scaler. Skipping them.\")\n",
    "        if valid_cols: # Check if there's anything to transform\n",
    "             df[valid_cols] = scaler.transform(df[valid_cols])\n",
    "\n",
    "    return df, scaler\n",
    "\n",
    "# --- Data Preparation Main Function ---\n",
    "def prepare_cmapss_data(data_dir: str, train_file: str, test_file: str, test_rul_file: str) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, MinMaxScaler, List[str]]:\n",
    "    \"\"\"Loads, cleans, preprocesses train/test data and RUL.\"\"\"\n",
    "    print(\"--- Preparing Training Data ---\")\n",
    "    train_df = load_dataframe(os.path.join(data_dir, train_file))\n",
    "    train_df = add_rul(train_df)\n",
    "\n",
    "    print(\"\\n--- Preparing Test Data ---\")\n",
    "    test_df = load_dataframe(os.path.join(data_dir, test_file))\n",
    "    test_rul_df = pd.read_csv(os.path.join(data_dir, test_rul_file), header=None, names=['RUL'])\n",
    "    # Adjust RUL based on test_rul_df and clipping if needed\n",
    "    # Test RUL is usually the RUL at the *end* of the test sequence\n",
    "    # We'll use this test_rul_df directly later for evaluation targets\n",
    "\n",
    "    # Clean Data - identify columns based on TRAINING data variance\n",
    "    cols_to_remove = clean_data(train_df)\n",
    "    feature_cols = [col for col in train_df.columns if col not in ['unit_number', 'time_in_cycles', 'RUL'] + cols_to_remove]\n",
    "    print(f\"\\nUsing Features: {feature_cols}\")\n",
    "\n",
    "    # Drop removed columns from both train and test\n",
    "    train_df.drop(columns=cols_to_remove, inplace=True, errors='ignore')\n",
    "    test_df.drop(columns=cols_to_remove, inplace=True, errors='ignore')\n",
    "\n",
    "\n",
    "    # Normalize features based on TRAINING data\n",
    "    print(\"\\n--- Normalizing Data ---\")\n",
    "    train_df_norm, scaler = normalize_data(train_df.copy(), feature_cols, scaler=None)\n",
    "    # Use the same scaler for test data\n",
    "    test_df_norm, _ = normalize_data(test_df.copy(), feature_cols, scaler=scaler)\n",
    "\n",
    "    return train_df_norm, test_df_norm, test_rul_df, scaler, feature_cols"
   ],
   "id": "8ed4af0ac9ecc063",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define MLP Model and Dataset Class\n",
   "id": "b27a03f0f1d02e51"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T06:11:33.932205Z",
     "start_time": "2025-05-13T06:11:33.922123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- MLP Model Definition (Using your provided class) ---\n",
    "class MLPmodel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 layer_units: List[int],    # List of neuron counts for hidden layers, e.g., [512, 256, 128]\n",
    "                 input_size: int,           # Number of input features\n",
    "                 output_size: int = 1,      # Number of output units (1 for RUL regression)\n",
    "                 dropout_rate: float = 0.2,\n",
    "                 use_batchnorm: bool = False, # Flag to enable/disable BatchNorm\n",
    "                 final_activation: Optional[nn.Module] = None # Optional: for tasks needing a final activation\n",
    "                ):\n",
    "        super(MLPmodel, self).__init__()\n",
    "        self.model_type = 'MLP'\n",
    "        self.layer_units = layer_units # Store for potential reference\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "        self.final_activation = final_activation\n",
    "\n",
    "        layers = []\n",
    "        current_dim = input_size\n",
    "\n",
    "        # Create hidden layers\n",
    "        for hidden_units in layer_units:\n",
    "            layers.append(nn.Linear(current_dim, hidden_units))\n",
    "            if use_batchnorm:\n",
    "                layers.append(nn.BatchNorm1d(hidden_units)) # BatchNorm applied to the output of Linear\n",
    "            layers.append(nn.ReLU()) # Activation function\n",
    "            layers.append(nn.Dropout(dropout_rate)) # Dropout for regularization\n",
    "            current_dim = hidden_units # Update current_dim for the next layer\n",
    "\n",
    "        # Create the output layer\n",
    "        layers.append(nn.Linear(current_dim, output_size))\n",
    "\n",
    "        # Add final activation if specified (e.g., Sigmoid for binary classification)\n",
    "        if self.final_activation is not None:\n",
    "            layers.append(self.final_activation)\n",
    "\n",
    "        # Combine all layers into a sequential module\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        \"\"\"Initializes weights for linear layers.\"\"\"\n",
    "        for module in self.network.modules(): # Iterate through all modules in self.network\n",
    "            if isinstance(module, nn.Linear):\n",
    "                # Kaiming uniform is often good for layers followed by ReLU\n",
    "                nn.init.kaiming_uniform_(module.weight, nonlinearity='relu')\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, 0)\n",
    "            elif isinstance(module, nn.BatchNorm1d):\n",
    "                # Default initialization for BatchNorm1d is usually fine (mean 0, var 1 for weights, 0 for bias)\n",
    "                nn.init.constant_(module.weight, 1)\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the MLP.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, input_size).\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor, shape depends on output_size and final_activation.\n",
    "                          For RUL regression, usually (batch_size, 1).\n",
    "        \"\"\"\n",
    "        # Input x shape should be [batch_size, input_features]\n",
    "        return self.network(x)\n",
    "\n",
    "    def get_prunable_layers(self) -> List[nn.Linear]:\n",
    "        \"\"\"Helper to get a list of linear layers, excluding the final output layer for pruning.\"\"\"\n",
    "        prunable = []\n",
    "        # Iterate through direct children of self.network, which are the layers we added\n",
    "        for i, layer in enumerate(self.network):\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                # Check if it's the last Linear layer in the sequence\n",
    "                is_last_linear = True\n",
    "                for subsequent_layer in list(self.network)[i+1:]: # Look ahead\n",
    "                    if isinstance(subsequent_layer, nn.Linear):\n",
    "                        is_last_linear = False\n",
    "                        break\n",
    "                if not is_last_linear:\n",
    "                    prunable.append(layer)\n",
    "        return prunable\n",
    "\n",
    "    def get_output_layer(self) -> Optional[nn.Linear]:\n",
    "        \"\"\"Helper to get the final output linear layer, which should typically be ignored during pruning.\"\"\"\n",
    "        # Iterate backwards to find the last nn.Linear layer in self.network\n",
    "        for layer in reversed(list(self.network.children())):\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                return layer\n",
    "        return None\n",
    "\n",
    "# --- PyTorch Dataset for CMaps MLP ---\n",
    "class CMAPSS_MLP_Dataset(Dataset):\n",
    "    def __init__(self, features: np.ndarray, targets: np.ndarray):\n",
    "        if features.ndim == 3: # Handle potential sequence input by flattening or taking last step\n",
    "             print(\"Warning: Input features seem sequential. Taking last step for MLP.\")\n",
    "             # This assumes LSTM-prepared data; better to prepare MLP data correctly upstream\n",
    "             features = features[:, -1, :]\n",
    "        if targets.ndim > 1 and targets.shape[1] > 1:\n",
    "             print(\"Warning: Targets have more than one dimension. Squeezing.\")\n",
    "             targets = targets.squeeze()\n",
    "\n",
    "\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(targets, dtype=torch.float32).unsqueeze(1) # Ensure target shape is [N, 1]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        return self.features[idx], self.targets[idx]"
   ],
   "id": "1d72abf80e56967d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training and Evaluation Functions (Adapted for Regression)",
   "id": "3dac04ff7e938de9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T06:11:37.320930Z",
     "start_time": "2025-05-13T06:11:37.304207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Utility Functions ---\n",
    "def save_model_as_onnx(model: nn.Module, example_input: torch.Tensor, output_path: str, device: torch.device):\n",
    "    \"\"\"Exports a PyTorch model to ONNX format.\"\"\"\n",
    "    model.eval() # Ensure model is in evaluation mode\n",
    "    model.to(device) # Ensure model is on the correct device\n",
    "    example_input_on_device = example_input.to(device) # Ensure example input is on the device\n",
    "\n",
    "    try:\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            example_input_on_device,\n",
    "            output_path,\n",
    "            export_params=True,\n",
    "            opset_version=11, # Common opset, can be 12, 13, etc.\n",
    "            input_names=['input'],\n",
    "            output_names=['output'],\n",
    "            dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    "        )\n",
    "        print(f\"âœ… Model successfully saved as ONNX to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Loglevel: Error - Failed to export model to ONNX at {output_path}: {e}\")\n",
    "        print(\" Loglevel: Error - Please check model compatibility with ONNX opset version or input/output names.\")\n",
    "\n",
    "\n",
    "def save_model_state(model: nn.Module, path_prefix: str, example_input_for_onnx: Optional[torch.Tensor] = None, device_for_onnx: Optional[torch.device] = None):\n",
    "    \"\"\"Saves model state dictionary (.pth) and optionally its ONNX version.\"\"\"\n",
    "    # Ensure path_prefix ends with .pth for the PyTorch state_dict\n",
    "    if not path_prefix.endswith(\".pth\"):\n",
    "        pth_path = path_prefix + \".pth\"\n",
    "    else:\n",
    "        pth_path = path_prefix # Assume full .pth path given\n",
    "        path_prefix = path_prefix[:-4] # Remove .pth for ONNX naming\n",
    "\n",
    "    os.makedirs(os.path.dirname(pth_path), exist_ok=True)\n",
    "    torch.save(model.state_dict(), pth_path)\n",
    "    print(f\"Model state (.pth) saved to {pth_path}\")\n",
    "\n",
    "    if example_input_for_onnx is not None and device_for_onnx is not None:\n",
    "        onnx_path = path_prefix + \".onnx\" # Use the prefix before .pth was added\n",
    "        print(f\"Attempting to save ONNX model to: {onnx_path}\")\n",
    "        save_model_as_onnx(model, example_input_for_onnx, onnx_path, device_for_onnx)\n",
    "\n",
    "def load_model_state(model, path, device):\n",
    "    \"\"\"Loads model state dictionary.\"\"\"\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    print(f\"Model state loaded from {path}\")\n",
    "    return model\n",
    "\n",
    "def calculate_flops_params(model, example_input): # Assuming this is defined elsewhere or here\n",
    "    # Ensure model and example_input are on the same device for count_ops_and_params\n",
    "    device = next(model.parameters()).device\n",
    "    example_input_on_device = example_input.to(device)\n",
    "    return tp.utils.count_ops_and_params(model, example_input_on_device)\n",
    "\n",
    "# --- Evaluation Function (RMSE) ---\n",
    "def evaluate_model_rmse(model: nn.Module, data_loader: DataLoader, device: torch.device, example_input: torch.Tensor) -> Dict[str, float]:\n",
    "    \"\"\"Evaluates the regression model using RMSE and calculates FLOPs/Params.\"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for features, targets in data_loader:\n",
    "            features = features.to(device)\n",
    "            predictions = model(features)\n",
    "            all_predictions.append(predictions.cpu().numpy())\n",
    "            all_targets.append(targets.numpy()) # Targets are already [N, 1]\n",
    "\n",
    "    # Concatenate results from all batches\n",
    "    all_predictions = np.concatenate(all_predictions).squeeze()\n",
    "    all_targets = np.concatenate(all_targets).squeeze()\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(all_targets, all_predictions))\n",
    "    print(f\"Evaluation RMSE: {rmse:.4f}\")\n",
    "\n",
    "    # Calculate FLOPs and Params\n",
    "    flops, params = calculate_flops_params(model, example_input.to(device))\n",
    "    size_mb = params * 4 / 1e6 # Approximation\n",
    "\n",
    "    return {\n",
    "        'rmse': rmse,\n",
    "        'flops': flops,\n",
    "        'params': params,\n",
    "        'size_mb': size_mb\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def train_mlp_model(\n",
    "        model: nn.Module,\n",
    "        train_loader: DataLoader,\n",
    "        val_loader: DataLoader,\n",
    "        criterion: nn.Module,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        scheduler: Optional[torch.optim.lr_scheduler._LRScheduler],\n",
    "        device: torch.device,\n",
    "        num_epochs: int,\n",
    "        patience: int = 10,\n",
    "        model_save_path: str = \"temp_best_model.pth\"\n",
    "                    ) -> Tuple[nn.Module, List[float], List[float], List[float]]: # Return history\n",
    "    \"\"\"Trains an MLP model with validation, early stopping.\n",
    "       Returns: best model, train_loss_history, val_loss_history, val_rmse_history (if calculable)\n",
    "    \"\"\"\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    # val_rmse_history = [] # We'll calculate RMSE outside based on final model on test set for simplicity in main loop\n",
    "\n",
    "    print(f\"Starting training on {device} with patience={patience}\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss_train = 0.0\n",
    "        for features, targets in train_loader:\n",
    "            features, targets = features.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss_train += loss.item() * features.size(0)\n",
    "\n",
    "        epoch_train_loss = running_loss_train / len(train_loader.dataset)\n",
    "        train_loss_history.append(epoch_train_loss)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_loss_val = 0.0\n",
    "        all_val_preds = []\n",
    "        all_val_targets = []\n",
    "        with torch.no_grad():\n",
    "            for features, targets in val_loader:\n",
    "                features, targets = features.to(device), targets.to(device)\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, targets)\n",
    "                running_loss_val += loss.item() * features.size(0)\n",
    "                all_val_preds.append(outputs.cpu().numpy())\n",
    "                all_val_targets.append(targets.cpu().numpy())\n",
    "\n",
    "\n",
    "        epoch_val_loss = running_loss_val / len(val_loader.dataset)\n",
    "        val_loss_history.append(epoch_val_loss)\n",
    "\n",
    "        # Optional: Calculate validation RMSE per epoch if needed for detailed plotting\n",
    "        # current_val_preds = np.concatenate(all_val_preds).squeeze()\n",
    "        # current_val_targets = np.concatenate(all_val_targets).squeeze()\n",
    "        # epoch_val_rmse = np.sqrt(mean_squared_error(current_val_targets, current_val_preds))\n",
    "        # val_rmse_history.append(epoch_val_rmse)\n",
    "\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss={epoch_train_loss:.4f}, Val Loss={epoch_val_loss:.4f}, LR={current_lr:.1e}\")\n",
    "        # print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss={epoch_train_loss:.4f}, Val Loss={epoch_val_loss:.4f}, Val RMSE={epoch_val_rmse:.4f} LR={current_lr:.1e}\")\n",
    "\n",
    "\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            print(f\"*** New best validation loss: {best_val_loss:.4f} (Epoch {epoch+1}) ***\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            # print(f\"Val loss did not improve for {epochs_no_improve} epoch(s).\") # Can be verbose\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {patience} epochs without improvement on Val Loss.\")\n",
    "            break\n",
    "\n",
    "        if scheduler:\n",
    "            if isinstance(scheduler, ReduceLROnPlateau):\n",
    "                scheduler.step(epoch_val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "\n",
    "    print(f\"Training finished. Best validation loss: {best_val_loss:.4f}\")\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(\"Loaded best model state based on validation loss.\")\n",
    "    else:\n",
    "         print(\"Warning: No improvement in validation loss. Using model from last epoch.\")\n",
    "\n",
    "    return model, train_loss_history, val_loss_history #, val_rmse_history"
   ],
   "id": "f78b71cc98b01c9b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Pruning Function (Adapted for MLP)",
   "id": "d6a95d0fae741f9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T06:11:41.925100Z",
     "start_time": "2025-05-13T06:11:41.914147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prune_mlp_model(model_to_prune: nn.Module, example_input: torch.Tensor, strategy_name_for_debug:str, strategy: Dict, # Added strategy_name_for_debug\n",
    "                    target_sparsity: float = 0.5, iterative_steps: int = 1,\n",
    "                    importance: Optional[tp.importance.Importance] = None) -> nn.Module:\n",
    "    \"\"\"Prunes an MLP model using the specified strategy (Revised with more prints).\"\"\"\n",
    "    device = example_input.device\n",
    "    model_to_prune.eval().to(device)\n",
    "\n",
    "    print(f\"\\n--- Model Structure BEFORE Pruning ({strategy_name_for_debug}) ---\")\n",
    "    print(model_to_prune)\n",
    "    flops_before, params_before = calculate_flops_params(model_to_prune, example_input)\n",
    "    print(f\"State Before Pruning ({strategy_name_for_debug}): FLOPs={flops_before/1e6:.4f}M, Params={params_before/1e6:.4f}M\")\n",
    "\n",
    "\n",
    "    ignored_layers = []\n",
    "    if hasattr(model_to_prune, 'get_output_layer') and callable(model_to_prune.get_output_layer):\n",
    "        output_layer_instance = model_to_prune.get_output_layer()\n",
    "        if output_layer_instance:\n",
    "            ignored_layers.append(output_layer_instance)\n",
    "            print(f\"Ignoring output layer ({output_layer_instance}) during pruning for {strategy_name_for_debug}.\")\n",
    "    elif hasattr(model_to_prune, 'layers') and isinstance(model_to_prune.layers, nn.ModuleList) and len(model_to_prune.layers) > 0: # Fallback for older MLP structure\n",
    "        output_layer_candidate = model_to_prune.layers[-1]\n",
    "        if isinstance(output_layer_candidate, nn.Linear):\n",
    "             ignored_layers.append(output_layer_candidate)\n",
    "             print(f\"Ignoring output layer ({output_layer_candidate}) using direct access for {strategy_name_for_debug}.\")\n",
    "    else:\n",
    "        print(f\"Warning ({strategy_name_for_debug}): Could not automatically determine output layer. Check model structure.\")\n",
    "\n",
    "\n",
    "    if importance is None:\n",
    "        importance_metric = strategy['importance']\n",
    "    else:\n",
    "        importance_metric = importance\n",
    "    print(f\"Using Importance Metric ({strategy_name_for_debug}): {type(importance_metric).__name__}\")\n",
    "\n",
    "    pruner_class = strategy['pruner']\n",
    "    print(f\"Using Pruner Class ({strategy_name_for_debug}): {pruner_class.__name__}\")\n",
    "\n",
    "    try:\n",
    "        pruner = pruner_class(\n",
    "            model=model_to_prune,\n",
    "            example_inputs=example_input.to(device),\n",
    "            importance=importance_metric,\n",
    "            iterative_steps=iterative_steps,\n",
    "            ch_sparsity=target_sparsity,\n",
    "            root_module_types=[nn.Linear],\n",
    "            ignored_layers=ignored_layers,\n",
    "        )\n",
    "    except TypeError as e:\n",
    "        print(f\"Warning ({strategy_name_for_debug}): Error initializing pruner {pruner_class.__name__} with standard args: {e}\")\n",
    "        print(\"Attempting initialization with fewer args...\")\n",
    "        try:\n",
    "            pruner = pruner_class(\n",
    "                model=model_to_prune,\n",
    "                example_inputs=example_input.to(device),\n",
    "                importance=importance_metric,\n",
    "                ch_sparsity=target_sparsity,\n",
    "                ignored_layers=ignored_layers,\n",
    "             )\n",
    "        except Exception as E:\n",
    "             print(f\"ERROR ({strategy_name_for_debug}): Could not initialize pruner {pruner_class.__name__}\")\n",
    "             raise E\n",
    "\n",
    "\n",
    "    print(f\"Starting pruning with {strategy_name_for_debug}, Target Sparsity: {target_sparsity:.2f}\")\n",
    "\n",
    "    if isinstance(importance_metric, tp.importance.TaylorImportance):\n",
    "        model_to_prune.train()\n",
    "        input_on_device = example_input.to(device)\n",
    "        output = model_to_prune(input_on_device)\n",
    "        loss = torch.sum(output**2)\n",
    "        model_to_prune.zero_grad()\n",
    "        try:\n",
    "            loss.backward()\n",
    "            print(f\"Calculated gradients for TaylorImportance ({strategy_name_for_debug}).\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR ({strategy_name_for_debug}): Could not perform backward pass for TaylorImportance: {e}\")\n",
    "            raise e\n",
    "        finally:\n",
    "             model_to_prune.eval()\n",
    "\n",
    "\n",
    "    # --- BEGIN DEBUGGING PRUNING GROUPS (Optional) ---\n",
    "    # if \"magnitude\" in strategy_name_for_debug: # Or any strategy you want to debug\n",
    "    #     print(f\"--- Inspecting Pruning Groups for {strategy_name_for_debug} (Interactive Mode) ---\")\n",
    "    #     # Create a temporary pruner instance for inspection only to avoid altering the main one\n",
    "    #     temp_pruner_for_inspection = pruner_class(\n",
    "    #         model=model_to_prune, example_inputs=example_input.to(device),\n",
    "    #         importance=importance_metric, ch_sparsity=target_sparsity,\n",
    "    #         root_module_types=[nn.Linear], ignored_layers=ignored_layers,\n",
    "    #     )\n",
    "    #     # This call is just to get the groups, not to prune with this temp_pruner\n",
    "    #     num_groups_found = 0\n",
    "    #     # DG should be created upon pruner instantiation if using torch_pruning>=1.2\n",
    "    #     if hasattr(temp_pruner_for_inspection, 'DG'):\n",
    "    #         example_group = temp_pruner_for_inspection.DG.get_pruning_group(model_to_prune.layers[0], tp.pruning.pruning_dim.pruning_out_channels, 0) # Example\n",
    "    #         print(f\"Example Group from DG: {example_group}\")\n",
    "\n",
    "    #     # Iterate through what the pruner would do if it were interactive\n",
    "    #     # Note: pruner.step(interactive=True) might need to be called to generate groups for some pruners\n",
    "    #     # This part of debugging might be tricky without a deeper dive into a specific pruner\n",
    "    #     print(f\"--- End of Group Inspection for {strategy_name_for_debug} ---\")\n",
    "    # --- END DEBUGGING PRUNING GROUPS ---\n",
    "\n",
    "    try:\n",
    "        pruner.step()\n",
    "    except AttributeError as e:\n",
    "         print(f\"ERROR ({strategy_name_for_debug}): During pruner.step() for {pruner_class.__name__}: {e}\")\n",
    "         raise e\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR ({strategy_name_for_debug}): An unexpected error during pruner.step() for {pruner_class.__name__}: {e}\")\n",
    "        raise e\n",
    "\n",
    "    print(f\"\\n--- Model Structure AFTER Pruning ({strategy_name_for_debug}) ---\")\n",
    "    print(model_to_prune)\n",
    "    flops_after, params_after = calculate_flops_params(model_to_prune, example_input.to(device))\n",
    "    print(f\"Pruning finished for {strategy_name_for_debug}. Final FLOPs: {flops_after/1e6:.4f}M, Params: {params_after/1e6:.4f}M\")\n",
    "    if flops_before > 0: print(f\"FLOPs Reduction ({strategy_name_for_debug}): {(flops_before-flops_after)/flops_before*100:.2f}%\")\n",
    "    if params_before > 0: print(f\"Params Reduction ({strategy_name_for_debug}): {(params_before-params_after)/params_before*100:.2f}%\")\n",
    "\n",
    "    print(f\"\\n--- Named Parameters AFTER Pruning ({strategy_name_for_debug}) ---\")\n",
    "    for name, param in model_to_prune.named_parameters():\n",
    "        print(f\"{name}: shape={param.shape}, num_elements={param.numel()}, requires_grad={param.requires_grad}\")\n",
    "\n",
    "\n",
    "    num_params_fixed = 0\n",
    "    for name, param in model_to_prune.named_parameters():\n",
    "        if not param.requires_grad:\n",
    "            param.requires_grad = True\n",
    "            num_params_fixed += 1\n",
    "    if num_params_fixed > 0:\n",
    "        print(f\"Set requires_grad=True for {num_params_fixed} parameters ({strategy_name_for_debug}).\")\n",
    "\n",
    "    return model_to_prune"
   ],
   "id": "70f8b1a324b7fa4f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###  Comparison and Plotting (Adapted for Regression)",
   "id": "713571cff53fda73"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T06:11:47.808769Z",
     "start_time": "2025-05-13T06:11:47.798509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os # Ensure imported\n",
    "from typing import Dict # Ensure imported\n",
    "\n",
    "def compare_results_and_plot_rmse(results: Dict[str, Dict[str, float]], output_dir: str):\n",
    "    \"\"\"Prints comparison table and plots results for regression (RMSE).\"\"\"\n",
    "\n",
    "    print(\"\\n=== Pruning Strategy Comparison (RMSE) ===\")\n",
    "    print(f\"{'Strategy':<12} | {'FLOPs':<12} | {'Params':<10} | {'Size (MB)':<10} | {'RMSE':<10}\")\n",
    "    print(\"-\" * 65)\n",
    "    # Sort strategies by RMSE (lower is better) for better comparison\n",
    "    sorted_strategies = sorted(results.keys(), key=lambda s: results[s].get('rmse', float('inf')))\n",
    "\n",
    "    for strategy in sorted_strategies:\n",
    "        metrics = results[strategy]\n",
    "        # Use .get() with defaults for robustness if a metric is missing\n",
    "        flops_m = metrics.get('flops', 0) / 1e6\n",
    "        params_m = metrics.get('params', 0) / 1e6\n",
    "        size_mb_val = metrics.get('size_mb', 0)\n",
    "        rmse_val = metrics.get('rmse', float('nan'))\n",
    "        print(f\"{strategy:<12} | {flops_m:<11.2f}M | {params_m:<9.2f}M | {size_mb_val:>9.2f} | {rmse_val:<10.4f}\")\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # Ensure 'initial' is first if it exists for plotting reference\n",
    "    plot_strategies = ['initial'] + [s for s in sorted_strategies if s != 'initial']\n",
    "    metrics_to_plot = ['flops', 'params', 'size_mb', 'rmse']\n",
    "    titles = {'flops': 'FLOPs Comparison', 'params': 'Parameters Comparison',\n",
    "              'size_mb': 'Model Size (MB) Comparison', 'rmse': 'RMSE Comparison (Lower is Better)'}\n",
    "    y_labels = {'flops': 'FLOPs (Millions)', 'params': 'Parameters (Millions)',\n",
    "                'size_mb': 'Size (MB)', 'rmse': 'RMSE'}\n",
    "\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(plot_strategies)))\n",
    "\n",
    "    for metric_name in metrics_to_plot:\n",
    "        if not any(metric_name in results.get(s, {}) for s in plot_strategies):\n",
    "             print(f\"Skipping plot for '{metric_name}', data not found in results.\")\n",
    "             continue\n",
    "\n",
    "        values = []\n",
    "        for strategy in plot_strategies:\n",
    "             metric_val = results.get(strategy, {}).get(metric_name, np.nan)\n",
    "             if metric_name in ['flops', 'params']:\n",
    "                 if not np.isnan(metric_val): # Avoid division by zero or on NaN\n",
    "                     metric_val /= 1e6\n",
    "             values.append(metric_val)\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        bars = plt.bar(plot_strategies, values, color=colors)\n",
    "        plt.xlabel('Strategy')\n",
    "        plt.ylabel(y_labels[metric_name])\n",
    "        plt.title(titles[metric_name])\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "        # Determine format string for labels OUTSIDE the f-string placeholder\n",
    "        label_format = '.4f' if metric_name == 'rmse' else '.2f'\n",
    "        for bar in bars:\n",
    "            yval = bar.get_height()\n",
    "            if not np.isnan(yval):\n",
    "                # Use the determined label_format inside the f-string placeholder\n",
    "                plt.text(bar.get_x() + bar.get_width()/2., yval, f'{yval:{label_format}}',\n",
    "                         ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "        # Add initial model reference line\n",
    "        if 'initial' in results and metric_name in results['initial'] and not np.isnan(results['initial'][metric_name]):\n",
    "            initial_value = results['initial'][metric_name]\n",
    "            if metric_name in ['flops', 'params']:\n",
    "                initial_value /= 1e6\n",
    "\n",
    "            # --- CORRECTED PART for the label ---\n",
    "            # 1. Determine the format string based on the metric\n",
    "            initial_label_format = '.4f' if metric_name == 'rmse' else '.2f'\n",
    "            # 2. Apply the format string to the value\n",
    "            formatted_initial_value = f\"{initial_value:{initial_label_format}}\"\n",
    "            # 3. Construct the label string\n",
    "            initial_line_label = f\"Initial ({formatted_initial_value})\"\n",
    "\n",
    "            plt.axhline(y=initial_value, color='r', linestyle='--', label=initial_line_label) # Use the constructed label\n",
    "            plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f'mlp_{metric_name}_comparison.png'))\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"Comparison plots saved to {output_dir}\")"
   ],
   "id": "619bf68dbdb48e64",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Main Workflow Configuration",
   "id": "fd7f90a7b2e0b08e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T06:11:52.545942Z",
     "start_time": "2025-05-13T06:11:52.510773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Configuration ---\n",
    "DATA_DIR = './data/CMaps/' # <<< IMPORTANT: Set path to your NASA CMaps data directory\n",
    "OUTPUT_DIR = './output_mlp_pruning/fd001/'\n",
    "TRAIN_FILE = 'train_FD001.txt'\n",
    "TEST_FILE = 'test_FD001.txt'\n",
    "TEST_RUL_FILE = 'RUL_FD001.txt'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Model Config\n",
    "MLP_HIDDEN_UNITS = [2048, 1024, 1024, 512, 512, 256, 128]\n",
    "OUTPUT_SIZE = 1 # For RUL regression\n",
    "DROPOUT_RATE = 0.3 # Maybe increase for bigger model\n",
    "USE_BATCHNORM = True # Set to True to include BatchNorm layers\n",
    "\n",
    "# Training Config\n",
    "INITIAL_TRAIN_EPOCHS = 100 # Train longer initially\n",
    "FINETUNE_EPOCHS = 100    # Fine-tune potentially as long\n",
    "BATCH_SIZE = 128\n",
    "INITIAL_LR = 0.001\n",
    "FINETUNE_LR = 0.0005\n",
    "PATIENCE = 15 # Patience for early stopping\n",
    "VAL_SPLIT_RATIO = 0.2 # Use 20% of training engines for validation\n",
    "\n",
    "# Pruning Config\n",
    "PRUNING_TARGET_SPARSITY = 0.2 # Target 50% sparsity\n",
    "PRUNING_ITERATIVE_STEPS = 1 # For structured pruning, 1 step is common\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Pruning strategies (can reuse from ResNet example)\n",
    "# Note: BNScalePruner/GroupNormPruner less applicable to MLP without BatchNorm layers\n",
    "pruning_strategies = {\n",
    "    'magnitude': {'pruner': tp.pruner.MagnitudePruner, 'importance': tp.importance.MagnitudeImportance(p=2)},\n",
    "    #'bn_scale': {'pruner': tp.pruner.BNScalePruner, 'importance': tp.importance.BNScaleImportance()}, # If you add BN layers\n",
    "    'random': {'pruner': tp.pruner.MagnitudePruner, 'importance': tp.importance.RandomImportance()},\n",
    "    'Taylor': {'pruner': tp.pruner.MagnitudePruner, 'importance': tp.importance.TaylorImportance()},\n",
    "    #'Hessian': {'pruner': tp.pruner.MagnitudePruner, 'importance': tp.importance.GroupHessianImportance()}, # Slow, requires grads\n",
    "    'lamp': {'pruner': tp.pruner.MagnitudePruner, 'importance': tp.importance.LAMPImportance(p=2)},\n",
    "    #'geometry': {'pruner': tp.pruner.MagnitudePruner, 'importance': tp.importance.FPGMImportance()} # More geometric\n",
    "}"
   ],
   "id": "fdf31bb603c5e8b0",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Loading and Preparation Execution",
   "id": "1692327131960ad2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T06:11:56.217423Z",
     "start_time": "2025-05-13T06:11:55.883624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Load and Prepare Data ---\n",
    "train_df_norm, test_df_norm, test_rul_df, scaler, feature_cols = prepare_cmapss_data(\n",
    "    DATA_DIR, TRAIN_FILE, TEST_FILE, TEST_RUL_FILE\n",
    ")\n",
    "\n",
    "INPUT_SIZE = len(feature_cols) # Determine input size dynamically\n",
    "print(f\"MLP Input Size determined as: {INPUT_SIZE}\")\n",
    "\n",
    "# --- Split Training Data into Train/Validation (by engine unit) ---\n",
    "train_units = train_df_norm['unit_number'].unique()\n",
    "np.random.seed(42) # For reproducible split\n",
    "np.random.shuffle(train_units)\n",
    "split_idx = int(len(train_units) * (1 - VAL_SPLIT_RATIO))\n",
    "train_unit_ids = train_units[:split_idx]\n",
    "val_unit_ids = train_units[split_idx:]\n",
    "\n",
    "df_train_split = train_df_norm[train_df_norm['unit_number'].isin(train_unit_ids)]\n",
    "df_val_split = train_df_norm[train_df_norm['unit_number'].isin(val_unit_ids)]\n",
    "\n",
    "print(f\"Training data split: {len(df_train_split)} samples ({len(train_unit_ids)} engines)\")\n",
    "print(f\"Validation data split: {len(df_val_split)} samples ({len(val_unit_ids)} engines)\")\n",
    "\n",
    "# --- Prepare MLP Inputs/Outputs ---\n",
    "# Training data: use all time steps\n",
    "X_train = df_train_split[feature_cols].values\n",
    "y_train = df_train_split['RUL'].values\n",
    "\n",
    "# Validation data: use all time steps\n",
    "X_val = df_val_split[feature_cols].values\n",
    "y_val = df_val_split['RUL'].values\n",
    "\n",
    "# Test data: use ONLY the LAST time step for each engine\n",
    "X_test = []\n",
    "test_engine_ids = test_df_norm['unit_number'].unique()\n",
    "for eng_id in test_engine_ids:\n",
    "    eng_data = test_df_norm[test_df_norm['unit_number'] == eng_id]\n",
    "    last_step_features = eng_data[feature_cols].iloc[-1].values # Get last row features\n",
    "    X_test.append(last_step_features)\n",
    "X_test = np.array(X_test)\n",
    "# Target RULs for test set are provided directly in RUL_FD001.txt\n",
    "y_test = test_rul_df['RUL'].values[:len(X_test)] # Ensure lengths match if RUL file has extra lines\n",
    "\n",
    "print(f\"Prepared MLP data shapes:\")\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "\n",
    "# --- Create DataLoaders ---\n",
    "train_dataset = CMAPSS_MLP_Dataset(X_train, y_train)\n",
    "val_dataset = CMAPSS_MLP_Dataset(X_val, y_val)\n",
    "test_dataset = CMAPSS_MLP_Dataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False) # Use same batch size for consistency\n",
    "\n",
    "# Create an example input tensor for pruning/flops calculation\n",
    "example_input_tensor = torch.randn(1, INPUT_SIZE).to(DEVICE)"
   ],
   "id": "6920f457d6b0d906",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparing Training Data ---\n",
      "\n",
      "--- Preparing Test Data ---\n",
      "Columns with std < 0.02 (potential removal): ['op_setting_1', 'op_setting_2', 'op_setting_3', 'sensor_1', 'sensor_5', 'sensor_6', 'sensor_10', 'sensor_16', 'sensor_18', 'sensor_19']\n",
      "\n",
      "Using Features: ['sensor_2', 'sensor_3', 'sensor_4', 'sensor_7', 'sensor_8', 'sensor_9', 'sensor_11', 'sensor_12', 'sensor_13', 'sensor_14', 'sensor_15', 'sensor_17', 'sensor_20', 'sensor_21']\n",
      "\n",
      "--- Normalizing Data ---\n",
      "MLP Input Size determined as: 14\n",
      "Training data split: 16340 samples (80 engines)\n",
      "Validation data split: 4291 samples (20 engines)\n",
      "Prepared MLP data shapes:\n",
      "X_train: (16340, 14), y_train: (16340,)\n",
      "X_val: (4291, 14), y_val: (4291,)\n",
      "X_test: (100, 14), y_test: (100,)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T06:15:39.716746Z",
     "start_time": "2025-05-13T06:15:39.713781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_structural_metrics_comparison():\n",
    "    pass\n",
    "def plot_finetuning_curves():\n",
    "    pass"
   ],
   "id": "b0afff9f8b5a27eb",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Main Pruning Workflow Execution",
   "id": "5b4fb1a2e19de774"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T06:16:07.855819Z",
     "start_time": "2025-05-13T06:15:41.962162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 9: Main Pruning Workflow Execution\n",
    "import pickle\n",
    "# --- Main Workflow ---\n",
    "all_results = {}\n",
    "structural_metrics_after_pruning = {}\n",
    "fine_tuning_history = {}\n",
    "initial_train_history = {} # Initialize as empty dict\n",
    "\n",
    "# Define base paths for saving (without .pth extension)\n",
    "initial_model_base_path = os.path.join(OUTPUT_DIR, \"mlp_initial\")\n",
    "initial_history_path = os.path.join(OUTPUT_DIR, \"mlp_initial_train_history.pkl\") # Path for history\n",
    "current_mlp_model = None\n",
    "\n",
    "# --- 1. Initial Training ---\n",
    "if not os.path.exists(initial_model_base_path + \".pth\"):\n",
    "    print(\"\\n--- Training Initial MLP Model ---\")\n",
    "    current_mlp_model = MLPmodel(layer_units=MLP_HIDDEN_UNITS, input_size=INPUT_SIZE, dropout_rate=DROPOUT_RATE).to(DEVICE)\n",
    "    # ... (criterion, optimizer, scheduler setup for initial training) ...\n",
    "    criterion_initial = nn.MSELoss()\n",
    "    optimizer_initial = torch.optim.Adam(current_mlp_model.parameters(), lr=INITIAL_LR, weight_decay=1e-5)\n",
    "    scheduler_initial = ReduceLROnPlateau(optimizer_initial, mode='min', factor=0.5, patience=int(PATIENCE/2), verbose=True)\n",
    "\n",
    "\n",
    "    current_mlp_model, train_hist, val_hist = train_mlp_model(\n",
    "        model=current_mlp_model, train_loader=train_loader, val_loader=val_loader,\n",
    "        criterion=criterion_initial, optimizer=optimizer_initial, scheduler=scheduler_initial,\n",
    "        device=DEVICE, num_epochs=INITIAL_TRAIN_EPOCHS, patience=PATIENCE,\n",
    "        model_save_path=initial_model_base_path + \"_best_val_checkpoint.pth\"\n",
    "    )\n",
    "    initial_train_history['train_loss'] = train_hist\n",
    "    initial_train_history['val_loss'] = val_hist\n",
    "    save_model_state(current_mlp_model, initial_model_base_path, example_input_for_onnx=example_input_tensor, device_for_onnx=DEVICE)\n",
    "    # Save the training history\n",
    "    with open(initial_history_path, 'wb') as f:\n",
    "        pickle.dump(initial_train_history, f)\n",
    "    print(f\"Initial model training history saved to {initial_history_path}\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\n--- Loading Initial MLP Model from {initial_model_base_path}.pth ---\")\n",
    "    current_mlp_model = MLPmodel(layer_units=MLP_HIDDEN_UNITS, input_size=INPUT_SIZE, dropout_rate=DROPOUT_RATE).to(DEVICE)\n",
    "    current_mlp_model = load_model_state(current_mlp_model, initial_model_base_path + \".pth\", DEVICE)\n",
    "    # Load the training history if it exists\n",
    "    if os.path.exists(initial_history_path):\n",
    "        with open(initial_history_path, 'rb') as f:\n",
    "            initial_train_history = pickle.load(f)\n",
    "        print(f\"Initial model training history loaded from {initial_history_path}\")\n",
    "    else:\n",
    "        print(f\"Warning: Initial model training history file not found at {initial_history_path}. Will not be plotted.\")\n",
    "        initial_train_history = {} # Ensure it's an empty dict if not loaded\n",
    "\n",
    "# --- 2. Evaluate Initial Model on Test Set ---\n",
    "print(\"\\n--- Evaluating Initial MLP Model on Test Set ---\")\n",
    "initial_metrics_on_test = evaluate_model_rmse(current_mlp_model, test_loader, DEVICE, example_input_tensor)\n",
    "all_results['initial'] = initial_metrics_on_test # This will be used in the final comparison table\n",
    "# Store initial structural metrics for the structural comparison plot\n",
    "structural_metrics_after_pruning['initial'] = {\n",
    "    'flops': initial_metrics_on_test['flops'],\n",
    "    'params': initial_metrics_on_test['params'],\n",
    "    'size_mb': initial_metrics_on_test['size_mb']\n",
    "}\n",
    "\n",
    "\n",
    "# --- 3. Pruning and Fine-tuning Loop ---\n",
    "for strategy_name, strategy_details in pruning_strategies.items():\n",
    "    print(f\"\\n\\n{'='*20} STRATEGY: {strategy_name.upper()} {'='*20}\")\n",
    "    print(f\"--- Preparing Model for Pruning with Strategy: {strategy_name} ---\")\n",
    "\n",
    "    # Load a fresh copy of the *initial trained model* for each pruning strategy\n",
    "    model_for_this_strategy = MLPmodel(layer_units=MLP_HIDDEN_UNITS, input_size=INPUT_SIZE, dropout_rate=DROPOUT_RATE).to(DEVICE)\n",
    "    model_for_this_strategy = load_model_state(model_for_this_strategy, initial_model_base_path + \".pth\", DEVICE) # Load initial weights\n",
    "\n",
    "    current_importance_metric = None # For stateful importance like Taylor\n",
    "    if strategy_name == 'Taylor':\n",
    "         current_importance_metric = tp.importance.TaylorImportance()\n",
    "         # TaylorImportance requires gradients to be calculated before pruner.step() uses it.\n",
    "         # This is handled inside the `prune_mlp_model` function.\n",
    "\n",
    "    pruned_successfully_flag = False\n",
    "    # Create a deep copy to prune, so model_for_this_strategy (the initial loaded one) remains untouched if pruning fails\n",
    "    model_to_actually_prune = copy.deepcopy(model_for_this_strategy)\n",
    "\n",
    "    print(f\"--- Attempting Pruning with Strategy: {strategy_name} ---\")\n",
    "    try:\n",
    "        pruned_model_output = prune_mlp_model( # This function modifies the model in-place\n",
    "            model_to_prune=model_to_actually_prune, # Pass the copy\n",
    "            example_input=example_input_tensor,\n",
    "            strategy_name_for_debug=strategy_name,\n",
    "            strategy=strategy_details,\n",
    "            target_sparsity=PRUNING_TARGET_SPARSITY,\n",
    "            iterative_steps=PRUNING_ITERATIVE_STEPS,\n",
    "            importance = current_importance_metric # Pass stateful importance if created\n",
    "        )\n",
    "        # After successful pruning, model_to_actually_prune is the pruned model\n",
    "        pruned_model_for_finetuning = model_to_actually_prune\n",
    "        pruned_successfully_flag = True\n",
    "        print(f\"Pruning successful for {strategy_name}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"!!!!!! CRITICAL PRUNING FAILURE for strategy {strategy_name}: {e} !!!!!!\")\n",
    "        # If pruning fails, we will fine-tune the original unpruned model for this strategy slot\n",
    "        # to keep the workflow running and have some comparison point.\n",
    "        print(f\"Using UNPRUNED (initial) model for fine-tuning slot of strategy {strategy_name} due to pruning error.\")\n",
    "        pruned_model_for_finetuning = model_for_this_strategy # Use the original loaded model\n",
    "        pruned_successfully_flag = False\n",
    "\n",
    "\n",
    "    # Store structural metrics IMMEDIATELY AFTER PRUNING (or use initial if pruning failed)\n",
    "    if pruned_successfully_flag:\n",
    "        flops_post_prune, params_post_prune = calculate_flops_params(pruned_model_for_finetuning, example_input_tensor)\n",
    "        size_mb_post_prune = params_post_prune * 4 / 1e6\n",
    "        structural_metrics_after_pruning[strategy_name] = {\n",
    "            'flops': flops_post_prune,\n",
    "            'params': params_post_prune,\n",
    "            'size_mb': size_mb_post_prune\n",
    "        }\n",
    "    else: # Pruning failed, so structural metrics are same as initial\n",
    "        structural_metrics_after_pruning[strategy_name] = structural_metrics_after_pruning['initial']\n",
    "\n",
    "    # Save the state of the model after pruning (even if it's the unpruned one due to failure)\n",
    "    pruned_model_base_path = os.path.join(OUTPUT_DIR, f\"mlp_{strategy_name}_pruned\")\n",
    "    save_model_state(pruned_model_for_finetuning, pruned_model_base_path) # Only .pth for intermediate\n",
    "\n",
    "    # --- Fine-tune the (potentially) pruned model ---\n",
    "    print(f\"\\n--- Fine-tuning MLP for Strategy: {strategy_name} ---\")\n",
    "    # Ensure all parameters that should be trained require gradients\n",
    "    for param in pruned_model_for_finetuning.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    optimizer_ft = torch.optim.Adam(pruned_model_for_finetuning.parameters(), lr=FINETUNE_LR, weight_decay=1e-5)\n",
    "    scheduler_ft = ReduceLROnPlateau(optimizer_ft, mode='min', factor=0.5, patience=int(PATIENCE/2)-1 if PATIENCE>2 else 1, verbose=True) # Slightly less patience for scheduler than early stopping\n",
    "    criterion_ft = nn.MSELoss()\n",
    "\n",
    "    # The model passed (pruned_model_for_finetuning) will be modified in-place by train_mlp_model\n",
    "    fine_tuned_model_instance, ft_train_hist, ft_val_hist = train_mlp_model(\n",
    "        model=pruned_model_for_finetuning, # This model gets updated with best val weights\n",
    "        train_loader=train_loader, val_loader=val_loader,\n",
    "        criterion=criterion_ft, optimizer=optimizer_ft, scheduler=scheduler_ft,\n",
    "        device=DEVICE, num_epochs=FINETUNE_EPOCHS, patience=PATIENCE,\n",
    "        model_save_path=os.path.join(OUTPUT_DIR, f\"mlp_{strategy_name}_finetune_best_val_checkpoint.pth\")\n",
    "    )\n",
    "    fine_tuning_history[strategy_name] = {\n",
    "        'train_loss': ft_train_hist,\n",
    "        'val_loss': ft_val_hist,\n",
    "    }\n",
    "\n",
    "    # --- Evaluate the fine-tuned model on Test Set ---\n",
    "    print(f\"\\n--- Evaluating Fine-tuned MLP ({strategy_name}) on Test Set ---\")\n",
    "    final_metrics_on_test = evaluate_model_rmse(fine_tuned_model_instance, test_loader, DEVICE, example_input_tensor)\n",
    "\n",
    "    # Combine final test performance (RMSE) with its structural metrics (which were set after pruning)\n",
    "    # The FLOPs/Params don't change during fine-tuning, so use from structural_metrics_after_pruning\n",
    "    combined_final_metrics = {\n",
    "        'rmse': final_metrics_on_test['rmse'], # RMSE from test set after fine-tuning\n",
    "        **structural_metrics_after_pruning[strategy_name] # FLOPs, Params, size_mb from after pruning\n",
    "    }\n",
    "    all_results[strategy_name] = combined_final_metrics\n",
    "\n",
    "\n",
    "    # Save the final fine-tuned model state (.pth) and its ONNX version\n",
    "    final_model_base_path = os.path.join(OUTPUT_DIR, f\"mlp_{strategy_name}_final\")\n",
    "    save_model_state(fine_tuned_model_instance, final_model_base_path, example_input_for_onnx=example_input_tensor, device_for_onnx=DEVICE)\n",
    "\n",
    "\n",
    "# --- 4. Compare Final Test Results (Table for RMSE and post-pruning structural metrics) ---\n",
    "print(\"\\n\\n--- Final Test RMSE and Structural Metrics (Post-Pruning) Comparison ---\")\n",
    "compare_results_and_plot_rmse(all_results, OUTPUT_DIR) # This uses all_results which contains RMSE and structural data\n",
    "\n",
    "# --- 5. Plot Training/Fine-tuning History (Loss curves over epochs) ---\n",
    "print(\"\\n\\n--- Plotting Fine-tuning Loss Curves ---\")\n",
    "if 'fine_tuning_history' in locals() and fine_tuning_history:\n",
    "    plot_finetuning_curves(fine_tuning_history,\n",
    "                           initial_history=(initial_train_history if initial_train_history else None), # Pass loaded history\n",
    "                           output_dir=OUTPUT_DIR)\n",
    "else:\n",
    "    print(\"Fine-tuning history dictionary not found or is empty.\")\n",
    "\n",
    "# --- 6. Plot Structural Metrics (Bar Chart: FLOPs/Params Initial vs. Post-Pruning) ---\n",
    "print(\"\\n\\n--- Plotting Structural Metrics (Initial vs. Post-Pruning) ---\")\n",
    "if 'structural_metrics_after_pruning' in locals() and structural_metrics_after_pruning:\n",
    "    plot_structural_metrics_comparison(structural_metrics_after_pruning, OUTPUT_DIR)\n",
    "else:\n",
    "    print(\"Structural metrics (post-pruning) dictionary not found or is empty.\")\n",
    "\n",
    "print(\"\\nMLP Pruning Workflow Completed!\")"
   ],
   "id": "ab9ea8654e60e023",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Initial MLP Model ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muis/.virtualenvs/master-thesis/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on cuda with patience=15\n",
      "Epoch 1/100: Train Loss=991.6038, Val Loss=571.1660, LR=1.0e-03\n",
      "*** New best validation loss: 571.1660 (Epoch 1) ***\n",
      "Epoch 2/100: Train Loss=665.4012, Val Loss=612.5370, LR=1.0e-03\n",
      "Epoch 3/100: Train Loss=639.5186, Val Loss=1176.5614, LR=1.0e-03\n",
      "Epoch 4/100: Train Loss=622.9357, Val Loss=707.1494, LR=1.0e-03\n",
      "Epoch 5/100: Train Loss=622.5278, Val Loss=1188.2493, LR=1.0e-03\n",
      "Epoch 6/100: Train Loss=580.2433, Val Loss=1490.3106, LR=1.0e-03\n",
      "Epoch 7/100: Train Loss=601.4487, Val Loss=1185.8904, LR=1.0e-03\n",
      "Epoch 8/100: Train Loss=565.4043, Val Loss=1016.8169, LR=1.0e-03\n",
      "Epoch 9/100: Train Loss=551.8645, Val Loss=830.8966, LR=1.0e-03\n",
      "Epoch 10/100: Train Loss=516.5370, Val Loss=1258.1280, LR=5.0e-04\n",
      "Epoch 11/100: Train Loss=505.1975, Val Loss=1158.3758, LR=5.0e-04\n",
      "Epoch 12/100: Train Loss=493.8528, Val Loss=861.8777, LR=5.0e-04\n",
      "Epoch 13/100: Train Loss=486.1058, Val Loss=913.9163, LR=5.0e-04\n",
      "Epoch 14/100: Train Loss=473.9388, Val Loss=1100.9368, LR=5.0e-04\n",
      "Epoch 15/100: Train Loss=459.5682, Val Loss=791.2624, LR=5.0e-04\n",
      "Epoch 16/100: Train Loss=450.8876, Val Loss=868.0937, LR=5.0e-04\n",
      "Early stopping triggered after 15 epochs without improvement on Val Loss.\n",
      "Training finished. Best validation loss: 571.1660\n",
      "Loaded best model state based on validation loss.\n",
      "Model state (.pth) saved to ./output_mlp_pruning/fd001/mlp_initial.pth\n",
      "Attempting to save ONNX model to: ./output_mlp_pruning/fd001/mlp_initial.onnx\n",
      "âœ… Model successfully saved as ONNX to ./output_mlp_pruning/fd001/mlp_initial.onnx\n",
      "Initial model training history saved to ./output_mlp_pruning/fd001/mlp_initial_train_history.pkl\n",
      "\n",
      "--- Evaluating Initial MLP Model on Test Set ---\n",
      "Evaluation RMSE: 23.5396\n",
      "\n",
      "\n",
      "==================== STRATEGY: MAGNITUDE ====================\n",
      "--- Preparing Model for Pruning with Strategy: magnitude ---\n",
      "Model state loaded from ./output_mlp_pruning/fd001/mlp_initial.pth\n",
      "--- Attempting Pruning with Strategy: magnitude ---\n",
      "\n",
      "--- Model Structure BEFORE Pruning (magnitude) ---\n",
      "MLPmodel(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=14, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.3, inplace=False)\n",
      "    (9): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.3, inplace=False)\n",
      "    (12): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (13): ReLU()\n",
      "    (14): Dropout(p=0.3, inplace=False)\n",
      "    (15): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (16): ReLU()\n",
      "    (17): Dropout(p=0.3, inplace=False)\n",
      "    (18): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (19): ReLU()\n",
      "    (20): Dropout(p=0.3, inplace=False)\n",
      "    (21): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "State Before Pruning (magnitude): FLOPs=4.1358M, Params=4.1303M\n",
      "Ignoring output layer (Linear(in_features=128, out_features=1, bias=True)) during pruning for magnitude.\n",
      "Using Importance Metric (magnitude): MagnitudeImportance\n",
      "Using Pruner Class (magnitude): BasePruner\n",
      "Starting pruning with magnitude, Target Sparsity: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muis/.virtualenvs/master-thesis/lib/python3.12/site-packages/torch_pruning/pruner/algorithms/base_pruner.py:87: UserWarning: ch_sparsity is deprecated in v1.3.0. Please use pruning_ratio.\n",
      "  warnings.warn(\n",
      "/home/muis/.virtualenvs/master-thesis/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Structure AFTER Pruning (magnitude) ---\n",
      "MLPmodel(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=14, out_features=1638, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=1638, out_features=819, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=819, out_features=819, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.3, inplace=False)\n",
      "    (9): Linear(in_features=819, out_features=409, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.3, inplace=False)\n",
      "    (12): Linear(in_features=409, out_features=409, bias=True)\n",
      "    (13): ReLU()\n",
      "    (14): Dropout(p=0.3, inplace=False)\n",
      "    (15): Linear(in_features=409, out_features=204, bias=True)\n",
      "    (16): ReLU()\n",
      "    (17): Dropout(p=0.3, inplace=False)\n",
      "    (18): Linear(in_features=204, out_features=102, bias=True)\n",
      "    (19): ReLU()\n",
      "    (20): Dropout(p=0.3, inplace=False)\n",
      "    (21): Linear(in_features=102, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Pruning finished for magnitude. Final FLOPs: 2.6506M, Params: 2.6462M\n",
      "FLOPs Reduction (magnitude): 35.91%\n",
      "Params Reduction (magnitude): 35.93%\n",
      "\n",
      "--- Named Parameters AFTER Pruning (magnitude) ---\n",
      "network.0.weight: shape=torch.Size([1638, 14]), num_elements=22932, requires_grad=True\n",
      "network.0.bias: shape=torch.Size([1638]), num_elements=1638, requires_grad=True\n",
      "network.3.weight: shape=torch.Size([819, 1638]), num_elements=1341522, requires_grad=True\n",
      "network.3.bias: shape=torch.Size([819]), num_elements=819, requires_grad=True\n",
      "network.6.weight: shape=torch.Size([819, 819]), num_elements=670761, requires_grad=True\n",
      "network.6.bias: shape=torch.Size([819]), num_elements=819, requires_grad=True\n",
      "network.9.weight: shape=torch.Size([409, 819]), num_elements=334971, requires_grad=True\n",
      "network.9.bias: shape=torch.Size([409]), num_elements=409, requires_grad=True\n",
      "network.12.weight: shape=torch.Size([409, 409]), num_elements=167281, requires_grad=True\n",
      "network.12.bias: shape=torch.Size([409]), num_elements=409, requires_grad=True\n",
      "network.15.weight: shape=torch.Size([204, 409]), num_elements=83436, requires_grad=True\n",
      "network.15.bias: shape=torch.Size([204]), num_elements=204, requires_grad=True\n",
      "network.18.weight: shape=torch.Size([102, 204]), num_elements=20808, requires_grad=True\n",
      "network.18.bias: shape=torch.Size([102]), num_elements=102, requires_grad=True\n",
      "network.21.weight: shape=torch.Size([1, 102]), num_elements=102, requires_grad=True\n",
      "network.21.bias: shape=torch.Size([1]), num_elements=1, requires_grad=True\n",
      "Pruning successful for magnitude.\n",
      "Model state (.pth) saved to ./output_mlp_pruning/fd001/mlp_magnitude_pruned.pth\n",
      "\n",
      "--- Fine-tuning MLP for Strategy: magnitude ---\n",
      "Starting training on cuda with patience=15\n",
      "Epoch 1/100: Train Loss=712.8436, Val Loss=842.2745, LR=5.0e-04\n",
      "*** New best validation loss: 842.2745 (Epoch 1) ***\n",
      "Epoch 2/100: Train Loss=626.3040, Val Loss=909.7760, LR=5.0e-04\n",
      "Epoch 3/100: Train Loss=618.0933, Val Loss=1431.1982, LR=5.0e-04\n",
      "Epoch 4/100: Train Loss=599.4391, Val Loss=1056.1304, LR=5.0e-04\n",
      "Epoch 5/100: Train Loss=590.5597, Val Loss=1500.1244, LR=5.0e-04\n",
      "Epoch 6/100: Train Loss=579.3872, Val Loss=1652.6984, LR=5.0e-04\n",
      "Epoch 7/100: Train Loss=570.1420, Val Loss=1207.3471, LR=5.0e-04\n",
      "Epoch 8/100: Train Loss=568.5071, Val Loss=1093.1491, LR=5.0e-04\n",
      "Epoch 9/100: Train Loss=540.6819, Val Loss=1022.0035, LR=2.5e-04\n",
      "Epoch 10/100: Train Loss=528.0018, Val Loss=1028.0292, LR=2.5e-04\n",
      "Epoch 11/100: Train Loss=517.4127, Val Loss=1350.9457, LR=2.5e-04\n",
      "Epoch 12/100: Train Loss=528.3853, Val Loss=1540.6352, LR=2.5e-04\n",
      "Epoch 13/100: Train Loss=520.9801, Val Loss=1299.1038, LR=2.5e-04\n",
      "Epoch 14/100: Train Loss=507.3368, Val Loss=1401.7514, LR=2.5e-04\n",
      "Epoch 15/100: Train Loss=510.5688, Val Loss=1172.6371, LR=2.5e-04\n",
      "Epoch 16/100: Train Loss=490.5361, Val Loss=1367.0504, LR=1.3e-04\n",
      "Early stopping triggered after 15 epochs without improvement on Val Loss.\n",
      "Training finished. Best validation loss: 842.2745\n",
      "Loaded best model state based on validation loss.\n",
      "\n",
      "--- Evaluating Fine-tuned MLP (magnitude) on Test Set ---\n",
      "Evaluation RMSE: 27.3649\n",
      "Model state (.pth) saved to ./output_mlp_pruning/fd001/mlp_magnitude_final.pth\n",
      "Attempting to save ONNX model to: ./output_mlp_pruning/fd001/mlp_magnitude_final.onnx\n",
      "âœ… Model successfully saved as ONNX to ./output_mlp_pruning/fd001/mlp_magnitude_final.onnx\n",
      "\n",
      "\n",
      "==================== STRATEGY: RANDOM ====================\n",
      "--- Preparing Model for Pruning with Strategy: random ---\n",
      "Model state loaded from ./output_mlp_pruning/fd001/mlp_initial.pth\n",
      "--- Attempting Pruning with Strategy: random ---\n",
      "\n",
      "--- Model Structure BEFORE Pruning (random) ---\n",
      "MLPmodel(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=14, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.3, inplace=False)\n",
      "    (9): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.3, inplace=False)\n",
      "    (12): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (13): ReLU()\n",
      "    (14): Dropout(p=0.3, inplace=False)\n",
      "    (15): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (16): ReLU()\n",
      "    (17): Dropout(p=0.3, inplace=False)\n",
      "    (18): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (19): ReLU()\n",
      "    (20): Dropout(p=0.3, inplace=False)\n",
      "    (21): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "State Before Pruning (random): FLOPs=4.1358M, Params=4.1303M\n",
      "Ignoring output layer (Linear(in_features=128, out_features=1, bias=True)) during pruning for random.\n",
      "Using Importance Metric (random): RandomImportance\n",
      "Using Pruner Class (random): BasePruner\n",
      "Starting pruning with random, Target Sparsity: 0.20\n",
      "\n",
      "--- Model Structure AFTER Pruning (random) ---\n",
      "MLPmodel(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=14, out_features=1638, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=1638, out_features=819, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=819, out_features=819, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.3, inplace=False)\n",
      "    (9): Linear(in_features=819, out_features=409, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.3, inplace=False)\n",
      "    (12): Linear(in_features=409, out_features=409, bias=True)\n",
      "    (13): ReLU()\n",
      "    (14): Dropout(p=0.3, inplace=False)\n",
      "    (15): Linear(in_features=409, out_features=204, bias=True)\n",
      "    (16): ReLU()\n",
      "    (17): Dropout(p=0.3, inplace=False)\n",
      "    (18): Linear(in_features=204, out_features=102, bias=True)\n",
      "    (19): ReLU()\n",
      "    (20): Dropout(p=0.3, inplace=False)\n",
      "    (21): Linear(in_features=102, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Pruning finished for random. Final FLOPs: 2.6506M, Params: 2.6462M\n",
      "FLOPs Reduction (random): 35.91%\n",
      "Params Reduction (random): 35.93%\n",
      "\n",
      "--- Named Parameters AFTER Pruning (random) ---\n",
      "network.0.weight: shape=torch.Size([1638, 14]), num_elements=22932, requires_grad=True\n",
      "network.0.bias: shape=torch.Size([1638]), num_elements=1638, requires_grad=True\n",
      "network.3.weight: shape=torch.Size([819, 1638]), num_elements=1341522, requires_grad=True\n",
      "network.3.bias: shape=torch.Size([819]), num_elements=819, requires_grad=True\n",
      "network.6.weight: shape=torch.Size([819, 819]), num_elements=670761, requires_grad=True\n",
      "network.6.bias: shape=torch.Size([819]), num_elements=819, requires_grad=True\n",
      "network.9.weight: shape=torch.Size([409, 819]), num_elements=334971, requires_grad=True\n",
      "network.9.bias: shape=torch.Size([409]), num_elements=409, requires_grad=True\n",
      "network.12.weight: shape=torch.Size([409, 409]), num_elements=167281, requires_grad=True\n",
      "network.12.bias: shape=torch.Size([409]), num_elements=409, requires_grad=True\n",
      "network.15.weight: shape=torch.Size([204, 409]), num_elements=83436, requires_grad=True\n",
      "network.15.bias: shape=torch.Size([204]), num_elements=204, requires_grad=True\n",
      "network.18.weight: shape=torch.Size([102, 204]), num_elements=20808, requires_grad=True\n",
      "network.18.bias: shape=torch.Size([102]), num_elements=102, requires_grad=True\n",
      "network.21.weight: shape=torch.Size([1, 102]), num_elements=102, requires_grad=True\n",
      "network.21.bias: shape=torch.Size([1]), num_elements=1, requires_grad=True\n",
      "Pruning successful for random.\n",
      "Model state (.pth) saved to ./output_mlp_pruning/fd001/mlp_random_pruned.pth\n",
      "\n",
      "--- Fine-tuning MLP for Strategy: random ---\n",
      "Starting training on cuda with patience=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muis/.virtualenvs/master-thesis/lib/python3.12/site-packages/torch_pruning/pruner/algorithms/base_pruner.py:87: UserWarning: ch_sparsity is deprecated in v1.3.0. Please use pruning_ratio.\n",
      "  warnings.warn(\n",
      "/home/muis/.virtualenvs/master-thesis/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: Train Loss=812.5706, Val Loss=1147.5005, LR=5.0e-04\n",
      "*** New best validation loss: 1147.5005 (Epoch 1) ***\n",
      "Epoch 2/100: Train Loss=628.3127, Val Loss=832.0639, LR=5.0e-04\n",
      "*** New best validation loss: 832.0639 (Epoch 2) ***\n",
      "Epoch 3/100: Train Loss=612.1355, Val Loss=775.6994, LR=5.0e-04\n",
      "*** New best validation loss: 775.6994 (Epoch 3) ***\n",
      "Epoch 4/100: Train Loss=598.3383, Val Loss=1029.1780, LR=5.0e-04\n",
      "Epoch 5/100: Train Loss=574.3806, Val Loss=565.8034, LR=5.0e-04\n",
      "*** New best validation loss: 565.8034 (Epoch 5) ***\n",
      "Epoch 6/100: Train Loss=578.2769, Val Loss=816.6314, LR=5.0e-04\n",
      "Epoch 7/100: Train Loss=554.2090, Val Loss=1215.0672, LR=5.0e-04\n",
      "Epoch 8/100: Train Loss=566.1565, Val Loss=735.9275, LR=5.0e-04\n",
      "Epoch 9/100: Train Loss=545.2213, Val Loss=799.6775, LR=5.0e-04\n",
      "Epoch 10/100: Train Loss=543.8791, Val Loss=986.0833, LR=5.0e-04\n",
      "Epoch 11/100: Train Loss=526.8757, Val Loss=1001.3114, LR=5.0e-04\n",
      "Epoch 12/100: Train Loss=521.4647, Val Loss=846.0322, LR=5.0e-04\n",
      "Epoch 13/100: Train Loss=508.8047, Val Loss=967.8282, LR=2.5e-04\n",
      "Epoch 14/100: Train Loss=491.1668, Val Loss=907.4694, LR=2.5e-04\n",
      "Epoch 15/100: Train Loss=491.1118, Val Loss=1154.0310, LR=2.5e-04\n",
      "Epoch 16/100: Train Loss=475.6276, Val Loss=961.2919, LR=2.5e-04\n",
      "Epoch 17/100: Train Loss=487.6633, Val Loss=825.3988, LR=2.5e-04\n",
      "Epoch 18/100: Train Loss=474.1337, Val Loss=789.3801, LR=2.5e-04\n",
      "Epoch 19/100: Train Loss=466.4153, Val Loss=664.2623, LR=2.5e-04\n",
      "Epoch 20/100: Train Loss=457.6869, Val Loss=643.4890, LR=1.3e-04\n",
      "Early stopping triggered after 15 epochs without improvement on Val Loss.\n",
      "Training finished. Best validation loss: 565.8034\n",
      "Loaded best model state based on validation loss.\n",
      "\n",
      "--- Evaluating Fine-tuned MLP (random) on Test Set ---\n",
      "Evaluation RMSE: 23.3557\n",
      "Model state (.pth) saved to ./output_mlp_pruning/fd001/mlp_random_final.pth\n",
      "Attempting to save ONNX model to: ./output_mlp_pruning/fd001/mlp_random_final.onnx\n",
      "âœ… Model successfully saved as ONNX to ./output_mlp_pruning/fd001/mlp_random_final.onnx\n",
      "\n",
      "\n",
      "==================== STRATEGY: TAYLOR ====================\n",
      "--- Preparing Model for Pruning with Strategy: Taylor ---\n",
      "Model state loaded from ./output_mlp_pruning/fd001/mlp_initial.pth\n",
      "--- Attempting Pruning with Strategy: Taylor ---\n",
      "\n",
      "--- Model Structure BEFORE Pruning (Taylor) ---\n",
      "MLPmodel(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=14, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.3, inplace=False)\n",
      "    (9): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.3, inplace=False)\n",
      "    (12): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (13): ReLU()\n",
      "    (14): Dropout(p=0.3, inplace=False)\n",
      "    (15): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (16): ReLU()\n",
      "    (17): Dropout(p=0.3, inplace=False)\n",
      "    (18): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (19): ReLU()\n",
      "    (20): Dropout(p=0.3, inplace=False)\n",
      "    (21): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "State Before Pruning (Taylor): FLOPs=4.1358M, Params=4.1303M\n",
      "Ignoring output layer (Linear(in_features=128, out_features=1, bias=True)) during pruning for Taylor.\n",
      "Using Importance Metric (Taylor): TaylorImportance\n",
      "Using Pruner Class (Taylor): BasePruner\n",
      "Starting pruning with Taylor, Target Sparsity: 0.20\n",
      "Calculated gradients for TaylorImportance (Taylor).\n",
      "\n",
      "--- Model Structure AFTER Pruning (Taylor) ---\n",
      "MLPmodel(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=14, out_features=1638, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=1638, out_features=819, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=819, out_features=819, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.3, inplace=False)\n",
      "    (9): Linear(in_features=819, out_features=409, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.3, inplace=False)\n",
      "    (12): Linear(in_features=409, out_features=409, bias=True)\n",
      "    (13): ReLU()\n",
      "    (14): Dropout(p=0.3, inplace=False)\n",
      "    (15): Linear(in_features=409, out_features=204, bias=True)\n",
      "    (16): ReLU()\n",
      "    (17): Dropout(p=0.3, inplace=False)\n",
      "    (18): Linear(in_features=204, out_features=102, bias=True)\n",
      "    (19): ReLU()\n",
      "    (20): Dropout(p=0.3, inplace=False)\n",
      "    (21): Linear(in_features=102, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Pruning finished for Taylor. Final FLOPs: 2.6506M, Params: 2.6462M\n",
      "FLOPs Reduction (Taylor): 35.91%\n",
      "Params Reduction (Taylor): 35.93%\n",
      "\n",
      "--- Named Parameters AFTER Pruning (Taylor) ---\n",
      "network.0.weight: shape=torch.Size([1638, 14]), num_elements=22932, requires_grad=True\n",
      "network.0.bias: shape=torch.Size([1638]), num_elements=1638, requires_grad=True\n",
      "network.3.weight: shape=torch.Size([819, 1638]), num_elements=1341522, requires_grad=True\n",
      "network.3.bias: shape=torch.Size([819]), num_elements=819, requires_grad=True\n",
      "network.6.weight: shape=torch.Size([819, 819]), num_elements=670761, requires_grad=True\n",
      "network.6.bias: shape=torch.Size([819]), num_elements=819, requires_grad=True\n",
      "network.9.weight: shape=torch.Size([409, 819]), num_elements=334971, requires_grad=True\n",
      "network.9.bias: shape=torch.Size([409]), num_elements=409, requires_grad=True\n",
      "network.12.weight: shape=torch.Size([409, 409]), num_elements=167281, requires_grad=True\n",
      "network.12.bias: shape=torch.Size([409]), num_elements=409, requires_grad=True\n",
      "network.15.weight: shape=torch.Size([204, 409]), num_elements=83436, requires_grad=True\n",
      "network.15.bias: shape=torch.Size([204]), num_elements=204, requires_grad=True\n",
      "network.18.weight: shape=torch.Size([102, 204]), num_elements=20808, requires_grad=True\n",
      "network.18.bias: shape=torch.Size([102]), num_elements=102, requires_grad=True\n",
      "network.21.weight: shape=torch.Size([1, 102]), num_elements=102, requires_grad=True\n",
      "network.21.bias: shape=torch.Size([1]), num_elements=1, requires_grad=True\n",
      "Pruning successful for Taylor.\n",
      "Model state (.pth) saved to ./output_mlp_pruning/fd001/mlp_Taylor_pruned.pth\n",
      "\n",
      "--- Fine-tuning MLP for Strategy: Taylor ---\n",
      "Starting training on cuda with patience=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muis/.virtualenvs/master-thesis/lib/python3.12/site-packages/torch_pruning/pruner/algorithms/base_pruner.py:87: UserWarning: ch_sparsity is deprecated in v1.3.0. Please use pruning_ratio.\n",
      "  warnings.warn(\n",
      "/home/muis/.virtualenvs/master-thesis/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: Train Loss=674.4255, Val Loss=1133.1097, LR=5.0e-04\n",
      "*** New best validation loss: 1133.1097 (Epoch 1) ***\n",
      "Epoch 2/100: Train Loss=612.9259, Val Loss=1038.8062, LR=5.0e-04\n",
      "*** New best validation loss: 1038.8062 (Epoch 2) ***\n",
      "Epoch 3/100: Train Loss=589.0846, Val Loss=1449.0496, LR=5.0e-04\n",
      "Epoch 4/100: Train Loss=579.1713, Val Loss=895.7759, LR=5.0e-04\n",
      "*** New best validation loss: 895.7759 (Epoch 4) ***\n",
      "Epoch 5/100: Train Loss=565.6650, Val Loss=672.7230, LR=5.0e-04\n",
      "*** New best validation loss: 672.7230 (Epoch 5) ***\n",
      "Epoch 6/100: Train Loss=566.9346, Val Loss=920.5810, LR=5.0e-04\n",
      "Epoch 7/100: Train Loss=546.0113, Val Loss=1489.1959, LR=5.0e-04\n",
      "Epoch 8/100: Train Loss=524.8692, Val Loss=748.6324, LR=5.0e-04\n",
      "Epoch 9/100: Train Loss=551.7423, Val Loss=633.0120, LR=5.0e-04\n",
      "*** New best validation loss: 633.0120 (Epoch 9) ***\n",
      "Epoch 10/100: Train Loss=527.6934, Val Loss=688.5154, LR=5.0e-04\n",
      "Epoch 11/100: Train Loss=521.9492, Val Loss=1221.2100, LR=5.0e-04\n",
      "Epoch 12/100: Train Loss=512.4278, Val Loss=840.1772, LR=5.0e-04\n",
      "Epoch 13/100: Train Loss=498.0116, Val Loss=1048.2709, LR=5.0e-04\n",
      "Epoch 14/100: Train Loss=476.2493, Val Loss=828.4690, LR=5.0e-04\n",
      "Epoch 15/100: Train Loss=465.8032, Val Loss=658.5152, LR=5.0e-04\n",
      "Epoch 16/100: Train Loss=469.2775, Val Loss=550.6034, LR=5.0e-04\n",
      "*** New best validation loss: 550.6034 (Epoch 16) ***\n",
      "Epoch 17/100: Train Loss=442.0774, Val Loss=453.3264, LR=5.0e-04\n",
      "*** New best validation loss: 453.3264 (Epoch 17) ***\n",
      "Epoch 18/100: Train Loss=444.1477, Val Loss=463.3157, LR=5.0e-04\n",
      "Epoch 19/100: Train Loss=439.1485, Val Loss=458.9302, LR=5.0e-04\n",
      "Epoch 20/100: Train Loss=439.0232, Val Loss=418.1899, LR=5.0e-04\n",
      "*** New best validation loss: 418.1899 (Epoch 20) ***\n",
      "Epoch 21/100: Train Loss=431.2836, Val Loss=411.2200, LR=5.0e-04\n",
      "*** New best validation loss: 411.2200 (Epoch 21) ***\n",
      "Epoch 22/100: Train Loss=429.4409, Val Loss=435.9473, LR=5.0e-04\n",
      "Epoch 23/100: Train Loss=430.5392, Val Loss=405.7290, LR=5.0e-04\n",
      "*** New best validation loss: 405.7290 (Epoch 23) ***\n",
      "Epoch 24/100: Train Loss=427.5476, Val Loss=380.6819, LR=5.0e-04\n",
      "*** New best validation loss: 380.6819 (Epoch 24) ***\n",
      "Epoch 25/100: Train Loss=423.5630, Val Loss=383.0075, LR=5.0e-04\n",
      "Epoch 26/100: Train Loss=424.6164, Val Loss=408.0958, LR=5.0e-04\n",
      "Epoch 27/100: Train Loss=421.4030, Val Loss=396.5932, LR=5.0e-04\n",
      "Epoch 28/100: Train Loss=419.4630, Val Loss=396.1510, LR=5.0e-04\n",
      "Epoch 29/100: Train Loss=418.3043, Val Loss=382.4680, LR=5.0e-04\n",
      "Epoch 30/100: Train Loss=412.2482, Val Loss=410.0340, LR=5.0e-04\n",
      "Epoch 31/100: Train Loss=413.2058, Val Loss=413.8542, LR=5.0e-04\n",
      "Epoch 32/100: Train Loss=404.0895, Val Loss=385.1681, LR=2.5e-04\n",
      "Epoch 33/100: Train Loss=410.7230, Val Loss=391.8848, LR=2.5e-04\n",
      "Epoch 34/100: Train Loss=409.3787, Val Loss=391.4762, LR=2.5e-04\n",
      "Epoch 35/100: Train Loss=401.7256, Val Loss=394.1689, LR=2.5e-04\n",
      "Epoch 36/100: Train Loss=400.3024, Val Loss=391.8831, LR=2.5e-04\n",
      "Epoch 37/100: Train Loss=407.3396, Val Loss=405.1948, LR=2.5e-04\n",
      "Epoch 38/100: Train Loss=402.2843, Val Loss=395.9477, LR=2.5e-04\n",
      "Epoch 39/100: Train Loss=406.4649, Val Loss=396.6085, LR=1.3e-04\n",
      "Early stopping triggered after 15 epochs without improvement on Val Loss.\n",
      "Training finished. Best validation loss: 380.6819\n",
      "Loaded best model state based on validation loss.\n",
      "\n",
      "--- Evaluating Fine-tuned MLP (Taylor) on Test Set ---\n",
      "Evaluation RMSE: 18.4787\n",
      "Model state (.pth) saved to ./output_mlp_pruning/fd001/mlp_Taylor_final.pth\n",
      "Attempting to save ONNX model to: ./output_mlp_pruning/fd001/mlp_Taylor_final.onnx\n",
      "âœ… Model successfully saved as ONNX to ./output_mlp_pruning/fd001/mlp_Taylor_final.onnx\n",
      "\n",
      "\n",
      "==================== STRATEGY: LAMP ====================\n",
      "--- Preparing Model for Pruning with Strategy: lamp ---\n",
      "Model state loaded from ./output_mlp_pruning/fd001/mlp_initial.pth\n",
      "--- Attempting Pruning with Strategy: lamp ---\n",
      "\n",
      "--- Model Structure BEFORE Pruning (lamp) ---\n",
      "MLPmodel(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=14, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.3, inplace=False)\n",
      "    (9): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.3, inplace=False)\n",
      "    (12): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (13): ReLU()\n",
      "    (14): Dropout(p=0.3, inplace=False)\n",
      "    (15): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (16): ReLU()\n",
      "    (17): Dropout(p=0.3, inplace=False)\n",
      "    (18): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (19): ReLU()\n",
      "    (20): Dropout(p=0.3, inplace=False)\n",
      "    (21): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "State Before Pruning (lamp): FLOPs=4.1358M, Params=4.1303M\n",
      "Ignoring output layer (Linear(in_features=128, out_features=1, bias=True)) during pruning for lamp.\n",
      "Using Importance Metric (lamp): LAMPImportance\n",
      "Using Pruner Class (lamp): BasePruner\n",
      "Starting pruning with lamp, Target Sparsity: 0.20\n",
      "\n",
      "--- Model Structure AFTER Pruning (lamp) ---\n",
      "MLPmodel(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=14, out_features=1638, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=1638, out_features=819, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=819, out_features=819, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.3, inplace=False)\n",
      "    (9): Linear(in_features=819, out_features=409, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.3, inplace=False)\n",
      "    (12): Linear(in_features=409, out_features=409, bias=True)\n",
      "    (13): ReLU()\n",
      "    (14): Dropout(p=0.3, inplace=False)\n",
      "    (15): Linear(in_features=409, out_features=204, bias=True)\n",
      "    (16): ReLU()\n",
      "    (17): Dropout(p=0.3, inplace=False)\n",
      "    (18): Linear(in_features=204, out_features=102, bias=True)\n",
      "    (19): ReLU()\n",
      "    (20): Dropout(p=0.3, inplace=False)\n",
      "    (21): Linear(in_features=102, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Pruning finished for lamp. Final FLOPs: 2.6506M, Params: 2.6462M\n",
      "FLOPs Reduction (lamp): 35.91%\n",
      "Params Reduction (lamp): 35.93%\n",
      "\n",
      "--- Named Parameters AFTER Pruning (lamp) ---\n",
      "network.0.weight: shape=torch.Size([1638, 14]), num_elements=22932, requires_grad=True\n",
      "network.0.bias: shape=torch.Size([1638]), num_elements=1638, requires_grad=True\n",
      "network.3.weight: shape=torch.Size([819, 1638]), num_elements=1341522, requires_grad=True\n",
      "network.3.bias: shape=torch.Size([819]), num_elements=819, requires_grad=True\n",
      "network.6.weight: shape=torch.Size([819, 819]), num_elements=670761, requires_grad=True\n",
      "network.6.bias: shape=torch.Size([819]), num_elements=819, requires_grad=True\n",
      "network.9.weight: shape=torch.Size([409, 819]), num_elements=334971, requires_grad=True\n",
      "network.9.bias: shape=torch.Size([409]), num_elements=409, requires_grad=True\n",
      "network.12.weight: shape=torch.Size([409, 409]), num_elements=167281, requires_grad=True\n",
      "network.12.bias: shape=torch.Size([409]), num_elements=409, requires_grad=True\n",
      "network.15.weight: shape=torch.Size([204, 409]), num_elements=83436, requires_grad=True\n",
      "network.15.bias: shape=torch.Size([204]), num_elements=204, requires_grad=True\n",
      "network.18.weight: shape=torch.Size([102, 204]), num_elements=20808, requires_grad=True\n",
      "network.18.bias: shape=torch.Size([102]), num_elements=102, requires_grad=True\n",
      "network.21.weight: shape=torch.Size([1, 102]), num_elements=102, requires_grad=True\n",
      "network.21.bias: shape=torch.Size([1]), num_elements=1, requires_grad=True\n",
      "Pruning successful for lamp.\n",
      "Model state (.pth) saved to ./output_mlp_pruning/fd001/mlp_lamp_pruned.pth\n",
      "\n",
      "--- Fine-tuning MLP for Strategy: lamp ---\n",
      "Starting training on cuda with patience=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muis/.virtualenvs/master-thesis/lib/python3.12/site-packages/torch_pruning/pruner/algorithms/base_pruner.py:87: UserWarning: ch_sparsity is deprecated in v1.3.0. Please use pruning_ratio.\n",
      "  warnings.warn(\n",
      "/home/muis/.virtualenvs/master-thesis/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: Train Loss=726.1977, Val Loss=577.9471, LR=5.0e-04\n",
      "*** New best validation loss: 577.9471 (Epoch 1) ***\n",
      "Epoch 2/100: Train Loss=650.8271, Val Loss=833.5916, LR=5.0e-04\n",
      "Epoch 3/100: Train Loss=613.5140, Val Loss=839.4975, LR=5.0e-04\n",
      "Epoch 4/100: Train Loss=623.4720, Val Loss=1146.2618, LR=5.0e-04\n",
      "Epoch 5/100: Train Loss=579.8646, Val Loss=817.7384, LR=5.0e-04\n",
      "Epoch 6/100: Train Loss=580.7284, Val Loss=1099.1759, LR=5.0e-04\n",
      "Epoch 7/100: Train Loss=577.9139, Val Loss=814.0399, LR=5.0e-04\n",
      "Epoch 8/100: Train Loss=575.6259, Val Loss=1110.4190, LR=5.0e-04\n",
      "Epoch 9/100: Train Loss=532.0131, Val Loss=1281.5012, LR=2.5e-04\n",
      "Epoch 10/100: Train Loss=536.2497, Val Loss=1457.3895, LR=2.5e-04\n",
      "Epoch 11/100: Train Loss=528.8344, Val Loss=1123.1528, LR=2.5e-04\n",
      "Epoch 12/100: Train Loss=516.6119, Val Loss=1208.5332, LR=2.5e-04\n",
      "Epoch 13/100: Train Loss=518.9981, Val Loss=1551.0431, LR=2.5e-04\n",
      "Epoch 14/100: Train Loss=517.7538, Val Loss=1427.6987, LR=2.5e-04\n",
      "Epoch 15/100: Train Loss=513.0484, Val Loss=1020.6906, LR=2.5e-04\n",
      "Epoch 16/100: Train Loss=498.5099, Val Loss=1304.5142, LR=1.3e-04\n",
      "Early stopping triggered after 15 epochs without improvement on Val Loss.\n",
      "Training finished. Best validation loss: 577.9471\n",
      "Loaded best model state based on validation loss.\n",
      "\n",
      "--- Evaluating Fine-tuned MLP (lamp) on Test Set ---\n",
      "Evaluation RMSE: 23.7194\n",
      "Model state (.pth) saved to ./output_mlp_pruning/fd001/mlp_lamp_final.pth\n",
      "Attempting to save ONNX model to: ./output_mlp_pruning/fd001/mlp_lamp_final.onnx\n",
      "âœ… Model successfully saved as ONNX to ./output_mlp_pruning/fd001/mlp_lamp_final.onnx\n",
      "\n",
      "\n",
      "--- Final Test RMSE and Structural Metrics (Post-Pruning) Comparison ---\n",
      "\n",
      "=== Pruning Strategy Comparison (RMSE) ===\n",
      "Strategy     | FLOPs        | Params     | Size (MB)  | RMSE      \n",
      "-----------------------------------------------------------------\n",
      "Taylor       | 2.65       M | 2.65     M |     10.58 | 18.4787   \n",
      "random       | 2.65       M | 2.65     M |     10.58 | 23.3557   \n",
      "initial      | 4.14       M | 4.13     M |     16.52 | 23.5396   \n",
      "lamp         | 2.65       M | 2.65     M |     10.58 | 23.7194   \n",
      "magnitude    | 2.65       M | 2.65     M |     10.58 | 27.3649   \n",
      "Comparison plots saved to ./output_mlp_pruning/fd001/\n",
      "\n",
      "\n",
      "--- Plotting Fine-tuning Loss Curves ---\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "plot_finetuning_curves() got an unexpected keyword argument 'initial_history'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 170\u001B[39m\n\u001B[32m    168\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m--- Plotting Fine-tuning Loss Curves ---\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    169\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m'\u001B[39m\u001B[33mfine_tuning_history\u001B[39m\u001B[33m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mlocals\u001B[39m() \u001B[38;5;129;01mand\u001B[39;00m fine_tuning_history:\n\u001B[32m--> \u001B[39m\u001B[32m170\u001B[39m     \u001B[43mplot_finetuning_curves\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfine_tuning_history\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    171\u001B[39m \u001B[43m                           \u001B[49m\u001B[43minitial_history\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43minitial_train_history\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43minitial_train_history\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# Pass loaded history\u001B[39;49;00m\n\u001B[32m    172\u001B[39m \u001B[43m                           \u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mOUTPUT_DIR\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    173\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    174\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mFine-tuning history dictionary not found or is empty.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mTypeError\u001B[39m: plot_finetuning_curves() got an unexpected keyword argument 'initial_history'"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Plotting Epoch-wise fine tune history",
   "id": "51b2302901da687d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T06:16:19.841116Z",
     "start_time": "2025-05-13T06:16:18.769549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt # Ensure plt is imported here\n",
    "import numpy as np            # Ensure np is imported here\n",
    "import os                     # Ensure os is imported here\n",
    "from typing import Dict, List, Optional # Ensure typing is imported here\n",
    "\n",
    "\n",
    "def plot_finetuning_curves(history_dict: Dict[str, Dict[str, List[float]]],\n",
    "                           initial_history: Optional[Dict[str, List[float]]] = None,\n",
    "                           output_dir: str = \"./\"):\n",
    "    \"\"\"Plots training and validation loss curves from fine-tuning.\"\"\"\n",
    "    num_strategies_ft = len(history_dict) # Use a different variable name\n",
    "\n",
    "    # Create a figure for each strategy's fine-tuning curves\n",
    "    for strategy_name, history in history_dict.items():\n",
    "        if not history or 'train_loss' not in history or 'val_loss' not in history:\n",
    "            print(f\"Skipping plot for {strategy_name}, missing history data.\")\n",
    "            continue\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        epochs_ft = range(1, len(history['train_loss']) + 1)\n",
    "        plt.plot(epochs_ft, history['train_loss'], label=f'{strategy_name} - Train Loss')\n",
    "        plt.plot(epochs_ft, history['val_loss'], label=f'{strategy_name} - Val Loss')\n",
    "\n",
    "        # Plot initial model's training curves if available and valid\n",
    "        if initial_history and \\\n",
    "           initial_history.get('train_loss') and \\\n",
    "           initial_history.get('val_loss'): # Check keys and ensure not empty lists\n",
    "             epochs_initial = range(1, len(initial_history['train_loss']) + 1)\n",
    "             plt.plot(epochs_initial, initial_history['train_loss'], linestyle='--', color='gray', alpha=0.8, label='Initial Model - Train Loss')\n",
    "             plt.plot(epochs_initial, initial_history['val_loss'], linestyle=':', color='darkgray', alpha=0.8, label='Initial Model - Val Loss')\n",
    "\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss (MSE)\")\n",
    "        plt.title(f\"Fine-tuning Loss: {strategy_name} Strategy\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.yscale('log')\n",
    "        plot_path = os.path.join(output_dir, f\"mlp_finetuning_loss_{strategy_name}.png\")\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\"Saved fine-tuning curve for {strategy_name} to {plot_path}\")\n",
    "\n",
    "    # Combined plot for all strategies' validation losses\n",
    "    if num_strategies_ft > 0: # Only create combined plot if there's history\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        plotted_something_combined = False\n",
    "        for strategy_name, history in history_dict.items():\n",
    "            if history and history.get('val_loss'): # Check key and ensure not empty\n",
    "                epochs_ft = range(1, len(history['val_loss']) + 1)\n",
    "                plt.plot(epochs_ft, history['val_loss'], label=f'{strategy_name} - Val Loss')\n",
    "                plotted_something_combined = True\n",
    "\n",
    "        if initial_history and \\\n",
    "           initial_history.get('val_loss'): # Check key and ensure not empty\n",
    "            epochs_initial = range(1, len(initial_history['val_loss']) + 1)\n",
    "            plt.plot(epochs_initial, initial_history['val_loss'], linestyle=':', color='black', linewidth=2, label='Initial Model - Val Loss')\n",
    "            plotted_something_combined = True\n",
    "\n",
    "        if plotted_something_combined:\n",
    "            plt.xlabel(\"Epochs\")\n",
    "            plt.ylabel(\"Validation Loss (MSE)\")\n",
    "            plt.title(\"Comparison of Validation Loss During Training/Fine-tuning\")\n",
    "            plt.legend(loc='upper left', bbox_to_anchor=(1.05, 1.0)) # Adjusted for potential many lines\n",
    "            plt.grid(True)\n",
    "            plt.yscale('log')\n",
    "            combined_plot_path = os.path.join(output_dir, \"mlp_val_loss_comparison.png\")\n",
    "            plt.savefig(combined_plot_path, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"Saved combined validation loss curves to {combined_plot_path}\")\n",
    "        else:\n",
    "            print(\"No valid validation loss data found to create combined plot.\")\n",
    "    else:\n",
    "        print(\"No fine-tuning history available to plot combined validation losses.\")\n",
    "\n",
    "\n",
    "# --- Call the plotting function for fine-tuning history ---\n",
    "if 'fine_tuning_history' in locals() and fine_tuning_history: # Check if dict exists and is not empty\n",
    "    plot_finetuning_curves(fine_tuning_history,\n",
    "                           initial_history=(initial_train_history if 'initial_train_history' in locals() else None),\n",
    "                           output_dir=OUTPUT_DIR)\n",
    "else:\n",
    "    print(\"Fine-tuning history dictionary not found or is empty.\")\n",
    "\n",
    "\n"
   ],
   "id": "7abff3feb44c9709",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved fine-tuning curve for magnitude to ./output_mlp_pruning/fd001/mlp_finetuning_loss_magnitude.png\n",
      "Saved fine-tuning curve for random to ./output_mlp_pruning/fd001/mlp_finetuning_loss_random.png\n",
      "Saved fine-tuning curve for Taylor to ./output_mlp_pruning/fd001/mlp_finetuning_loss_Taylor.png\n",
      "Saved fine-tuning curve for lamp to ./output_mlp_pruning/fd001/mlp_finetuning_loss_lamp.png\n",
      "Saved combined validation loss curves to ./output_mlp_pruning/fd001/mlp_val_loss_comparison.png\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### --- Plotting Structural Metrics (Bar Chart for FLOPs/Params after pruning) ---",
   "id": "555800811b8b0d68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T06:16:22.237685Z",
     "start_time": "2025-05-13T06:16:22.005044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def plot_structural_metrics_comparison(structural_metrics: Dict[str, Dict[str, float]], output_dir: str):\n",
    "    if not structural_metrics or 'initial' not in structural_metrics: # Ensure initial exists\n",
    "        print(\"No structural metrics to plot, or 'initial' metrics are missing.\")\n",
    "        return\n",
    "\n",
    "    # Ensure 'initial' is first for consistent plotting order\n",
    "    labels = ['initial'] + [s for s in structural_metrics.keys() if s != 'initial']\n",
    "\n",
    "    # Filter out strategies not present in structural_metrics for robustness\n",
    "    labels = [s for s in labels if s in structural_metrics]\n",
    "    if not labels:\n",
    "        print(\"No valid strategies found in structural metrics for plotting.\")\n",
    "        return\n",
    "\n",
    "    flops_values = [structural_metrics[s].get('flops', 0) / 1e6 for s in labels]  # MFLOPs\n",
    "    params_values = [structural_metrics[s].get('params', 0) / 1e6 for s in labels] # MParams\n",
    "\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(14, 8)) # Increased figure size slightly\n",
    "\n",
    "    color_flops = 'tab:blue'\n",
    "    ax1.set_xlabel('Model State (Initial vs. Post-Pruning, Pre-Finetuning)')\n",
    "    ax1.set_ylabel('FLOPs (Millions)', color=color_flops)\n",
    "    bars1 = ax1.bar(x - width/2, flops_values, width, label='FLOPs', color=color_flops)\n",
    "    ax1.tick_params(axis='y', labelcolor=color_flops)\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    color_params = 'tab:red'\n",
    "    ax2.set_ylabel('Parameters (Millions)', color=color_params)\n",
    "    bars2 = ax2.bar(x + width/2, params_values, width, label='Parameters', color=color_params)\n",
    "    ax2.tick_params(axis='y', labelcolor=color_params)\n",
    "\n",
    "    def autolabel(bars, ax):\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            if not np.isnan(height): # Check for NaN before annotating\n",
    "                ax.annotate(f'{height:.2f}',\n",
    "                            xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                            xytext=(0, 3),\n",
    "                            textcoords=\"offset points\",\n",
    "                            ha='center', va='bottom', fontsize=9) # Increased font size slightly\n",
    "    autolabel(bars1, ax1)\n",
    "    autolabel(bars2, ax2)\n",
    "\n",
    "    fig.suptitle('Structural Metrics: Initial vs. Post-Pruning (Before Fine-tuning)', fontsize=14) # Changed title position\n",
    "    fig.tight_layout(rect=[0, 0.1, 1, 0.96]) # Adjust layout to make space for suptitle and legend\n",
    "\n",
    "    # Combined legend\n",
    "    handles1, labels1_fig = ax1.get_legend_handles_labels()\n",
    "    handles2, labels2_fig = ax2.get_legend_handles_labels()\n",
    "    fig.legend(handles1 + handles2, labels1_fig + labels2_fig, loc='upper center', bbox_to_anchor=(0.5, 0.07), ncol=2)\n",
    "\n",
    "\n",
    "    structural_plot_path = os.path.join(output_dir, \"mlp_structural_metrics_after_pruning.png\")\n",
    "    plt.savefig(structural_plot_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved structural metrics plot to {structural_plot_path}\")\n",
    "\n",
    "#Ensure this is called at the end of your main workflow cell:\n",
    "if 'structural_metrics_after_pruning' in locals() and structural_metrics_after_pruning:\n",
    "    plot_structural_metrics_comparison(structural_metrics_after_pruning, OUTPUT_DIR)\n",
    "else:\n",
    "    print(\"Structural metrics (post-pruning) dictionary not found or is empty.\")"
   ],
   "id": "3c8b9d1563ca521b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved structural metrics plot to ./output_mlp_pruning/fd001/mlp_structural_metrics_after_pruning.png\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
