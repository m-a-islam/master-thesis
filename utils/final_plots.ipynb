{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T00:16:02.852827Z",
     "start_time": "2025-06-05T00:15:51.680314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Set consistent style and parameters for all plots\n",
    "plt.style.use('default')  # Use default style for consistency\n",
    "sns.set_palette(\"tab10\")  # Consistent color palette\n",
    "\n",
    "# Global font and style settings\n",
    "plt.rcParams.update({\n",
    "    'figure.dpi': 300,\n",
    "    'savefig.dpi': 300,\n",
    "    'font.size': 16,\n",
    "    'axes.titlesize': 20,\n",
    "    'axes.labelsize': 18,\n",
    "    'xtick.labelsize': 16,\n",
    "    'ytick.labelsize': 16,\n",
    "    'legend.fontsize': 16,\n",
    "    'figure.titlesize': 22,\n",
    "    'lines.linewidth': 3,\n",
    "    'lines.markersize': 10,\n",
    "    'axes.linewidth': 1.5,\n",
    "    'grid.linewidth': 1.0,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.3\n",
    "})\n",
    "\n",
    "# Consistent color scheme\n",
    "COLORS = {\n",
    "    'BNScale': '#1f77b4',      # Blue\n",
    "    'MagnitudeL2': '#ff7f0e',  # Orange\n",
    "    'Random': '#d62728',       # Red\n",
    "    'MLP': '#2ca02c',          # Green\n",
    "    'LSTM': '#9467bd',         # Purple\n",
    "    'MobileNetV2': '#8c564b',  # Brown\n",
    "    'ResNet-18': '#e377c2'     # Pink\n",
    "}\n",
    "\n",
    "def load_all_results():\n",
    "    \"\"\"Load all experimental results from JSON files\"\"\"\n",
    "    try:\n",
    "        with open('mobileNetV2_complete_results.json', 'r') as f:\n",
    "            mobilenetv2_results = json.load(f)\n",
    "\n",
    "        with open('resnet18_complete_results.json', 'r') as f:\n",
    "            resnet18_results = json.load(f)\n",
    "\n",
    "        with open('mlp_complete_results.json', 'r') as f:\n",
    "            mlp_results = json.load(f)\n",
    "\n",
    "        with open('lstm_complete_results.json', 'r') as f:\n",
    "            lstm_results = json.load(f)\n",
    "\n",
    "        return mobilenetv2_results, resnet18_results, mlp_results, lstm_results\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error loading files: {e}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "def results_to_dataframe(results, model_name, task='classification'):\n",
    "    \"\"\"Convert results dictionary to pandas DataFrame\"\"\"\n",
    "    data = []\n",
    "    for strategy, strategy_results in results.items():\n",
    "        for sparsity, metrics in strategy_results.items():\n",
    "            row = {\n",
    "                'model': model_name,\n",
    "                'strategy': strategy,\n",
    "                'sparsity': float(sparsity),\n",
    "                'sparsity_percent': float(sparsity) * 100,\n",
    "                'macs': metrics['macs'],\n",
    "                'macs_millions': metrics['macs'] / 1e6,\n",
    "                'params': metrics['params'],\n",
    "                'params_millions': metrics['params'] / 1e6,\n",
    "                'size_mb': metrics['size_mb'],\n",
    "                'loss': metrics['loss']\n",
    "            }\n",
    "\n",
    "            if task == 'classification':\n",
    "                row['accuracy'] = metrics['accuracy']\n",
    "            else:  # regression\n",
    "                row['mse'] = float(metrics.get('mse', metrics.get('loss', 0)))\n",
    "                row['mae'] = float(metrics.get('mae', 0))\n",
    "\n",
    "            data.append(row)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def create_output_directory():\n",
    "    \"\"\"Create output directory for plots\"\"\"\n",
    "    os.makedirs('chapter5_plots', exist_ok=True)\n",
    "    return 'chapter5_plots'\n",
    "\n",
    "# ============================================================================\n",
    "# Section 5.3.1: MobileNetV2 Performance Analysis\n",
    "# ============================================================================\n",
    "\n",
    "def plot_mobilenetv2_accuracy_vs_sparsity(mobilenet_df, output_dir):\n",
    "    \"\"\"Plot MobileNetV2 accuracy vs sparsity for all strategies\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    for strategy in sorted(mobilenet_df['strategy'].unique()):\n",
    "        data = mobilenet_df[mobilenet_df['strategy'] == strategy].sort_values('sparsity')\n",
    "        ax.plot(data['sparsity_percent'], data['accuracy'],\n",
    "                'o-', color=COLORS[strategy], label=strategy, linewidth=3, markersize=10)\n",
    "\n",
    "    ax.set_xlabel('Sparsity (%)', fontweight='bold')\n",
    "    ax.set_ylabel('Accuracy (%)', fontweight='bold')\n",
    "    ax.set_title('MobileNetV2: Accuracy vs Sparsity Level', fontweight='bold')\n",
    "    ax.legend(frameon=True, fancybox=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim(84, 86.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/mobilenetv2_accuracy_vs_sparsity.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_mobilenetv2_macs_reduction(mobilenet_df, output_dir):\n",
    "    \"\"\"Plot MobileNetV2 MACs reduction\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    baseline_macs = mobilenet_df[mobilenet_df['sparsity'] == 0.0]['macs_millions'].iloc[0]\n",
    "\n",
    "    for strategy in sorted(mobilenet_df['strategy'].unique()):\n",
    "        data = mobilenet_df[mobilenet_df['strategy'] == strategy].sort_values('sparsity')\n",
    "        macs_reduction = (1 - data['macs_millions'] / baseline_macs) * 100\n",
    "        ax.plot(data['sparsity_percent'], macs_reduction,\n",
    "                'o-', color=COLORS[strategy], label=strategy, linewidth=3, markersize=10)\n",
    "\n",
    "    ax.set_xlabel('Sparsity (%)', fontweight='bold')\n",
    "    ax.set_ylabel('MACs Reduction (%)', fontweight='bold')\n",
    "    ax.set_title('MobileNetV2: Computational Cost Reduction', fontweight='bold')\n",
    "    ax.legend(frameon=True, fancybox=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/mobilenetv2_macs_reduction.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_mobilenetv2_size_reduction(mobilenet_df, output_dir):\n",
    "    \"\"\"Plot MobileNetV2 model size reduction\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    baseline_size = mobilenet_df[mobilenet_df['sparsity'] == 0.0]['size_mb'].iloc[0]\n",
    "\n",
    "    for strategy in sorted(mobilenet_df['strategy'].unique()):\n",
    "        data = mobilenet_df[mobilenet_df['strategy'] == strategy].sort_values('sparsity')\n",
    "        size_reduction = (1 - data['size_mb'] / baseline_size) * 100\n",
    "        ax.plot(data['sparsity_percent'], size_reduction,\n",
    "                'o-', color=COLORS[strategy], label=strategy, linewidth=3, markersize=10)\n",
    "\n",
    "    ax.set_xlabel('Sparsity (%)', fontweight='bold')\n",
    "    ax.set_ylabel('Model Size Reduction (%)', fontweight='bold')\n",
    "    ax.set_title('MobileNetV2: Model Size Reduction', fontweight='bold')\n",
    "    ax.legend(frameon=True, fancybox=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/mobilenetv2_size_reduction.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_mobilenetv2_pareto_frontier(mobilenet_df, output_dir):\n",
    "    \"\"\"Plot MobileNetV2 Pareto frontier (Accuracy vs MACs)\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    for strategy in sorted(mobilenet_df['strategy'].unique()):\n",
    "        data = mobilenet_df[mobilenet_df['strategy'] == strategy].sort_values('macs_millions')\n",
    "        ax.scatter(data['macs_millions'], data['accuracy'],\n",
    "                  color=COLORS[strategy], s=150, label=strategy, alpha=0.8,\n",
    "                  edgecolors='black', linewidth=1.5)\n",
    "        ax.plot(data['macs_millions'], data['accuracy'],\n",
    "               color=COLORS[strategy], linestyle='--', alpha=0.7, linewidth=2)\n",
    "\n",
    "    ax.set_xlabel('MACs (Millions)', fontweight='bold')\n",
    "    ax.set_ylabel('Accuracy (%)', fontweight='bold')\n",
    "    ax.set_title('MobileNetV2: Pareto Frontier (Accuracy vs Computational Cost)', fontweight='bold')\n",
    "    ax.legend(frameon=True, fancybox=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/mobilenetv2_pareto_frontier.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# Section 5.3.2: ResNet-18 Performance Analysis\n",
    "# ============================================================================\n",
    "\n",
    "def plot_resnet18_accuracy_vs_sparsity(resnet_df, output_dir):\n",
    "    \"\"\"Plot ResNet-18 accuracy vs sparsity for all strategies\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    for strategy in sorted(resnet_df['strategy'].unique()):\n",
    "        data = resnet_df[resnet_df['strategy'] == strategy].sort_values('sparsity')\n",
    "        ax.plot(data['sparsity_percent'], data['accuracy'],\n",
    "                'o-', color=COLORS[strategy], label=strategy, linewidth=3, markersize=10)\n",
    "\n",
    "    ax.set_xlabel('Sparsity (%)', fontweight='bold')\n",
    "    ax.set_ylabel('Accuracy (%)', fontweight='bold')\n",
    "    ax.set_title('ResNet-18: Accuracy vs Sparsity Level', fontweight='bold')\n",
    "    ax.legend(frameon=True, fancybox=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim(82, 85)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/resnet18_accuracy_vs_sparsity.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_resnet18_macs_reduction(resnet_df, output_dir):\n",
    "    \"\"\"Plot ResNet-18 MACs reduction\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    baseline_macs = resnet_df[resnet_df['sparsity'] == 0.0]['macs_millions'].iloc[0]\n",
    "\n",
    "    for strategy in sorted(resnet_df['strategy'].unique()):\n",
    "        data = resnet_df[resnet_df['strategy'] == strategy].sort_values('sparsity')\n",
    "        macs_reduction = (1 - data['macs_millions'] / baseline_macs) * 100\n",
    "        ax.plot(data['sparsity_percent'], macs_reduction,\n",
    "                'o-', color=COLORS[strategy], label=strategy, linewidth=3, markersize=10)\n",
    "\n",
    "    ax.set_xlabel('Sparsity (%)', fontweight='bold')\n",
    "    ax.set_ylabel('MACs Reduction (%)', fontweight='bold')\n",
    "    ax.set_title('ResNet-18: Computational Cost Reduction', fontweight='bold')\n",
    "    ax.legend(frameon=True, fancybox=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/resnet18_macs_reduction.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_resnet18_pareto_frontier(resnet_df, output_dir):\n",
    "    \"\"\"Plot ResNet-18 Pareto frontier (Accuracy vs MACs)\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    for strategy in sorted(resnet_df['strategy'].unique()):\n",
    "        data = resnet_df[resnet_df['strategy'] == strategy].sort_values('macs_millions')\n",
    "        ax.scatter(data['macs_millions'], data['accuracy'],\n",
    "                  color=COLORS[strategy], s=150, label=strategy, alpha=0.8,\n",
    "                  edgecolors='black', linewidth=1.5)\n",
    "        ax.plot(data['macs_millions'], data['accuracy'],\n",
    "               color=COLORS[strategy], linestyle='--', alpha=0.7, linewidth=2)\n",
    "\n",
    "    ax.set_xlabel('MACs (Millions)', fontweight='bold')\n",
    "    ax.set_ylabel('Accuracy (%)', fontweight='bold')\n",
    "    ax.set_title('ResNet-18: Pareto Frontier (Accuracy vs Computational Cost)', fontweight='bold')\n",
    "    ax.legend(frameon=True, fancybox=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/resnet18_pareto_frontier.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# Section 5.3.3: CNN Comparative Analysis\n",
    "# ============================================================================\n",
    "\n",
    "def plot_cnn_accuracy_comparison(mobilenet_df, resnet_df, output_dir):\n",
    "    \"\"\"Compare CNN accuracies using MagnitudeL2 strategy\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # MobileNetV2 data\n",
    "    mobilenet_data = mobilenet_df[mobilenet_df['strategy'] == 'MagnitudeL2'].sort_values('sparsity')\n",
    "    ax.plot(mobilenet_data['sparsity_percent'], mobilenet_data['accuracy'],\n",
    "            'o-', color=COLORS['MobileNetV2'], label='MobileNetV2', linewidth=3, markersize=10)\n",
    "\n",
    "    # ResNet-18 data\n",
    "    resnet_data = resnet_df[resnet_df['strategy'] == 'MagnitudeL2'].sort_values('sparsity')\n",
    "    ax.plot(resnet_data['sparsity_percent'], resnet_data['accuracy'],\n",
    "            'o-', color=COLORS['ResNet-18'], label='ResNet-18', linewidth=3, markersize=10)\n",
    "\n",
    "    ax.set_xlabel('Sparsity (%)', fontweight='bold')\n",
    "    ax.set_ylabel('Accuracy (%)', fontweight='bold')\n",
    "    ax.set_title('CNN Architectures: Accuracy Comparison (MagnitudeL2 Pruning)', fontweight='bold')\n",
    "    ax.legend(frameon=True, fancybox=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/cnn_accuracy_comparison.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_cnn_efficiency_comparison(mobilenet_df, resnet_df, output_dir):\n",
    "    \"\"\"Compare CNN efficiency (MACs reduction)\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # Calculate MACs reduction for both models\n",
    "    mobilenet_baseline = mobilenet_df[mobilenet_df['sparsity'] == 0.0]['macs_millions'].iloc[0]\n",
    "    resnet_baseline = resnet_df[resnet_df['sparsity'] == 0.0]['macs_millions'].iloc[0]\n",
    "\n",
    "    mobilenet_data = mobilenet_df[mobilenet_df['strategy'] == 'MagnitudeL2'].sort_values('sparsity')\n",
    "    mobilenet_reduction = (1 - mobilenet_data['macs_millions'] / mobilenet_baseline) * 100\n",
    "\n",
    "    resnet_data = resnet_df[resnet_df['strategy'] == 'MagnitudeL2'].sort_values('sparsity')\n",
    "    resnet_reduction = (1 - resnet_data['macs_millions'] / resnet_baseline) * 100\n",
    "\n",
    "    ax.plot(mobilenet_data['sparsity_percent'], mobilenet_reduction,\n",
    "            'o-', color=COLORS['MobileNetV2'], label='MobileNetV2', linewidth=3, markersize=10)\n",
    "    ax.plot(resnet_data['sparsity_percent'], resnet_reduction,\n",
    "            'o-', color=COLORS['ResNet-18'], label='ResNet-18', linewidth=3, markersize=10)\n",
    "\n",
    "    ax.set_xlabel('Sparsity (%)', fontweight='bold')\n",
    "    ax.set_ylabel('MACs Reduction (%)', fontweight='bold')\n",
    "    ax.set_title('CNN Architectures: Computational Efficiency Comparison', fontweight='bold')\n",
    "    ax.legend(frameon=True, fancybox=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/cnn_efficiency_comparison.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# Section 5.4.1: MLP Performance Analysis\n",
    "# ============================================================================\n",
    "\n",
    "def plot_mlp_mse_vs_sparsity(mlp_df, output_dir):\n",
    "    \"\"\"Plot MLP MSE vs sparsity\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    for strategy in sorted(mlp_df['strategy'].unique()):\n",
    "        data = mlp_df[mlp_df['strategy'] == strategy].sort_values('sparsity')\n",
    "        ax.plot(data['sparsity_percent'], data['mse'],\n",
    "                'o-', color=COLORS[strategy], label=strategy, linewidth=3, markersize=10)\n",
    "\n",
    "    ax.set_xlabel('Sparsity (%)', fontweight='bold')\n",
    "    ax.set_ylabel('MSE', fontweight='bold')\n",
    "    ax.set_title('MLP: Mean Squared Error vs Sparsity Level', fontweight='bold')\n",
    "    ax.legend(frameon=True, fancybox=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/mlp_mse_vs_sparsity.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_mlp_mae_vs_sparsity(mlp_df, output_dir):\n",
    "    \"\"\"Plot MLP MAE vs sparsity\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    for strategy in sorted(mlp_df['strategy'].unique()):\n",
    "        data = mlp_df[mlp_df['strategy'] == strategy].sort_values('sparsity')\n",
    "        ax.plot(data['sparsity_percent'], data['mae'],\n",
    "                'o-', color=COLORS[strategy], label=strategy, linewidth=3, markersize=10)\n",
    "\n",
    "    ax.set_xlabel('Sparsity (%)', fontweight='bold')\n",
    "    ax.set_ylabel('MAE', fontweight='bold')\n",
    "    ax.set_title('MLP: Mean Absolute Error vs Sparsity Level', fontweight='bold')\n",
    "    ax.legend(frameon=True, fancybox=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/mlp_mae_vs_sparsity.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_mlp_macs_reduction(mlp_df, output_dir):\n",
    "    \"\"\"Plot MLP MACs reduction\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    baseline_macs = mlp_df[mlp_df['sparsity'] == 0.0]['macs'].iloc[0] / 1000  # Convert to thousands\n",
    "\n",
    "    for strategy in sorted(mlp_df['strategy'].unique()):\n",
    "        data = mlp_df[mlp_df['strategy'] == strategy].sort_values('sparsity')\n",
    "        macs_reduction = (1 - (data['macs'] / 1000) / baseline_macs) * 100\n",
    "        ax.plot(data['sparsity_percent'], macs_reduction,\n",
    "                'o-', color=COLORS[strategy], label=strategy, linewidth=3, markersize=10)\n",
    "\n",
    "    ax.set_xlabel('Sparsity (%)', fontweight='bold')\n",
    "    ax.set_ylabel('MACs Reduction (%)', fontweight='bold')\n",
    "    ax.set_title('MLP: Computational Cost Reduction', fontweight='bold')\n",
    "    ax.legend(frameon=True, fancybox=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/mlp_macs_reduction.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# Section 5.4.2: LSTM Performance Analysis\n",
    "# ============================================================================\n",
    "\n",
    "def plot_lstm_mse_vs_sparsity(lstm_df, output_dir):\n",
    "    \"\"\"Plot LSTM MSE vs sparsity\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    for strategy in sorted(lstm_df['strategy'].unique()):\n",
    "        data = lstm_df[lstm_df['strategy'] == strategy].sort_values('sparsity')\n",
    "        ax.plot(data['sparsity_percent'], data['mse'],\n",
    "                'o-', color=COLORS[strategy], label=strategy, linewidth=3, markersize=10)\n",
    "\n",
    "    ax.set_xlabel('Sparsity (%)', fontweight='bold')\n",
    "    ax.set_ylabel('MSE', fontweight='bold')\n",
    "    ax.set_title('LSTM: Mean Squared Error vs Sparsity Level', fontweight='bold')\n",
    "    ax.legend(frameon=True, fancybox=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/lstm_mse_vs_sparsity.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_lstm_mae_vs_sparsity(lstm_df, output_dir):\n",
    "    \"\"\"Plot LSTM MAE vs sparsity\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    for strategy in sorted(lstm_df['strategy'].unique()):\n",
    "        data = lstm_df[lstm_df['strategy'] == strategy].sort_values('sparsity')\n",
    "        ax.plot(data['sparsity_percent'], data['mae'],\n",
    "                'o-', color=COLORS[strategy], label=strategy, linewidth=3, markersize=10)\n",
    "\n",
    "    ax.set_xlabel('Sparsity (%)', fontweight='bold')\n",
    "    ax.set_ylabel('MAE', fontweight='bold')\n",
    "    ax.set_title('LSTM: Mean Absolute Error vs Sparsity Level', fontweight='bold')\n",
    "    ax.legend(frameon=True, fancybox=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/lstm_mae_vs_sparsity.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_lstm_macs_analysis(lstm_df, output_dir):\n",
    "    \"\"\"Plot LSTM MACs behavior (special analysis)\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    for strategy in sorted(lstm_df['strategy'].unique()):\n",
    "        data = lstm_df[lstm_df['strategy'] == strategy].sort_values('sparsity')\n",
    "        ax.plot(data['sparsity_percent'], data['macs'] / 1000,\n",
    "                'o-', color=COLORS[strategy], label=strategy, linewidth=3, markersize=10)\n",
    "\n",
    "    ax.set_xlabel('Sparsity (%)', fontweight='bold')\n",
    "    ax.set_ylabel('MACs (Thousands)', fontweight='bold')\n",
    "    ax.set_title('LSTM: Minimal MACs Reduction Despite Pruning', fontweight='bold')\n",
    "    ax.legend(frameon=True, fancybox=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/lstm_macs_analysis.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# Section 5.4.3: Time-Series Models Comparison\n",
    "# ============================================================================\n",
    "\n",
    "def plot_timeseries_mse_comparison(mlp_df, lstm_df, output_dir):\n",
    "    \"\"\"Compare MLP vs LSTM MSE performance\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # Use MagnitudeL2 strategy for comparison\n",
    "    mlp_data = mlp_df[mlp_df['strategy'] == 'MagnitudeL2'].sort_values('sparsity')\n",
    "    lstm_data = lstm_df[lstm_df['strategy'] == 'MagnitudeL2'].sort_values('sparsity')\n",
    "\n",
    "    ax.plot(mlp_data['sparsity_percent'], mlp_data['mse'],\n",
    "            'o-', color=COLORS['MLP'], label='MLP', linewidth=3, markersize=10)\n",
    "    ax.plot(lstm_data['sparsity_percent'], lstm_data['mse'],\n",
    "            'o-', color=COLORS['LSTM'], label='LSTM', linewidth=3, markersize=10)\n",
    "\n",
    "    ax.set_xlabel('Sparsity (%)', fontweight='bold')\n",
    "    ax.set_ylabel('MSE', fontweight='bold')\n",
    "    ax.set_title('Time-Series Models: MSE Comparison (MagnitudeL2 Pruning)', fontweight='bold')\n",
    "    ax.legend(frameon=True, fancybox=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/timeseries_mse_comparison.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_timeseries_params_comparison(mlp_df, lstm_df, output_dir):\n",
    "    \"\"\"Compare parameter reduction between MLP and LSTM\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # Calculate parameter reduction\n",
    "    mlp_baseline = mlp_df[mlp_df['sparsity'] == 0.0]['params'].iloc[0]\n",
    "    lstm_baseline = lstm_df[lstm_df['sparsity'] == 0.0]['params'].iloc[0]\n",
    "\n",
    "    mlp_data = mlp_df[mlp_df['strategy'] == 'MagnitudeL2'].sort_values('sparsity')\n",
    "    lstm_data = lstm_df[lstm_df['strategy'] == 'MagnitudeL2'].sort_values('sparsity')\n",
    "\n",
    "    mlp_reduction = (1 - mlp_data['params'] / mlp_baseline) * 100\n",
    "    lstm_reduction = (1 - lstm_data['params'] / lstm_baseline) * 100\n",
    "\n",
    "    ax.plot(mlp_data['sparsity_percent'], mlp_reduction,\n",
    "            'o-', color=COLORS['MLP'], label='MLP', linewidth=3, markersize=10)\n",
    "    ax.plot(lstm_data['sparsity_percent'], lstm_reduction,\n",
    "            'o-', color=COLORS['LSTM'], label='LSTM', linewidth=3, markersize=10)\n",
    "\n",
    "    ax.set_xlabel('Sparsity (%)', fontweight='bold')\n",
    "    ax.set_ylabel('Parameter Reduction (%)', fontweight='bold')\n",
    "    ax.set_title('Time-Series Models: Parameter Reduction Comparison', fontweight='bold')\n",
    "    ax.legend(frameon=True, fancybox=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/timeseries_params_comparison.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# Section 5.5: Cross-Architecture Analysis\n",
    "# ============================================================================\n",
    "\n",
    "def plot_strategy_effectiveness_comparison(mobilenet_df, resnet_df, mlp_df, lstm_df, output_dir):\n",
    "    \"\"\"Compare strategy effectiveness across all architectures at 50% sparsity\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "    models = ['MobileNetV2', 'ResNet-18', 'MLP', 'LSTM']\n",
    "    strategies = ['MagnitudeL2', 'Random']\n",
    "\n",
    "    # Prepare data for 50% sparsity\n",
    "    data_50 = {\n",
    "        'MobileNetV2': mobilenet_df[mobilenet_df['sparsity'] == 0.5],\n",
    "        'ResNet-18': resnet_df[resnet_df['sparsity'] == 0.5],\n",
    "        'MLP': mlp_df[mlp_df['sparsity'] == 0.5],\n",
    "        'LSTM': lstm_df[lstm_df['sparsity'] == 0.5]\n",
    "    }\n",
    "\n",
    "    baselines = {\n",
    "        'MobileNetV2': mobilenet_df[mobilenet_df['sparsity'] == 0.0],\n",
    "        'ResNet-18': resnet_df[resnet_df['sparsity'] == 0.0],\n",
    "        'MLP': mlp_df[mlp_df['sparsity'] == 0.0],\n",
    "        'LSTM': lstm_df[lstm_df['sparsity'] == 0.0]\n",
    "    }\n",
    "\n",
    "    x = np.arange(len(models))\n",
    "    width = 0.35\n",
    "\n",
    "    retention_magnitudeL2 = []\n",
    "    retention_random = []\n",
    "\n",
    "    for model in models:\n",
    "        baseline_data = baselines[model]\n",
    "        pruned_data = data_50[model]\n",
    "\n",
    "        if model in ['MobileNetV2', 'ResNet-18']:\n",
    "            # For classification (higher is better)\n",
    "            baseline_perf = baseline_data[baseline_data['strategy'] == 'MagnitudeL2']['accuracy'].values[0]\n",
    "            mag_perf = pruned_data[pruned_data['strategy'] == 'MagnitudeL2']['accuracy'].values[0]\n",
    "            rand_perf = pruned_data[pruned_data['strategy'] == 'Random']['accuracy'].values[0]\n",
    "\n",
    "            retention_magnitudeL2.append((mag_perf / baseline_perf) * 100)\n",
    "            retention_random.append((rand_perf / baseline_perf) * 100)\n",
    "        else:\n",
    "            # For regression (lower is better, so inverse)\n",
    "            baseline_perf = baseline_data[baseline_data['strategy'] == 'MagnitudeL2']['mse'].values[0]\n",
    "            mag_perf = pruned_data[pruned_data['strategy'] == 'MagnitudeL2']['mse'].values[0]\n",
    "            rand_perf = pruned_data[pruned_data['strategy'] == 'Random']['mse'].values[0]\n",
    "\n",
    "            retention_magnitudeL2.append((baseline_perf / mag_perf) * 100)\n",
    "            retention_random.append((baseline_perf / rand_perf) * 100)\n",
    "\n",
    "    bars1 = ax.bar(x - width/2, retention_magnitudeL2, width,\n",
    "                   label='MagnitudeL2', color=COLORS['MagnitudeL2'], alpha=0.8)\n",
    "    bars2 = ax.bar(x + width/2, retention_random, width,\n",
    "                   label='Random', color=COLORS['Random'], alpha=0.8)\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                   f'{height:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "    ax.set_xlabel('Model Architecture', fontweight='bold')\n",
    "    ax.set_ylabel('Performance Retention (%)', fontweight='bold')\n",
    "    ax.set_title('Strategy Effectiveness Comparison at 50% Sparsity', fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models)\n",
    "    ax.legend(frameon=True, fancybox=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    ax.axhline(y=100, color='black', linestyle='--', alpha=0.5, linewidth=2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/strategy_effectiveness_comparison.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_model_size_comparison(mobilenet_df, resnet_df, mlp_df, lstm_df, output_dir):\n",
    "    \"\"\"Compare model sizes across architectures\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "    models = ['MobileNetV2', 'ResNet-18', 'MLP', 'LSTM']\n",
    "    sparsity_levels = [0.0, 0.2, 0.5, 0.7]\n",
    "\n",
    "    data_dict = {\n",
    "        'MobileNetV2': mobilenet_df,\n",
    "        'ResNet-18': resnet_df,\n",
    "        'MLP': mlp_df,\n",
    "        'LSTM': lstm_df\n",
    "    }\n",
    "\n",
    "    x = np.arange(len(models))\n",
    "    width = 0.2\n",
    "\n",
    "    for i, sparsity in enumerate(sparsity_levels):\n",
    "        sizes = []\n",
    "        for model in models:\n",
    "            df = data_dict[model]\n",
    "            size = df[(df['strategy'] == 'MagnitudeL2') &\n",
    "                     (df['sparsity'] == sparsity)]['size_mb'].values[0]\n",
    "            sizes.append(size)\n",
    "\n",
    "        bars = ax.bar(x + i*width, sizes, width,\n",
    "                      label=f'{int(sparsity*100)}% Sparsity', alpha=0.8)\n",
    "\n",
    "        # Add value labels on bars\n",
    "        for bar, size in zip(bars, sizes):\n",
    "            height = bar.get_height()\n",
    "            if height > 1:\n",
    "                label = f'{size:.1f}'\n",
    "            else:\n",
    "                label = f'{size:.2f}'\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                   label, ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
    "\n",
    "    ax.set_xlabel('Model Architecture', fontweight='bold')\n",
    "    ax.set_ylabel('Model Size (MB)', fontweight='bold')\n",
    "    ax.set_title('Model Size Reduction Across Architectures (MagnitudeL2 Pruning)', fontweight='bold')\n",
    "    ax.set_xticks(x + width * 1.5)\n",
    "    ax.set_xticklabels(models)\n",
    "    ax.legend(frameon=True, fancybox=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/model_size_comparison.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_macs_comparison_all_models(mobilenet_df, resnet_df, mlp_df, lstm_df, output_dir):\n",
    "    \"\"\"Compare MACs across all models\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    models_data = [\n",
    "        (mobilenet_df, 'MobileNetV2', COLORS['MobileNetV2']),\n",
    "        (resnet_df, 'ResNet-18', COLORS['ResNet-18']),\n",
    "        (mlp_df, 'MLP', COLORS['MLP']),\n",
    "        (lstm_df, 'LSTM', COLORS['LSTM'])\n",
    "    ]\n",
    "\n",
    "    for df, model_name, color in models_data:\n",
    "        data = df[df['strategy'] == 'MagnitudeL2'].sort_values('sparsity')\n",
    "        baseline_macs = data[data['sparsity'] == 0.0]['macs'].values[0]\n",
    "\n",
    "        # Calculate percentage of MACs retained\n",
    "        macs_retained = (data['macs'] / baseline_macs) * 100\n",
    "\n",
    "        ax.plot(data['sparsity_percent'], macs_retained, 'o-',\n",
    "               color=color, label=model_name, linewidth=3, markersize=10)\n",
    "\n",
    "    ax.set_xlabel('Sparsity (%)', fontweight='bold')\n",
    "    ax.set_ylabel('MACs Retained (%)', fontweight='bold')\n",
    "    ax.set_title('Computational Cost Reduction Across All Models (MagnitudeL2 Pruning)', fontweight='bold')\n",
    "    ax.legend(frameon=True, fancybox=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim(0, 105)\n",
    "\n",
    "    # Add reference lines\n",
    "    ax.axhline(y=50, color='gray', linestyle=':', alpha=0.5, linewidth=2)\n",
    "    ax.text(35, 52, '50% MACs', fontsize=14, color='gray', fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/macs_comparison_all_models.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# Section 5.7: Detailed Results Analysis - Heatmaps\n",
    "# ============================================================================\n",
    "\n",
    "def plot_mobilenetv2_strategy_heatmap(mobilenet_df, output_dir):\n",
    "    \"\"\"Create strategy comparison heatmap for MobileNetV2\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    pivot_data = mobilenet_df.pivot(index='strategy', columns='sparsity_percent', values='accuracy')\n",
    "    baseline = pivot_data[0.0]\n",
    "    normalized = (pivot_data.T / baseline * 100).T\n",
    "\n",
    "    sns.heatmap(normalized, annot=True, fmt='.1f', cmap='RdYlGn',\n",
    "                center=100, ax=ax, cbar_kws={'label': 'Relative Accuracy (%)'})\n",
    "    ax.set_title('MobileNetV2: Relative Accuracy Heatmap', fontweight='bold')\n",
    "    ax.set_xlabel('Sparsity (%)', fontweight='bold')\n",
    "    ax.set_ylabel('Pruning Strategy', fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/mobilenetv2_strategy_heatmap.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_resnet18_strategy_heatmap(resnet_df, output_dir):\n",
    "    \"\"\"Create strategy comparison heatmap for ResNet-18\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    pivot_data = resnet_df.pivot(index='strategy', columns='sparsity_percent', values='accuracy')\n",
    "    baseline = pivot_data[0.0]\n",
    "    normalized = (pivot_data.T / baseline * 100).T\n",
    "\n",
    "    sns.heatmap(normalized, annot=True, fmt='.1f', cmap='RdYlGn',\n",
    "                center=100, ax=ax, cbar_kws={'label': 'Relative Accuracy (%)'})\n",
    "    ax.set_title('ResNet-18: Relative Accuracy Heatmap', fontweight='bold')\n",
    "    ax.set_xlabel('Sparsity (%)', fontweight='bold')\n",
    "    ax.set_ylabel('Pruning Strategy', fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/resnet18_strategy_heatmap.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_mlp_strategy_heatmap(mlp_df, output_dir):\n",
    "    \"\"\"Create strategy comparison heatmap for MLP\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    pivot_data = mlp_df.pivot(index='strategy', columns='sparsity_percent', values='mse')\n",
    "    baseline = pivot_data[0.0]\n",
    "    normalized = ((pivot_data.T / baseline - 1) * 100).T\n",
    "\n",
    "    sns.heatmap(normalized, annot=True, fmt='.1f', cmap='RdYlGn_r',\n",
    "                center=0, ax=ax, cbar_kws={'label': 'MSE Increase (%)'})\n",
    "    ax.set_title('MLP: MSE Increase Heatmap', fontweight='bold')\n",
    "    ax.set_xlabel('Sparsity (%)', fontweight='bold')\n",
    "    ax.set_ylabel('Pruning Strategy', fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/mlp_strategy_heatmap.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_lstm_strategy_heatmap(lstm_df, output_dir):\n",
    "    \"\"\"Create strategy comparison heatmap for LSTM\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    pivot_data = lstm_df.pivot(index='strategy', columns='sparsity_percent', values='mse')\n",
    "    baseline = pivot_data[0.0]\n",
    "    normalized = ((pivot_data.T / baseline - 1) * 100).T\n",
    "\n",
    "    sns.heatmap(normalized, annot=True, fmt='.1f', cmap='RdYlGn_r',\n",
    "                center=0, ax=ax, cbar_kws={'label': 'MSE Increase (%)'})\n",
    "    ax.set_title('LSTM: MSE Increase Heatmap', fontweight='bold')\n",
    "    ax.set_xlabel('Sparsity (%)', fontweight='bold')\n",
    "    ax.set_ylabel('Pruning Strategy', fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/lstm_strategy_heatmap.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# Section 5.9: Summary Analysis\n",
    "# ============================================================================\n",
    "\n",
    "def create_performance_summary_table(mobilenet_df, resnet_df, mlp_df, lstm_df, output_dir):\n",
    "    \"\"\"Create comprehensive summary table\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(16, 12))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Prepare data for table - show results at multiple sparsity levels\n",
    "    table_data = []\n",
    "    headers = ['Model', 'Strategy', 'Sparsity', 'Baseline', 'Pruned', 'Retention (%)',\n",
    "               'MACs Red. (%)', 'Size Red. (%)']\n",
    "\n",
    "    sparsity_levels = [0.2, 0.5, 0.7]\n",
    "\n",
    "    for df, model_name, metric in [(mobilenet_df, 'MobileNetV2', 'accuracy'),\n",
    "                                   (resnet_df, 'ResNet-18', 'accuracy'),\n",
    "                                   (mlp_df, 'MLP', 'mse'),\n",
    "                                   (lstm_df, 'LSTM', 'mse')]:\n",
    "\n",
    "        for strategy in ['MagnitudeL2', 'Random']:\n",
    "            if strategy not in df['strategy'].unique():\n",
    "                continue\n",
    "\n",
    "            baseline = df[(df['strategy'] == strategy) & (df['sparsity'] == 0.0)].iloc[0]\n",
    "\n",
    "            for sparsity in sparsity_levels:\n",
    "                pruned = df[(df['strategy'] == strategy) & (df['sparsity'] == sparsity)].iloc[0]\n",
    "\n",
    "                if metric == 'accuracy':\n",
    "                    baseline_perf = f\"{baseline['accuracy']:.2f}%\"\n",
    "                    pruned_perf = f\"{pruned['accuracy']:.2f}%\"\n",
    "                    retention = (pruned['accuracy'] / baseline['accuracy']) * 100\n",
    "                else:  # MSE\n",
    "                    baseline_perf = f\"{baseline['mse']:.2f}\"\n",
    "                    pruned_perf = f\"{pruned['mse']:.2f}\"\n",
    "                    retention = (baseline['mse'] / pruned['mse']) * 100\n",
    "\n",
    "                macs_reduction = (1 - pruned['macs'] / baseline['macs']) * 100\n",
    "                size_reduction = (1 - pruned['size_mb'] / baseline['size_mb']) * 100\n",
    "\n",
    "                table_data.append([\n",
    "                    model_name,\n",
    "                    strategy,\n",
    "                    f\"{int(sparsity*100)}%\",\n",
    "                    baseline_perf,\n",
    "                    pruned_perf,\n",
    "                    f\"{retention:.1f}\",\n",
    "                    f\"{macs_reduction:.1f}\",\n",
    "                    f\"{size_reduction:.1f}\"\n",
    "                ])\n",
    "\n",
    "    # Create table\n",
    "    table = ax.table(cellText=table_data, colLabels=headers,\n",
    "                    cellLoc='center', loc='center',\n",
    "                    colWidths=[0.12, 0.12, 0.08, 0.12, 0.12, 0.12, 0.12, 0.12])\n",
    "\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1.2, 1.8)\n",
    "\n",
    "    # Style the table\n",
    "    for i in range(len(headers)):\n",
    "        table[(0, i)].set_facecolor('#4CAF50')\n",
    "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "    # Alternate row colors\n",
    "    for i in range(1, len(table_data) + 1):\n",
    "        if i % 2 == 0:\n",
    "            for j in range(len(headers)):\n",
    "                table[(i, j)].set_facecolor('#f0f0f0')\n",
    "\n",
    "    plt.title('Comprehensive Performance Summary Across All Models and Sparsity Levels',\n",
    "             fontsize=18, fontweight='bold', pad=20)\n",
    "    plt.savefig(f'{output_dir}/performance_summary_table.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_optimal_points_analysis(mobilenet_df, resnet_df, mlp_df, lstm_df, output_dir):\n",
    "    \"\"\"Identify and plot optimal operating points for each model\"\"\"\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    # MobileNetV2\n",
    "    mobilenet_data = mobilenet_df[mobilenet_df['strategy'] == 'MagnitudeL2'].sort_values('macs_millions')\n",
    "    ax1.scatter(mobilenet_data['macs_millions'], mobilenet_data['accuracy'],\n",
    "               color=COLORS['MobileNetV2'], s=150, alpha=0.8, edgecolors='black', linewidth=1.5)\n",
    "    ax1.plot(mobilenet_data['macs_millions'], mobilenet_data['accuracy'],\n",
    "            color=COLORS['MobileNetV2'], linestyle='--', alpha=0.7, linewidth=2)\n",
    "    ax1.set_xlabel('MACs (Millions)', fontweight='bold')\n",
    "    ax1.set_ylabel('Accuracy (%)', fontweight='bold')\n",
    "    ax1.set_title('MobileNetV2: Optimal Operating Points', fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # ResNet-18\n",
    "    resnet_data = resnet_df[resnet_df['strategy'] == 'MagnitudeL2'].sort_values('macs_millions')\n",
    "    ax2.scatter(resnet_data['macs_millions'], resnet_data['accuracy'],\n",
    "               color=COLORS['ResNet-18'], s=150, alpha=0.8, edgecolors='black', linewidth=1.5)\n",
    "    ax2.plot(resnet_data['macs_millions'], resnet_data['accuracy'],\n",
    "            color=COLORS['ResNet-18'], linestyle='--', alpha=0.7, linewidth=2)\n",
    "    ax2.set_xlabel('MACs (Millions)', fontweight='bold')\n",
    "    ax2.set_ylabel('Accuracy (%)', fontweight='bold')\n",
    "    ax2.set_title('ResNet-18: Optimal Operating Points', fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    # MLP\n",
    "    mlp_data = mlp_df[mlp_df['strategy'] == 'MagnitudeL2'].sort_values('macs')\n",
    "    ax3.scatter(mlp_data['macs'] / 1000, mlp_data['mse'],\n",
    "               color=COLORS['MLP'], s=150, alpha=0.8, edgecolors='black', linewidth=1.5)\n",
    "    ax3.plot(mlp_data['macs'] / 1000, mlp_data['mse'],\n",
    "            color=COLORS['MLP'], linestyle='--', alpha=0.7, linewidth=2)\n",
    "    ax3.set_xlabel('MACs (Thousands)', fontweight='bold')\n",
    "    ax3.set_ylabel('MSE', fontweight='bold')\n",
    "    ax3.set_title('MLP: Optimal Operating Points', fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "\n",
    "    # LSTM\n",
    "    lstm_data = lstm_df[lstm_df['strategy'] == 'MagnitudeL2'].sort_values('macs')\n",
    "    ax4.scatter(lstm_data['macs'] / 1000, lstm_data['mse'],\n",
    "               color=COLORS['LSTM'], s=150, alpha=0.8, edgecolors='black', linewidth=1.5)\n",
    "    ax4.plot(lstm_data['macs'] / 1000, lstm_data['mse'],\n",
    "            color=COLORS['LSTM'], linestyle='--', alpha=0.7, linewidth=2)\n",
    "    ax4.set_xlabel('MACs (Thousands)', fontweight='bold')\n",
    "    ax4.set_ylabel('MSE', fontweight='bold')\n",
    "    ax4.set_title('LSTM: Optimal Operating Points', fontweight='bold')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/optimal_points_analysis.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# Main execution function\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Generate all plots for Chapter 5\"\"\"\n",
    "    print(\"Generating Chapter 5 plots...\")\n",
    "\n",
    "    # Load data\n",
    "    mobilenet_results, resnet_results, mlp_results, lstm_results = load_all_results()\n",
    "\n",
    "    if any(x is None for x in [mobilenet_results, resnet_results, mlp_results, lstm_results]):\n",
    "        print(\"Error: Could not load all result files. Please check file names and paths.\")\n",
    "        return\n",
    "\n",
    "    # Convert to DataFrames\n",
    "    mobilenet_df = results_to_dataframe(mobilenet_results, 'MobileNetV2', 'classification')\n",
    "    resnet_df = results_to_dataframe(resnet_results, 'ResNet-18', 'classification')\n",
    "    mlp_df = results_to_dataframe(mlp_results, 'MLP', 'regression')\n",
    "    lstm_df = results_to_dataframe(lstm_results, 'LSTM', 'regression')\n",
    "\n",
    "    # Create output directory\n",
    "    output_dir = create_output_directory()\n",
    "\n",
    "    print(f\"Saving plots to: {output_dir}\")\n",
    "\n",
    "    # Section 5.3.1: MobileNetV2 Analysis\n",
    "    print(\"Generating MobileNetV2 plots...\")\n",
    "    plot_mobilenetv2_accuracy_vs_sparsity(mobilenet_df, output_dir)\n",
    "    plot_mobilenetv2_macs_reduction(mobilenet_df, output_dir)\n",
    "    plot_mobilenetv2_size_reduction(mobilenet_df, output_dir)\n",
    "    plot_mobilenetv2_pareto_frontier(mobilenet_df, output_dir)\n",
    "\n",
    "    # Section 5.3.2: ResNet-18 Analysis\n",
    "    print(\"Generating ResNet-18 plots...\")\n",
    "    plot_resnet18_accuracy_vs_sparsity(resnet_df, output_dir)\n",
    "    plot_resnet18_macs_reduction(resnet_df, output_dir)\n",
    "    plot_resnet18_pareto_frontier(resnet_df, output_dir)\n",
    "\n",
    "    # Section 5.3.3: CNN Comparison\n",
    "    print(\"Generating CNN comparison plots...\")\n",
    "    plot_cnn_accuracy_comparison(mobilenet_df, resnet_df, output_dir)\n",
    "    plot_cnn_efficiency_comparison(mobilenet_df, resnet_df, output_dir)\n",
    "\n",
    "    # Section 5.4.1: MLP Analysis\n",
    "    print(\"Generating MLP plots...\")\n",
    "    plot_mlp_mse_vs_sparsity(mlp_df, output_dir)\n",
    "    plot_mlp_mae_vs_sparsity(mlp_df, output_dir)\n",
    "    plot_mlp_macs_reduction(mlp_df, output_dir)\n",
    "\n",
    "    # Section 5.4.2: LSTM Analysis\n",
    "    print(\"Generating LSTM plots...\")\n",
    "    plot_lstm_mse_vs_sparsity(lstm_df, output_dir)\n",
    "    plot_lstm_mae_vs_sparsity(lstm_df, output_dir)\n",
    "    plot_lstm_macs_analysis(lstm_df, output_dir)\n",
    "\n",
    "    # Section 5.4.3: Time-series Comparison\n",
    "    print(\"Generating time-series comparison plots...\")\n",
    "    plot_timeseries_mse_comparison(mlp_df, lstm_df, output_dir)\n",
    "    plot_timeseries_params_comparison(mlp_df, lstm_df, output_dir)\n",
    "\n",
    "    # Section 5.5: Cross-Architecture Analysis\n",
    "    print(\"Generating cross-architecture plots...\")\n",
    "    plot_strategy_effectiveness_comparison(mobilenet_df, resnet_df, mlp_df, lstm_df, output_dir)\n",
    "    plot_model_size_comparison(mobilenet_df, resnet_df, mlp_df, lstm_df, output_dir)\n",
    "    plot_macs_comparison_all_models(mobilenet_df, resnet_df, mlp_df, lstm_df, output_dir)\n",
    "\n",
    "    # Section 5.7: Heatmaps\n",
    "    print(\"Generating strategy heatmaps...\")\n",
    "    plot_mobilenetv2_strategy_heatmap(mobilenet_df, output_dir)\n",
    "    plot_resnet18_strategy_heatmap(resnet_df, output_dir)\n",
    "    plot_mlp_strategy_heatmap(mlp_df, output_dir)\n",
    "    plot_lstm_strategy_heatmap(lstm_df, output_dir)\n",
    "\n",
    "    # Section 5.9: Summary Analysis\n",
    "    print(\"Generating summary plots...\")\n",
    "    create_performance_summary_table(mobilenet_df, resnet_df, mlp_df, lstm_df, output_dir)\n",
    "    plot_optimal_points_analysis(mobilenet_df, resnet_df, mlp_df, lstm_df, output_dir)\n",
    "\n",
    "    print(f\"\\n‚úÖ All plots generated successfully!\")\n",
    "    print(f\"üìÅ Total plots created: 26\")\n",
    "    print(f\"üìÅ Saved to directory: {os.path.abspath(output_dir)}\")\n",
    "\n",
    "    # Print summary of generated plots\n",
    "    plot_files = [f for f in os.listdir(output_dir) if f.endswith('.png')]\n",
    "    print(f\"\\nGenerated plots:\")\n",
    "    for i, plot_file in enumerate(sorted(plot_files), 1):\n",
    "        print(f\"{i:2d}. {plot_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "b3ed553e8c51f504",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Chapter 5 plots...\n",
      "Saving plots to: chapter5_plots\n",
      "Generating MobileNetV2 plots...\n",
      "Generating ResNet-18 plots...\n",
      "Generating CNN comparison plots...\n",
      "Generating MLP plots...\n",
      "Generating LSTM plots...\n",
      "Generating time-series comparison plots...\n",
      "Generating cross-architecture plots...\n",
      "Generating strategy heatmaps...\n",
      "Generating summary plots...\n",
      "\n",
      "‚úÖ All plots generated successfully!\n",
      "üìÅ Total plots created: 26\n",
      "üìÅ Saved to directory: /home/muis/thesis/github-repo/master-thesis/utils/chapter5_plots\n",
      "\n",
      "Generated plots:\n",
      " 1. cnn_accuracy_comparison.png\n",
      " 2. cnn_efficiency_comparison.png\n",
      " 3. lstm_macs_analysis.png\n",
      " 4. lstm_mae_vs_sparsity.png\n",
      " 5. lstm_mse_vs_sparsity.png\n",
      " 6. lstm_strategy_heatmap.png\n",
      " 7. macs_comparison_all_models.png\n",
      " 8. mlp_macs_reduction.png\n",
      " 9. mlp_mae_vs_sparsity.png\n",
      "10. mlp_mse_vs_sparsity.png\n",
      "11. mlp_strategy_heatmap.png\n",
      "12. mobilenetv2_accuracy_vs_sparsity.png\n",
      "13. mobilenetv2_macs_reduction.png\n",
      "14. mobilenetv2_pareto_frontier.png\n",
      "15. mobilenetv2_size_reduction.png\n",
      "16. mobilenetv2_strategy_heatmap.png\n",
      "17. model_size_comparison.png\n",
      "18. optimal_points_analysis.png\n",
      "19. performance_summary_table.png\n",
      "20. resnet18_accuracy_vs_sparsity.png\n",
      "21. resnet18_macs_reduction.png\n",
      "22. resnet18_pareto_frontier.png\n",
      "23. resnet18_strategy_heatmap.png\n",
      "24. strategy_effectiveness_comparison.png\n",
      "25. timeseries_mse_comparison.png\n",
      "26. timeseries_params_comparison.png\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
