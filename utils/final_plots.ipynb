{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T21:47:21.121228Z",
     "start_time": "2025-06-04T21:47:13.206355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# --- Configuration ---\n",
    "OUTPUT_DIR = \"thesis_plots_v2\" # Changed output dir name to avoid overwriting\n",
    "FIG_SIZE = (10, 6) # Adjusted figure size for potentially more complex plots\n",
    "FONT_SIZE = 12\n",
    "TITLE_FONT_SIZE = 14\n",
    "LINE_WIDTH = 2\n",
    "MARKER_SIZE = 6\n",
    "\n",
    "# Consistent colors for pruning methods\n",
    "METHOD_COLORS = {\n",
    "    \"BNScale\": \"royalblue\",\n",
    "    \"MagnitudeL2\": \"darkorange\",\n",
    "    \"Random\": \"forestgreen\"\n",
    "}\n",
    "METHOD_MARKERS = {\n",
    "    \"BNScale\": \"o\",\n",
    "    \"MagnitudeL2\": \"s\",\n",
    "    \"Random\": \"^\"\n",
    "}\n",
    "\n",
    "# Linestyles for models within comparative plots\n",
    "MODEL_LINESTYLES = {\n",
    "    \"MobileNetV2\": \"-\",  # Solid\n",
    "    \"ResNet18\": \"--\", # Dashed\n",
    "    \"LSTM\": \":\",   # Dotted\n",
    "    \"MLP\": \"-.\"   # Dash-dot\n",
    "}\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "# Set global plot styles\n",
    "plt.rcParams.update({'font.size': FONT_SIZE})\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# --- Helper Function to Load JSON ---\n",
    "def load_json_data(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# --- Individual Model Plotting Function (from previous response, slightly adapted) ---\n",
    "def plot_individual_model_metric(\n",
    "    model_data,\n",
    "    model_name_display,\n",
    "    model_name_file,\n",
    "    metric_key,\n",
    "    y_label,\n",
    "    is_higher_better=True,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    log_scale_y=False,\n",
    "    y_multiplier=1.0,\n",
    "    y_unit_prefix=\"\"\n",
    "):\n",
    "    plt.figure(figsize=FIG_SIZE)\n",
    "\n",
    "    all_pruning_ratios_str = set()\n",
    "    # Ensure all methods are checked for available pruning ratios\n",
    "    for method_name_iter, method_data_iter in model_data.items():\n",
    "        if isinstance(method_data_iter, dict): # Check if method_data_iter is a dictionary of ratios\n",
    "            all_pruning_ratios_str.update(method_data_iter.keys())\n",
    "\n",
    "    pruning_ratios_str_sorted = []\n",
    "    if \"0.0\" in all_pruning_ratios_str:\n",
    "        pruning_ratios_str_sorted.append(\"0.0\")\n",
    "        all_pruning_ratios_str.remove(\"0.0\")\n",
    "\n",
    "    pruning_ratios_str_sorted.extend(sorted(list(all_pruning_ratios_str), key=float))\n",
    "    pruning_ratios_numeric = [float(r) for r in pruning_ratios_str_sorted]\n",
    "\n",
    "    for method_name, results in model_data.items():\n",
    "        if method_name not in METHOD_COLORS:\n",
    "            print(f\"Warning: Method '{method_name}' not in METHOD_COLORS for individual plot: {y_label} of {model_name_display}\")\n",
    "            continue\n",
    "\n",
    "        current_metric_values = []\n",
    "        current_ratios_numeric = []\n",
    "\n",
    "        for r_str in pruning_ratios_str_sorted:\n",
    "            if r_str in results and metric_key in results[r_str]:\n",
    "                try:\n",
    "                    value = float(results[r_str][metric_key]) * y_multiplier\n",
    "                    current_metric_values.append(value)\n",
    "                    current_ratios_numeric.append(float(r_str))\n",
    "                except (TypeError, ValueError) as e:\n",
    "                    print(f\"Warning: Could not convert metric '{metric_key}' for {model_name_display}, {method_name} at ratio {r_str}. Error: {e}. Value: {results[r_str].get(metric_key)}\")\n",
    "                    current_metric_values.append(np.nan)\n",
    "                    current_ratios_numeric.append(float(r_str))\n",
    "            else:\n",
    "                current_metric_values.append(np.nan)\n",
    "                current_ratios_numeric.append(float(r_str))\n",
    "\n",
    "        plt.plot(\n",
    "            current_ratios_numeric,\n",
    "            current_metric_values,\n",
    "            label=method_name,\n",
    "            color=METHOD_COLORS[method_name],\n",
    "            marker=METHOD_MARKERS[method_name],\n",
    "            linewidth=LINE_WIDTH,\n",
    "            markersize=MARKER_SIZE\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Pruning Ratio\")\n",
    "    plt.ylabel(f\"{y_label}{' (' + y_unit_prefix + ')' if y_unit_prefix else ''}\")\n",
    "    plt.title(f\"{y_label} vs. Pruning Ratio for {model_name_display}\", fontsize=TITLE_FONT_SIZE)\n",
    "    plt.xticks(pruning_ratios_numeric, labels=[str(r) for r in pruning_ratios_numeric])\n",
    "\n",
    "    if log_scale_y:\n",
    "        plt.yscale('log')\n",
    "\n",
    "    plt.legend(title=\"Pruning Method\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    filename = f\"individual_{model_name_file}_{metric_key.lower()}_vs_pruning.png\"\n",
    "    plt.savefig(os.path.join(output_dir, filename), dpi=300)\n",
    "    print(f\"Saved: {filename}\")\n",
    "    plt.close()\n",
    "\n",
    "# --- Comparative Plotting Function ---\n",
    "def plot_comparative_group(\n",
    "    models_data_dict, # {\"ModelName1\": data1_dict, \"ModelName2\": data2_dict}\n",
    "    model_names_in_group_display, # list of display names for models\n",
    "    model_group_name_display,\n",
    "    model_group_name_file,\n",
    "    metric_key,\n",
    "    y_label,\n",
    "    is_higher_better=True,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    log_scale_y=False,\n",
    "    y_multiplier=1.0,\n",
    "    y_unit_prefix=\"\"\n",
    "):\n",
    "    plt.figure(figsize=FIG_SIZE)\n",
    "\n",
    "    # Determine common pruning ratios across all models and methods in the group\n",
    "    all_pruning_ratios_str = set()\n",
    "    for model_name_key in models_data_dict.keys():\n",
    "        model_data_iter = models_data_dict[model_name_key]\n",
    "        if model_data_iter: # if data was loaded for this model\n",
    "            for method_data_iter in model_data_iter.values():\n",
    "                if isinstance(method_data_iter, dict):\n",
    "                     all_pruning_ratios_str.update(method_data_iter.keys())\n",
    "\n",
    "    pruning_ratios_str_sorted = []\n",
    "    if \"0.0\" in all_pruning_ratios_str:\n",
    "        pruning_ratios_str_sorted.append(\"0.0\")\n",
    "        all_pruning_ratios_str.remove(\"0.0\")\n",
    "\n",
    "    pruning_ratios_str_sorted.extend(sorted(list(all_pruning_ratios_str), key=float))\n",
    "    pruning_ratios_numeric = [float(r) for r in pruning_ratios_str_sorted]\n",
    "\n",
    "    for model_name_key, model_data in models_data_dict.items():\n",
    "        if not model_data: continue # Skip if model data wasn't loaded\n",
    "\n",
    "        # Get the display name for the legend, default to key if not found\n",
    "        model_display_name = model_name_key\n",
    "        for name_obj in model_names_in_group_display:\n",
    "            if name_obj['key'] == model_name_key:\n",
    "                model_display_name = name_obj['display']\n",
    "                break\n",
    "\n",
    "        for method_name, results in model_data.items():\n",
    "            if method_name not in METHOD_COLORS:\n",
    "                print(f\"Warning: Method '{method_name}' for model '{model_display_name}' not in METHOD_COLORS for comparative plot. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            current_metric_values = []\n",
    "            current_ratios_numeric = [] # Ratios for this specific line, in case of missing points\n",
    "\n",
    "            for r_str in pruning_ratios_str_sorted:\n",
    "                if r_str in results and metric_key in results[r_str]:\n",
    "                    try:\n",
    "                        value = float(results[r_str][metric_key]) * y_multiplier\n",
    "                        current_metric_values.append(value)\n",
    "                        current_ratios_numeric.append(float(r_str))\n",
    "                    except (TypeError, ValueError) as e:\n",
    "                        print(f\"Warning: Could not convert metric '{metric_key}' for {model_display_name}, {method_name} at ratio {r_str}. Error: {e}. Value: {results[r_str].get(metric_key)}\")\n",
    "                        current_metric_values.append(np.nan)\n",
    "                        current_ratios_numeric.append(float(r_str))\n",
    "                else: # Data point missing for this ratio\n",
    "                    current_metric_values.append(np.nan)\n",
    "                    current_ratios_numeric.append(float(r_str))\n",
    "\n",
    "            plt.plot(\n",
    "                current_ratios_numeric,\n",
    "                current_metric_values,\n",
    "                label=f\"{model_display_name} - {method_name}\",\n",
    "                color=METHOD_COLORS[method_name],\n",
    "                linestyle=MODEL_LINESTYLES.get(model_name_key, \"-\"), # Use model key for linestyle lookup\n",
    "                marker=METHOD_MARKERS[method_name],\n",
    "                linewidth=LINE_WIDTH,\n",
    "                markersize=MARKER_SIZE\n",
    "            )\n",
    "\n",
    "    plt.xlabel(\"Pruning Ratio\")\n",
    "    plt.ylabel(f\"{y_label}{' (' + y_unit_prefix + ')' if y_unit_prefix else ''}\")\n",
    "    plt.title(f\"Comparison of {y_label} vs. Pruning Ratio for {model_group_name_display}\", fontsize=TITLE_FONT_SIZE)\n",
    "    plt.xticks(pruning_ratios_numeric, labels=[str(r) for r in pruning_ratios_numeric])\n",
    "\n",
    "    if log_scale_y:\n",
    "        plt.yscale('log')\n",
    "\n",
    "    # Place legend outside the plot\n",
    "    plt.legend(title=\"Model - Method\", bbox_to_anchor=(1.03, 1), loc='upper left', borderaxespad=0.)\n",
    "    plt.subplots_adjust(right=0.75) # Adjust subplot to make room for legend\n",
    "\n",
    "    filename = f\"comparative_{model_group_name_file}_{metric_key.lower()}_vs_pruning.png\"\n",
    "    plt.savefig(os.path.join(output_dir, filename), dpi=300)\n",
    "    print(f\"Saved: {filename}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# --- Main Script ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Define models and their data files\n",
    "    models_config = {\n",
    "        \"MobileNetV2\": {\n",
    "            \"file\": \"mobileNetV2_complete_results.json\",\n",
    "            \"display_name\": \"MobileNetV2\",\n",
    "            \"type\": \"CNN\",\n",
    "            \"metrics\": {\n",
    "                \"accuracy\": {\"label\": \"Accuracy (%)\", \"higher_better\": True},\n",
    "                \"params\": {\"label\": \"Parameters\", \"higher_better\": False, \"multiplier\": 1e-6, \"unit_prefix\": \"M\"},\n",
    "                \"macs\": {\"label\": \"MACs\", \"higher_better\": False, \"multiplier\": 1e-6, \"unit_prefix\": \"M\"},\n",
    "                \"size_mb\": {\"label\": \"Size (MB)\", \"higher_better\": False},\n",
    "                \"loss\": {\"label\": \"Loss\", \"higher_better\": False}\n",
    "            }\n",
    "        },\n",
    "        \"ResNet18\": {\n",
    "            \"file\": \"resnet18_complete_results.json\",\n",
    "            \"display_name\": \"ResNet-18\",\n",
    "            \"type\": \"CNN\",\n",
    "            \"metrics\": {\n",
    "                \"accuracy\": {\"label\": \"Accuracy (%)\", \"higher_better\": True},\n",
    "                \"params\": {\"label\": \"Parameters\", \"higher_better\": False, \"multiplier\": 1e-6, \"unit_prefix\": \"M\"},\n",
    "                \"macs\": {\"label\": \"MACs\", \"higher_better\": False, \"multiplier\": 1e-7, \"unit_prefix\": \"10M\"}, # MACs are large\n",
    "                \"size_mb\": {\"label\": \"Size (MB)\", \"higher_better\": False},\n",
    "                \"loss\": {\"label\": \"Loss\", \"higher_better\": False}\n",
    "            }\n",
    "        },\n",
    "        \"LSTM\": {\n",
    "            \"file\": \"lstm_complete_results.json\",\n",
    "            \"display_name\": \"LSTM\",\n",
    "            \"type\": \"TimeSeries\",\n",
    "            \"metrics\": {\n",
    "                \"mse\": {\"label\": \"Mean Squared Error (MSE)\", \"higher_better\": False},\n",
    "                \"mae\": {\"label\": \"Mean Absolute Error (MAE)\", \"higher_better\": False},\n",
    "                \"params\": {\"label\": \"Parameters\", \"higher_better\": False, \"multiplier\": 1e-3, \"unit_prefix\": \"K\"},\n",
    "                \"macs\": {\"label\": \"MACs\", \"higher_better\": False, \"multiplier\": 1e-6, \"unit_prefix\": \"M\"},\n",
    "                \"size_mb\": {\"label\": \"Size (MB)\", \"higher_better\": False},\n",
    "                \"loss\": {\"label\": \"Loss\", \"higher_better\": False}\n",
    "            }\n",
    "        },\n",
    "        \"MLP\": {\n",
    "            \"file\": \"mlp_complete_results.json\",\n",
    "            \"display_name\": \"MLP\",\n",
    "            \"type\": \"TimeSeries\", # Assuming used for a time-series like regression task\n",
    "            \"metrics\": {\n",
    "                \"mse\": {\"label\": \"Mean Squared Error (MSE)\", \"higher_better\": False},\n",
    "                \"mae\": {\"label\": \"Mean Absolute Error (MAE)\", \"higher_better\": False},\n",
    "                \"params\": {\"label\": \"Parameters\", \"higher_better\": False, \"multiplier\": 1e-3, \"unit_prefix\": \"K\"},\n",
    "                \"macs\": {\"label\": \"MACs\", \"higher_better\": False, \"multiplier\": 1e-3, \"unit_prefix\": \"K\"},\n",
    "                \"size_mb\": {\"label\": \"Size (MB)\", \"higher_better\": False},\n",
    "                \"loss\": {\"label\": \"Loss\", \"higher_better\": False}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Load all data\n",
    "    all_model_data_loaded = {}\n",
    "    for model_key, config in models_config.items():\n",
    "        try:\n",
    "            all_model_data_loaded[model_key] = load_json_data(config[\"file\"])\n",
    "        except FileNotFoundError:\n",
    "            print(f\"ERROR: Data file not found: {config['file']}. Skipping {config['display_name']}.\")\n",
    "            all_model_data_loaded[model_key] = None # Mark as None if file not found\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while loading {config['file']}: {e}\")\n",
    "            all_model_data_loaded[model_key] = None\n",
    "\n",
    "    # --- 1. Generate individual plots for each model ---\n",
    "    print(\"\\n--- Generating Individual Model Plots ---\")\n",
    "    for model_key, config in models_config.items():\n",
    "        model_data = all_model_data_loaded.get(model_key)\n",
    "        if model_data is None:\n",
    "            continue # Skip if data wasn't loaded\n",
    "\n",
    "        model_name_file = model_key.lower().replace('-', '')\n",
    "        for metric_key, metric_config in config[\"metrics\"].items():\n",
    "            plot_individual_model_metric(\n",
    "                model_data=model_data,\n",
    "                model_name_display=config[\"display_name\"],\n",
    "                model_name_file=model_name_file,\n",
    "                metric_key=metric_key,\n",
    "                y_label=metric_config[\"label\"],\n",
    "                is_higher_better=metric_config[\"higher_better\"],\n",
    "                y_multiplier=metric_config.get(\"multiplier\", 1.0),\n",
    "                y_unit_prefix=metric_config.get(\"unit_prefix\", \"\")\n",
    "            )\n",
    "\n",
    "    # --- 2. Generate Comparative CNN Plots ---\n",
    "    print(\"\\n--- Generating Comparative CNN Plots ---\")\n",
    "    cnn_model_keys = [k for k, v in models_config.items() if v[\"type\"] == \"CNN\"]\n",
    "    cnn_models_data_for_plot = {k: all_model_data_loaded[k] for k in cnn_model_keys if all_model_data_loaded.get(k)}\n",
    "\n",
    "    if len(cnn_models_data_for_plot) == len(cnn_model_keys) and cnn_model_keys: # Ensure all specified CNNs loaded\n",
    "        cnn_display_names_obj = [{'key': k, 'display': models_config[k]['display_name']} for k in cnn_model_keys]\n",
    "        # Define metrics for CNN comparison (can pick from one of the CNN cfgs)\n",
    "        ref_cnn_config = models_config[cnn_model_keys[0]]['metrics']\n",
    "        metrics_for_cnn_comparison = {\n",
    "            \"accuracy\": ref_cnn_config[\"accuracy\"],\n",
    "            \"params\": ref_cnn_config[\"params\"],\n",
    "            \"macs\": ref_cnn_config[\"macs\"], # Will use MobileNetV2's MACs settings here\n",
    "            \"size_mb\": ref_cnn_config[\"size_mb\"],\n",
    "        }\n",
    "        # Custom MACs config for ResNet18 for better Y-axis scaling in comparative plot\n",
    "        metrics_for_cnn_comparison[\"macs\"][\"multiplier_override\"] = {\n",
    "            \"MobileNetV2\": 1e-6, \"ResNet18\": 1e-7 # Example if ResNet18 MACs are an order larger\n",
    "        }\n",
    "        metrics_for_cnn_comparison[\"macs\"][\"unit_prefix_override\"] = {\n",
    "             \"MobileNetV2\": \"M\", \"ResNet18\": \"10M\"\n",
    "        }\n",
    "\n",
    "\n",
    "        for metric_key, base_metric_config in metrics_for_cnn_comparison.items():\n",
    "             # For MACs, we want specific scaling for ResNet-18 if defined, otherwise generic\n",
    "            y_multiplier = base_metric_config.get(\"multiplier\", 1.0)\n",
    "            y_unit_prefix = base_metric_config.get(\"unit_prefix\", \"\")\n",
    "            # No need for multiplier/unit_prefix override logic in comparative plots as it adds complexity.\n",
    "            # Simpler to pick one consistent scale for the comparative graph.\n",
    "            # Using MobileNetV2's typical scale for Parameters and MACs for the comparative plot.\n",
    "            # For resnet18, its MACs are higher, so you might manually adjust if one curve dominates the scale too much.\n",
    "            # The common y_label, y_multiplier, y_unit_prefix for a given comparative plot are key.\n",
    "\n",
    "            plot_comparative_group(\n",
    "                models_data_dict=cnn_models_data_for_plot,\n",
    "                model_names_in_group_display=cnn_display_names_obj,\n",
    "                model_group_name_display=\"CNNs\",\n",
    "                model_group_name_file=\"cnns\",\n",
    "                metric_key=metric_key,\n",
    "                y_label=base_metric_config[\"label\"],\n",
    "                is_higher_better=base_metric_config[\"higher_better\"],\n",
    "                # Use consistent multiplier for comparison, e.g., from MobileNetV2 or an average scale\n",
    "                y_multiplier=models_config[\"MobileNetV2\"][\"metrics\"][metric_key].get(\"multiplier\", 1.0),\n",
    "                y_unit_prefix=models_config[\"MobileNetV2\"][\"metrics\"][metric_key].get(\"unit_prefix\", \"\")\n",
    "            )\n",
    "    else:\n",
    "        print(\"Skipping comparative CNN plots as data for one or more CNN models is missing.\")\n",
    "\n",
    "    # --- 3. Generate Comparative Time-Series Plots (LSTM & MLP) ---\n",
    "    print(\"\\n--- Generating Comparative Time-Series Plots ---\")\n",
    "    ts_model_keys = [k for k, v in models_config.items() if v[\"type\"] == \"TimeSeries\"]\n",
    "    ts_models_data_for_plot = {k: all_model_data_loaded[k] for k in ts_model_keys if all_model_data_loaded.get(k)}\n",
    "\n",
    "    if len(ts_models_data_for_plot) == len(ts_model_keys) and ts_model_keys: # Ensure all specified TS models loaded\n",
    "        ts_display_names_obj = [{'key': k, 'display': models_config[k]['display_name']} for k in ts_model_keys]\n",
    "        ref_ts_config = models_config[ts_model_keys[0]]['metrics']\n",
    "        metrics_for_ts_comparison = {\n",
    "            \"mse\": ref_ts_config[\"mse\"],\n",
    "            \"mae\": ref_ts_config[\"mae\"],\n",
    "            \"params\": ref_ts_config[\"params\"],\n",
    "            \"macs\": ref_ts_config[\"macs\"],\n",
    "            \"size_mb\": ref_ts_config[\"size_mb\"],\n",
    "        }\n",
    "\n",
    "        for metric_key, metric_config in metrics_for_ts_comparison.items():\n",
    "            plot_comparative_group(\n",
    "                models_data_dict=ts_models_data_for_plot,\n",
    "                model_names_in_group_display=ts_display_names_obj,\n",
    "                model_group_name_display=\"Time-Series Models\",\n",
    "                model_group_name_file=\"timeseries\",\n",
    "                metric_key=metric_key,\n",
    "                y_label=metric_config[\"label\"],\n",
    "                is_higher_better=metric_config[\"higher_better\"],\n",
    "                y_multiplier=metric_config.get(\"multiplier\", 1.0), # Uses LSTM's settings here by default\n",
    "                y_unit_prefix=metric_config.get(\"unit_prefix\", \"\")\n",
    "            )\n",
    "    else:\n",
    "        print(\"Skipping comparative Time-Series plots as data for one or more models is missing.\")\n",
    "\n",
    "    print(f\"\\nAll plots saved to '{OUTPUT_DIR}' directory.\")"
   ],
   "id": "b3ed553e8c51f504",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating Individual Model Plots ---\n",
      "Saved: individual_mobilenetv2_accuracy_vs_pruning.png\n",
      "Saved: individual_mobilenetv2_params_vs_pruning.png\n",
      "Saved: individual_mobilenetv2_macs_vs_pruning.png\n",
      "Saved: individual_mobilenetv2_size_mb_vs_pruning.png\n",
      "Saved: individual_mobilenetv2_loss_vs_pruning.png\n",
      "Saved: individual_resnet18_accuracy_vs_pruning.png\n",
      "Saved: individual_resnet18_params_vs_pruning.png\n",
      "Saved: individual_resnet18_macs_vs_pruning.png\n",
      "Saved: individual_resnet18_size_mb_vs_pruning.png\n",
      "Saved: individual_resnet18_loss_vs_pruning.png\n",
      "Saved: individual_lstm_mse_vs_pruning.png\n",
      "Saved: individual_lstm_mae_vs_pruning.png\n",
      "Saved: individual_lstm_params_vs_pruning.png\n",
      "Saved: individual_lstm_macs_vs_pruning.png\n",
      "Saved: individual_lstm_size_mb_vs_pruning.png\n",
      "Saved: individual_lstm_loss_vs_pruning.png\n",
      "Saved: individual_mlp_mse_vs_pruning.png\n",
      "Saved: individual_mlp_mae_vs_pruning.png\n",
      "Saved: individual_mlp_params_vs_pruning.png\n",
      "Saved: individual_mlp_macs_vs_pruning.png\n",
      "Saved: individual_mlp_size_mb_vs_pruning.png\n",
      "Saved: individual_mlp_loss_vs_pruning.png\n",
      "\n",
      "--- Generating Comparative CNN Plots ---\n",
      "Saved: comparative_cnns_accuracy_vs_pruning.png\n",
      "Saved: comparative_cnns_params_vs_pruning.png\n",
      "Saved: comparative_cnns_macs_vs_pruning.png\n",
      "Saved: comparative_cnns_size_mb_vs_pruning.png\n",
      "\n",
      "--- Generating Comparative Time-Series Plots ---\n",
      "Saved: comparative_timeseries_mse_vs_pruning.png\n",
      "Saved: comparative_timeseries_mae_vs_pruning.png\n",
      "Saved: comparative_timeseries_params_vs_pruning.png\n",
      "Saved: comparative_timeseries_macs_vs_pruning.png\n",
      "Saved: comparative_timeseries_size_mb_vs_pruning.png\n",
      "\n",
      "All plots saved to 'thesis_plots_v2' directory.\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
