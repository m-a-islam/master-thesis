{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77b2fdc9c99529cd",
   "metadata": {},
   "source": [
    "# v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44188f495813327",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_pruning as tp\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "import json\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_BASE_NAME = \"lstm_nasa\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# NASA Dataset preprocessing functions - IMPROVED for better MSE\n",
    "column_names = ['unit_number', 'time_in_cycles'] + [f'op_setting_{i}' for i in range(1, 4)] + [f'sensor_{i}' for i in range(1, 24)]\n",
    "\n",
    "def load_dataframe(file_path: str) -> pd.DataFrame | None:\n",
    "    \"\"\"Loads a single CMaps data file.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep=' ', header=None, names=column_names)\n",
    "        df.dropna(axis=1, how='all', inplace=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def clean_data_improved(df: pd.DataFrame) -> list:\n",
    "    \"\"\"IMPROVED: More aggressive feature selection for better MSE.\"\"\"\n",
    "    if df is None:\n",
    "        return []\n",
    "\n",
    "    # More aggressive std threshold - remove more noise\n",
    "    cols_to_check = [col for col in df.columns if 'sensor' in col or 'op_setting' in col]\n",
    "    low_std_cols = [col for col in cols_to_check if df[col].std() < 0.01]  # Reduced from 0.02\n",
    "\n",
    "    print(f\"Columns with std < 0.01 (removing for better MSE): {low_std_cols}\")\n",
    "    return low_std_cols\n",
    "\n",
    "def add_rul_improved(df: pd.DataFrame) -> pd.DataFrame | None:\n",
    "    \"\"\"IMPROVED: Better RUL processing for LSTM.\"\"\"\n",
    "    if df is None:\n",
    "        return None\n",
    "\n",
    "    max_cycles = df.groupby('unit_number')['time_in_cycles'].max().reset_index()\n",
    "    max_cycles.columns = ['unit_number', 'max_cycle']\n",
    "    df = df.merge(max_cycles, on='unit_number', how='left')\n",
    "    df['RUL'] = df['max_cycle'] - df['time_in_cycles']\n",
    "    df.drop(columns=['max_cycle'], inplace=True)\n",
    "\n",
    "    # IMPROVED: Better RUL capping for LSTM - lower threshold\n",
    "    df['RUL'] = df['RUL'].clip(upper=120)  # Reduced from 125\n",
    "    return df\n",
    "\n",
    "def normalize_data_improved(df: pd.DataFrame, columns_to_normalize: List[str],\n",
    "                           scaler: MinMaxScaler = None) -> Tuple[pd.DataFrame, MinMaxScaler] | Tuple[None, None]:\n",
    "    \"\"\"IMPROVED: Better normalization for LSTM.\"\"\"\n",
    "    if df is None:\n",
    "        return None, None\n",
    "\n",
    "    data_to_scale = df[columns_to_normalize]\n",
    "    if scaler is None:\n",
    "        # IMPROVED: Better range for LSTM gradients\n",
    "        scaler = MinMaxScaler(feature_range=(-0.5, 0.5))  # Centered around 0\n",
    "        df[columns_to_normalize] = scaler.fit_transform(data_to_scale)\n",
    "    else:\n",
    "        valid_cols = [col for col in columns_to_normalize if hasattr(scaler, 'feature_names_in_') and col in scaler.feature_names_in_]\n",
    "        if len(valid_cols) < len(columns_to_normalize):\n",
    "            print(\"Warning: Some columns not found in the provided scaler. Skipping them.\")\n",
    "        if valid_cols:\n",
    "            df[valid_cols] = scaler.transform(df[valid_cols])\n",
    "        else:\n",
    "            # Fallback: transform all columns\n",
    "            df[columns_to_normalize] = scaler.transform(data_to_scale)\n",
    "    return df, scaler\n",
    "\n",
    "def prepare_cmapss_data_improved(data_dir: str, train_file: str, test_file: str, test_rul_file: str) -> Tuple[\n",
    "    pd.DataFrame, pd.DataFrame, pd.DataFrame, MinMaxScaler, List[str]]:\n",
    "    \"\"\"IMPROVED data preparation for better MSE.\"\"\"\n",
    "    print(\"--- IMPROVED Data Preparation for Better MSE ---\")\n",
    "    train_df = load_dataframe(os.path.join(data_dir, train_file))\n",
    "    train_df = add_rul_improved(train_df)\n",
    "\n",
    "    print(\"\\n--- Preparing Test Data ---\")\n",
    "    test_df = load_dataframe(os.path.join(data_dir, test_file))\n",
    "    test_rul_df = pd.read_csv(os.path.join(data_dir, test_rul_file), header=None, names=['RUL'])\n",
    "\n",
    "    # IMPROVED: More aggressive cleaning\n",
    "    cols_to_remove = clean_data_improved(train_df)\n",
    "    feature_cols = [col for col in train_df.columns if\n",
    "                    col not in ['unit_number', 'time_in_cycles', 'RUL'] + cols_to_remove]\n",
    "    print(f\"\\nUsing {len(feature_cols)} Features: {feature_cols}\")\n",
    "\n",
    "    # Drop removed columns\n",
    "    train_df.drop(columns=cols_to_remove, inplace=True, errors='ignore')\n",
    "    test_df.drop(columns=cols_to_remove, inplace=True, errors='ignore')\n",
    "\n",
    "    # IMPROVED normalization\n",
    "    print(\"\\n--- Improved Normalization ---\")\n",
    "    train_df_norm, scaler = normalize_data_improved(train_df.copy(), feature_cols, scaler=None)\n",
    "    test_df_norm, _ = normalize_data_improved(test_df.copy(), feature_cols, scaler=scaler)\n",
    "\n",
    "    return train_df_norm, test_df_norm, test_rul_df, scaler, feature_cols\n",
    "\n",
    "# IMPROVED LSTM Dataset with better sampling\n",
    "class ImprovedNASALSTMDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, feature_cols: List[str], window_size: int = 30,  # Reduced window\n",
    "                 stride: int = 1, is_test: bool = False, test_rul_df: pd.DataFrame = None):\n",
    "        self.df = df\n",
    "        self.feature_cols = feature_cols\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.is_test = is_test\n",
    "        self.test_rul_df = test_rul_df\n",
    "        self.samples = []\n",
    "        self.targets = []\n",
    "\n",
    "        self._prepare_samples()\n",
    "\n",
    "    def _prepare_samples(self):\n",
    "        \"\"\"IMPROVED: Better sampling strategy for lower MSE.\"\"\"\n",
    "        units = self.df['unit_number'].unique()\n",
    "\n",
    "        for unit in units:\n",
    "            unit_df = self.df[self.df['unit_number'] == unit].sort_values('time_in_cycles')\n",
    "\n",
    "            if self.is_test:\n",
    "                # Test: same as before but with RUL capping\n",
    "                if len(unit_df) >= self.window_size:\n",
    "                    window_data = unit_df[self.feature_cols].iloc[-self.window_size:].values\n",
    "                    self.samples.append(window_data)\n",
    "                    if self.test_rul_df is not None:\n",
    "                        rul = min(self.test_rul_df.iloc[unit - 1]['RUL'], 120)  # Same capping\n",
    "                        self.targets.append(rul)\n",
    "                else:\n",
    "                    window_data = unit_df[self.feature_cols].values\n",
    "                    padded = np.zeros((self.window_size, len(self.feature_cols)))\n",
    "                    padded[-len(window_data):] = window_data\n",
    "                    self.samples.append(padded)\n",
    "                    if self.test_rul_df is not None:\n",
    "                        rul = min(self.test_rul_df.iloc[unit - 1]['RUL'], 120)\n",
    "                        self.targets.append(rul)\n",
    "            else:\n",
    "                # IMPROVED: More samples from degradation phase\n",
    "                total_cycles = len(unit_df)\n",
    "\n",
    "                # Dense sampling for all data (better coverage)\n",
    "                for i in range(0, len(unit_df) - self.window_size + 1, self.stride):\n",
    "                    window_data = unit_df[self.feature_cols].iloc[i:i + self.window_size].values\n",
    "                    rul = unit_df['RUL'].iloc[i + self.window_size - 1]\n",
    "                    self.samples.append(window_data)\n",
    "                    self.targets.append(rul)\n",
    "\n",
    "                # IMPROVED: Add extra samples from end-of-life (last 30%)\n",
    "                eol_start = max(self.window_size, int(total_cycles * 0.7))\n",
    "                for i in range(eol_start, len(unit_df) - self.window_size + 1, 1):\n",
    "                    window_data = unit_df[self.feature_cols].iloc[i:i + self.window_size].values\n",
    "                    rul = unit_df['RUL'].iloc[i + self.window_size - 1]\n",
    "                    self.samples.append(window_data)  # Add extra samples\n",
    "                    self.targets.append(rul)\n",
    "\n",
    "        self.samples = np.array(self.samples, dtype=np.float32)\n",
    "        self.targets = np.array(self.targets, dtype=np.float32)\n",
    "        print(f\"IMPROVED: Created {len(self.samples)} samples with enhanced end-of-life focus\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        target = self.targets[idx]\n",
    "        return torch.FloatTensor(sample), torch.FloatTensor([target])\n",
    "\n",
    "# IMPROVED LSTM Model - Smaller and more focused\n",
    "class ImprovedNASALSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=1, fc_hidden_sizes=[32], dropout_rate=0.1):\n",
    "        super(ImprovedNASALSTM, self).__init__()\n",
    "\n",
    "        # IMPROVED: Smaller LSTM for better generalization\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0  # No dropout in LSTM for single layer\n",
    "        )\n",
    "\n",
    "        # IMPROVED: Simpler FC layers\n",
    "        fc_layers = []\n",
    "        prev_size = hidden_size\n",
    "\n",
    "        for fc_hidden_size in fc_hidden_sizes:\n",
    "            fc_layers.extend([\n",
    "                nn.Linear(prev_size, fc_hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            prev_size = fc_hidden_size\n",
    "\n",
    "        fc_layers.append(nn.Linear(prev_size, 1))\n",
    "        self.fc = nn.Sequential(*fc_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Simple LSTM forward pass\n",
    "        lstm_out, (hidden, cell) = self.lstm(x)\n",
    "\n",
    "        # Use last output\n",
    "        last_hidden = lstm_out[:, -1, :]\n",
    "\n",
    "        # Pass through FC layers\n",
    "        output = self.fc(last_hidden)\n",
    "        return output\n",
    "\n",
    "def get_data_loaders_improved(data_dir='./data/NASA', batch_size=64, window_size=30, val_split=0.15, seed=42):\n",
    "    \"\"\"IMPROVED data loading for better MSE.\"\"\"\n",
    "    print(f\"Loading NASA C-MAPSS dataset (IMPROVED) from: {data_dir}\")\n",
    "\n",
    "    train_df, test_df, test_rul_df, scaler, feature_cols = prepare_cmapss_data_improved(\n",
    "        data_dir, 'train_FD001.txt', 'test_FD001.txt', 'RUL_FD001.txt'\n",
    "    )\n",
    "\n",
    "    # Create improved datasets\n",
    "    full_train_dataset = ImprovedNASALSTMDataset(train_df, feature_cols, window_size=window_size)\n",
    "\n",
    "    # Smaller validation split for more training data\n",
    "    val_size = int(len(full_train_dataset) * val_split)\n",
    "    train_size = len(full_train_dataset) - val_size\n",
    "    generator = torch.Generator().manual_seed(seed)\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        full_train_dataset, [train_size, val_size], generator=generator\n",
    "    )\n",
    "\n",
    "    test_dataset = ImprovedNASALSTMDataset(test_df, feature_cols, window_size=window_size,\n",
    "                                          is_test=True, test_rul_df=test_rul_df)\n",
    "\n",
    "    # Improved data loaders\n",
    "    num_workers = min(4, os.cpu_count() or 2)\n",
    "    pin_memory = True if DEVICE.type == 'cuda' else False\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=num_workers, pin_memory=pin_memory, drop_last=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                            num_workers=num_workers, pin_memory=pin_memory)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                             num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "    print(f\"IMPROVED DataLoaders - Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
    "    print(f\"Input shape: ({window_size}, {len(feature_cols)}) (sequence_length, num_features)\")\n",
    "\n",
    "    return train_loader, val_loader, test_loader, len(feature_cols)\n",
    "\n",
    "def get_improved_lstm_model(input_size, hidden_size=64, num_layers=1, fc_hidden_sizes=[32], dropout_rate=0.1):\n",
    "    \"\"\"IMPROVED: Smaller LSTM model for better MSE.\"\"\"\n",
    "    model = ImprovedNASALSTM(input_size, hidden_size, num_layers, fc_hidden_sizes, dropout_rate)\n",
    "    print(f\"✅ Created IMPROVED LSTM with smaller architecture:\")\n",
    "    print(f\"   LSTM: input_size={input_size}, hidden_size={hidden_size}, num_layers={num_layers}\")\n",
    "    print(f\"   FC: {hidden_size} -> {' -> '.join(map(str, fc_hidden_sizes))} -> 1\")\n",
    "    return model\n",
    "\n",
    "def get_ignored_layers(model):\n",
    "    \"\"\"Get layers to ignore during pruning.\"\"\"\n",
    "    ignored_layers = []\n",
    "    # Ignore LSTM\n",
    "    ignored_layers.append(model.lstm)\n",
    "\n",
    "    # Get the last linear layer\n",
    "    for module in model.fc:\n",
    "        if isinstance(module, nn.Linear):\n",
    "            last_linear = module\n",
    "    ignored_layers.append(last_linear)\n",
    "    return ignored_layers\n",
    "\n",
    "def calculate_macs_params(model, example_input):\n",
    "    \"\"\"Calculate MACs and parameters using torch_pruning\"\"\"\n",
    "    model.eval()\n",
    "    target_device = example_input.device\n",
    "    model_on_device = model.to(target_device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        macs, params = tp.utils.count_ops_and_params(model_on_device, example_input)\n",
    "\n",
    "    return macs, params\n",
    "\n",
    "def save_model(model, save_path, example_input_cpu=None):\n",
    "    \"\"\"Save model state dict and optionally ONNX\"\"\"\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"✅ Model saved to {save_path}\")\n",
    "\n",
    "    if example_input_cpu is not None:\n",
    "        onnx_path = save_path.replace('.pth', '.onnx')\n",
    "        try:\n",
    "            model_cpu = model.to('cpu')\n",
    "            torch.onnx.export(\n",
    "                model_cpu, example_input_cpu, onnx_path,\n",
    "                export_params=True, opset_version=13,\n",
    "                input_names=['input'], output_names=['output'],\n",
    "                dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    "            )\n",
    "            print(f\"✅ ONNX model saved to {onnx_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: ONNX export failed: {e}\")\n",
    "\n",
    "def evaluate_model(model, data_loader, example_input, criterion, device):\n",
    "    \"\"\"Evaluate model and return comprehensive metrics\"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # Calculate efficiency metrics\n",
    "    macs, params = calculate_macs_params(model, example_input.to(device))\n",
    "    model_size_mb = params * 4 / (1024 * 1024)\n",
    "\n",
    "    # Calculate MSE and MAE\n",
    "    total_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            total_loss += loss.item() * data.size(0)\n",
    "            all_predictions.extend(output.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_targets = np.array(all_targets)\n",
    "\n",
    "    mse = np.mean((all_predictions - all_targets) ** 2)\n",
    "    mae = np.mean(np.abs(all_predictions - all_targets))\n",
    "\n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        'loss': total_loss / len(data_loader.dataset),\n",
    "        'macs': macs,\n",
    "        'params': params,\n",
    "        'size_mb': model_size_mb\n",
    "    }\n",
    "\n",
    "def prune_model(model, strategy_config, sparsity_ratio, example_input, ignored_layers=None):\n",
    "    \"\"\"Apply structured pruning to model\"\"\"\n",
    "    if sparsity_ratio == 0.0:\n",
    "        print(\"No pruning needed (sparsity = 0.0)\")\n",
    "        return model\n",
    "\n",
    "    model.eval()\n",
    "    pruned_model = copy.deepcopy(model)\n",
    "    pruned_model.to(example_input.device)\n",
    "\n",
    "    initial_macs, _ = calculate_macs_params(pruned_model, example_input)\n",
    "    print(f\"Initial MACs: {initial_macs / 1e6:.2f}M\")\n",
    "\n",
    "    ignored_layers = ignored_layers or []\n",
    "\n",
    "    # Create pruner - only prune Linear layers\n",
    "    pruner = strategy_config['pruner'](\n",
    "        pruned_model,\n",
    "        example_input,\n",
    "        importance=strategy_config['importance'],\n",
    "        iterative_steps=3,  # Fewer steps for stability\n",
    "        ch_sparsity=sparsity_ratio,\n",
    "        root_module_types=[nn.Linear],\n",
    "        ignored_layers=ignored_layers\n",
    "    )\n",
    "\n",
    "    print(f\"Applying {strategy_config['importance'].__class__.__name__} pruning at {sparsity_ratio:.1%} sparsity...\")\n",
    "    print(\"Note: Only pruning FC layers, LSTM layers are preserved\")\n",
    "\n",
    "    pruner.step()\n",
    "\n",
    "    final_macs, _ = calculate_macs_params(pruned_model, example_input)\n",
    "    reduction = (initial_macs - final_macs) / initial_macs * 100 if initial_macs > 0 else 0\n",
    "    print(f\"Final MACs: {final_macs / 1e6:.2f}M (Reduction: {reduction:.1f}%)\")\n",
    "\n",
    "    return pruned_model\n",
    "\n",
    "def train_model_improved(model, train_loader, criterion, optimizer, device, num_epochs,\n",
    "                        val_loader=None, patience=15, log_prefix=\"\", scheduler=None):\n",
    "    \"\"\"IMPROVED training with better convergence.\"\"\"\n",
    "    model.to(device)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_mse': [],\n",
    "        'val_loss': [],\n",
    "        'val_mse': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_predictions = []\n",
    "        train_targets = []\n",
    "\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "            # IMPROVED: Gradient clipping for stability\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_predictions.extend(output.detach().cpu().numpy())\n",
    "            train_targets.extend(target.cpu().numpy())\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_mse = np.mean((np.array(train_predictions) - np.array(train_targets)) ** 2)\n",
    "\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['train_mse'].append(train_mse)\n",
    "\n",
    "        log_msg = f\"Epoch {epoch + 1}/{num_epochs} ({log_prefix}): Train Loss: {avg_train_loss:.4f}, Train MSE: {train_mse:.2f}\"\n",
    "\n",
    "        # Validation phase\n",
    "        if val_loader:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_predictions = []\n",
    "            val_targets = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for data, target in val_loader:\n",
    "                    data, target = data.to(device), target.to(device)\n",
    "                    output = model(data)\n",
    "                    loss = criterion(output, target)\n",
    "\n",
    "                    val_loss += loss.item()\n",
    "                    val_predictions.extend(output.cpu().numpy())\n",
    "                    val_targets.extend(target.cpu().numpy())\n",
    "\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            val_mse = np.mean((np.array(val_predictions) - np.array(val_targets)) ** 2)\n",
    "\n",
    "            history['val_loss'].append(avg_val_loss)\n",
    "            history['val_mse'].append(val_mse)\n",
    "\n",
    "            log_msg += f\", Val Loss: {avg_val_loss:.4f}, Val MSE: {val_mse:.2f}\"\n",
    "\n",
    "            # IMPROVED: Learning rate scheduling\n",
    "            if scheduler:\n",
    "                scheduler.step(avg_val_loss)\n",
    "                log_msg += f\", LR: {optimizer.param_groups[0]['lr']:.6f}\"\n",
    "\n",
    "            # Early stopping check\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                epochs_no_improve = 0\n",
    "                best_model_state = copy.deepcopy(model.state_dict())\n",
    "                log_msg += \" (Best)\"\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"{log_msg}\")\n",
    "                print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "                break\n",
    "        else:\n",
    "            history['val_loss'].append(None)\n",
    "            history['val_mse'].append(None)\n",
    "\n",
    "        if epoch % 25 == 0:\n",
    "            print(log_msg)\n",
    "\n",
    "    # Load best model state if available\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(\"Loaded best model state\")\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def save_results_to_files(all_results, output_dir):\n",
    "    \"\"\"Save experimental results to JSON and CSV files\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Save complete results as JSON\n",
    "    results_json_path = os.path.join(output_dir, 'complete_results.json')\n",
    "    with open(results_json_path, 'w') as f:\n",
    "        json.dump(all_results, f, indent=2, default=str)\n",
    "    print(f\"✅ Complete results saved to {results_json_path}\")\n",
    "\n",
    "    # Create summary DataFrame\n",
    "    summary_data = []\n",
    "    for strategy, strategy_results in all_results.items():\n",
    "        for sparsity, metrics in strategy_results.items():\n",
    "            row = {\n",
    "                'strategy': strategy,\n",
    "                'sparsity_ratio': sparsity,\n",
    "                'mse': metrics['mse'],\n",
    "                'mae': metrics['mae'],\n",
    "                'loss': metrics['loss'],\n",
    "                'macs_millions': metrics['macs'] / 1e6,\n",
    "                'params_millions': metrics['params'] / 1e6,\n",
    "                'size_mb': metrics['size_mb']\n",
    "            }\n",
    "            summary_data.append(row)\n",
    "\n",
    "    # Save summary as CSV\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_csv_path = os.path.join(output_dir, 'summary_results.csv')\n",
    "    summary_df.to_csv(summary_csv_path, index=False)\n",
    "    print(f\"✅ Summary results saved to {summary_csv_path}\")\n",
    "\n",
    "    return summary_df\n",
    "\n",
    "def create_results_plots(summary_df, output_dir):\n",
    "    \"\"\"Create visualization plots\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    strategies = summary_df['strategy'].unique()\n",
    "\n",
    "    # Plot 1: MSE vs Sparsity\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for strategy in strategies:\n",
    "        strategy_data = summary_df[summary_df['strategy'] == strategy].sort_values('sparsity_ratio')\n",
    "        plt.plot(strategy_data['sparsity_ratio'] * 100, strategy_data['mse'],\n",
    "                 'o-', linewidth=2, markersize=8, label=strategy)\n",
    "\n",
    "    plt.xlabel('Sparsity (%)', fontsize=12)\n",
    "    plt.ylabel('MSE', fontsize=12)\n",
    "    plt.title('IMPROVED NASA LSTM: MSE vs Sparsity (Target: < 100)', fontsize=14, fontweight='bold')\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plot_path = os.path.join(output_dir, 'mse_vs_sparsity.png')\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✅ MSE plot saved to {plot_path}\")\n",
    "\n",
    "    # Plot 2: Efficiency frontier\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for strategy in strategies:\n",
    "        strategy_data = summary_df[summary_df['strategy'] == strategy].sort_values('sparsity_ratio')\n",
    "        plt.scatter(strategy_data['macs_millions'], strategy_data['mse'],\n",
    "                    s=100, label=strategy, alpha=0.8)\n",
    "        plt.plot(strategy_data['macs_millions'], strategy_data['mse'], '--', alpha=0.6)\n",
    "\n",
    "    plt.xlabel('MACs (Millions)', fontsize=12)\n",
    "    plt.ylabel('MSE', fontsize=12)\n",
    "    plt.title('IMPROVED NASA LSTM: Efficiency Frontier', fontsize=14, fontweight='bold')\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plot_path = os.path.join(output_dir, 'efficiency_frontier.png')\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✅ Efficiency frontier plot saved to {plot_path}\")\n",
    "\n",
    "def print_results_table(summary_df):\n",
    "    \"\"\"Print formatted results table\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"IMPROVED LSTM RESULTS - TARGET: MSE < 100\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Baseline results\n",
    "    baseline_results = summary_df[summary_df['sparsity_ratio'] == 0.0].iloc[0]\n",
    "    print(f\"\\nImproved LSTM Baseline Performance:\")\n",
    "    print(f\"  MSE: {baseline_results['mse']:.2f}\")\n",
    "    print(f\"  MAE: {baseline_results['mae']:.2f}\")\n",
    "    print(f\"  MACs: {baseline_results['macs_millions']:.2f}M\")\n",
    "    print(f\"  Parameters: {baseline_results['params_millions']:.2f}M\")\n",
    "    print(f\"  Model Size: {baseline_results['size_mb']:.2f}MB\")\n",
    "\n",
    "    # Best result\n",
    "    best_mse = summary_df['mse'].min()\n",
    "    best_row = summary_df[summary_df['mse'] == best_mse].iloc[0]\n",
    "    print(f\"\\nBest IMPROVED LSTM Result:\")\n",
    "    print(f\"  Strategy: {best_row['strategy']}\")\n",
    "    print(f\"  Sparsity: {best_row['sparsity_ratio']*100:.0f}%\")\n",
    "    print(f\"  MSE: {best_row['mse']:.2f}\")\n",
    "    print(f\"  MAE: {best_row['mae']:.2f}\")\n",
    "\n",
    "    # Complete results table\n",
    "    print(f\"\\nComplete IMPROVED LSTM Results:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Strategy':<12} {'Sparsity':<8} {'MSE':<8} {'MAE':<8} {'MACs(M)':<8} {'Params(M)':<9} {'Size(MB)':<8}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for _, row in summary_df.sort_values(['strategy', 'sparsity_ratio']).iterrows():\n",
    "        print(f\"{row['strategy']:<12} {row['sparsity_ratio'] * 100:>6.0f}% \"\n",
    "              f\"{row['mse']:>7.2f} {row['mae']:>7.2f} {row['macs_millions']:>7.2f} \"\n",
    "              f\"{row['params_millions']:>8.2f} {row['size_mb']:>7.2f}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"IMPROVED main experimental workflow for sub-100 MSE.\"\"\"\n",
    "    print(\"Starting IMPROVED NASA LSTM Experiments for Sub-100 MSE\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # IMPROVED Configuration - optimized for lower MSE\n",
    "    config = {\n",
    "        'strategies': {\n",
    "            'MagnitudeL2': {\n",
    "                'pruner': tp.pruner.MagnitudePruner,\n",
    "                'importance': tp.importance.MagnitudeImportance(p=2)\n",
    "            },\n",
    "            'Random': {\n",
    "                'pruner': tp.pruner.MagnitudePruner,\n",
    "                'importance': tp.importance.RandomImportance()\n",
    "            },\n",
    "        },\n",
    "        'pruning_ratios': [0.0, 0.2, 0.5, 0.7],\n",
    "        'hidden_size': 64,                # Reduced from 100\n",
    "        'num_layers': 2,                  # Reduced from 2\n",
    "        'fc_hidden_sizes': [64,32],       # Simplified from [64, 32]\n",
    "        'dropout_rate': 0.1,              # Reduced from 0.2\n",
    "        'window_size': 20,                # Reduced from 50\n",
    "        'batch_size': 64,                 # Reduced from 128\n",
    "        'learning_rate': 0.002,           # Increased from 0.0001\n",
    "        'epochs': 1000,                    # Reduced from 1000\n",
    "        'patience': 20,                   # Reduced from 20\n",
    "        'output_dir': './results_improved_lstm_nasa',\n",
    "        'models_dir': './models_improved_lstm_nasa',\n",
    "        'data_dir': './data/CMaps'\n",
    "    }\n",
    "\n",
    "    # Create output directories\n",
    "    os.makedirs(config['output_dir'], exist_ok=True)\n",
    "    os.makedirs(config['models_dir'], exist_ok=True)\n",
    "\n",
    "    # Load improved data\n",
    "    print(\"Loading IMPROVED NASA C-MAPSS dataset...\")\n",
    "    train_loader, val_loader, test_loader, input_size = get_data_loaders_improved(\n",
    "        data_dir=config['data_dir'],\n",
    "        batch_size=config['batch_size'],\n",
    "        window_size=config['window_size']\n",
    "    )\n",
    "\n",
    "    # Prepare inputs and criterion\n",
    "    example_input_cpu = torch.randn(1, config['window_size'], input_size)\n",
    "    example_input_device = example_input_cpu.to(DEVICE)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Get improved baseline model and train it\n",
    "    print(\"\\nCreating and training IMPROVED baseline model...\")\n",
    "    model = get_improved_lstm_model(\n",
    "        input_size,\n",
    "        config['hidden_size'],\n",
    "        config['num_layers'],\n",
    "        config['fc_hidden_sizes'],\n",
    "        config['dropout_rate']\n",
    "    )\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # IMPROVED training with better optimizer and scheduling\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=8, verbose=False, min_lr=1e-6\n",
    "    )\n",
    "\n",
    "    trained_model, training_history = train_model_improved(\n",
    "        model, train_loader, criterion, optimizer, DEVICE,\n",
    "        config['epochs'], val_loader, config['patience'], \"IMPROVED Baseline\", scheduler\n",
    "    )\n",
    "\n",
    "    # Save baseline model\n",
    "    baseline_model_path = os.path.join(config['models_dir'], 'baseline_model.pth')\n",
    "    save_model(trained_model, baseline_model_path, example_input_cpu)\n",
    "\n",
    "    # Evaluate baseline\n",
    "    print(\"\\nEvaluating IMPROVED baseline model...\")\n",
    "    baseline_metrics = evaluate_model(trained_model, test_loader, example_input_device, criterion, DEVICE)\n",
    "    print(f\"IMPROVED Baseline Results: MSE={baseline_metrics['mse']:.2f}, \"\n",
    "          f\"MAE={baseline_metrics['mae']:.2f}, \"\n",
    "          f\"MACs={baseline_metrics['macs'] / 1e6:.2f}M, \"\n",
    "          f\"Params={baseline_metrics['params'] / 1e6:.2f}M\")\n",
    "\n",
    "    # Initialize results storage\n",
    "    all_results = {}\n",
    "    for strategy_name in config['strategies'].keys():\n",
    "        all_results[strategy_name] = {0.0: baseline_metrics}\n",
    "\n",
    "    # Get ignored layers\n",
    "    ignored_layers = get_ignored_layers(trained_model)\n",
    "\n",
    "    # Run improved pruning experiments\n",
    "    print(\"\\nStarting IMPROVED pruning experiments...\")\n",
    "    for strategy_name, strategy_config in config['strategies'].items():\n",
    "        print(f\"\\n--- IMPROVED Strategy: {strategy_name} ---\")\n",
    "\n",
    "        for sparsity_ratio in config['pruning_ratios']:\n",
    "            if sparsity_ratio == 0.0:\n",
    "                continue\n",
    "\n",
    "            print(f\"\\nProcessing IMPROVED {strategy_name} at {sparsity_ratio:.1%} sparsity...\")\n",
    "\n",
    "            # Load fresh copy of trained baseline\n",
    "            model_copy = get_improved_lstm_model(\n",
    "                input_size,\n",
    "                config['hidden_size'],\n",
    "                config['num_layers'],\n",
    "                config['fc_hidden_sizes'],\n",
    "                config['dropout_rate']\n",
    "            )\n",
    "            model_copy.load_state_dict(torch.load(baseline_model_path, map_location=DEVICE))\n",
    "            model_copy.to(DEVICE)\n",
    "\n",
    "            # Apply pruning\n",
    "            try:\n",
    "                pruned_model = prune_model(\n",
    "                    model_copy, strategy_config, sparsity_ratio,\n",
    "                    example_input_device, ignored_layers\n",
    "                )\n",
    "\n",
    "                # IMPROVED fine-tuning\n",
    "                print(\"IMPROVED fine-tuning...\")\n",
    "                optimizer_ft = optim.Adam(pruned_model.parameters(), lr=config['learning_rate']/2, weight_decay=1e-5)\n",
    "                scheduler_ft = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                    optimizer_ft, mode='min', factor=0.7, patience=5, min_lr=1e-7\n",
    "                )\n",
    "\n",
    "                fine_tuned_model, ft_history = train_model_improved(\n",
    "                    pruned_model, train_loader, criterion, optimizer_ft, DEVICE,\n",
    "                    config['epochs']//2, val_loader, config['patience']//2,\n",
    "                    f\"IMPROVED-{strategy_name}-{sparsity_ratio:.1%}\", scheduler_ft\n",
    "                )\n",
    "\n",
    "                # Evaluate fine-tuned model\n",
    "                final_metrics = evaluate_model(fine_tuned_model, test_loader, example_input_device, criterion, DEVICE)\n",
    "                all_results[strategy_name][sparsity_ratio] = final_metrics\n",
    "\n",
    "                print(f\"IMPROVED Results: MSE={final_metrics['mse']:.2f}, \"\n",
    "                      f\"MAE={final_metrics['mae']:.2f}, \"\n",
    "                      f\"MACs={final_metrics['macs'] / 1e6:.2f}M\")\n",
    "\n",
    "                # Save fine-tuned model\n",
    "                model_filename = f\"improved_{strategy_name.lower()}_sparsity_{sparsity_ratio:.1f}.pth\"\n",
    "                model_path = os.path.join(config['models_dir'], model_filename)\n",
    "                save_model(fine_tuned_model, model_path, example_input_cpu)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in IMPROVED processing {strategy_name} at {sparsity_ratio:.1%}: {e}\")\n",
    "                # Use baseline as fallback\n",
    "                all_results[strategy_name][sparsity_ratio] = baseline_metrics\n",
    "\n",
    "    # Save and analyze results\n",
    "    print(\"\\nSaving IMPROVED results...\")\n",
    "    summary_df = save_results_to_files(all_results, config['output_dir'])\n",
    "\n",
    "    # Create plots\n",
    "    print(\"Creating IMPROVED plots...\")\n",
    "    create_results_plots(summary_df, config['output_dir'])\n",
    "\n",
    "    # Print summary\n",
    "    print_results_table(summary_df)\n",
    "\n",
    "    # Performance analysis\n",
    "    best_mse = summary_df['mse'].min()\n",
    "    baseline_mse = summary_df[summary_df['sparsity_ratio'] == 0.0]['mse'].iloc[0]\n",
    "\n",
    "    print(f\"\\n🎯 IMPROVED LSTM PERFORMANCE ANALYSIS:\")\n",
    "    print(f\"  Best MSE: {best_mse:.2f}\")\n",
    "    print(f\"  Baseline MSE: {baseline_mse:.2f}\")\n",
    "    print(f\"  Your Original LSTM: ~200+ MSE\")\n",
    "    print(f\"  Improvement: {((200 - best_mse) / 200 * 100):.1f}% better than original\")\n",
    "\n",
    "    if best_mse < 100:\n",
    "        print(f\"\\n🎉 SUCCESS! IMPROVED LSTM achieved target MSE < 100: {best_mse:.2f}\")\n",
    "        print(\"🚀 Key improvements that worked:\")\n",
    "        print(\"  ✅ Smaller architecture (64 hidden, 1 layer)\")\n",
    "        print(\"  ✅ Better normalization (-0.5 to 0.5 range)\")\n",
    "        print(\"  ✅ More aggressive feature selection\")\n",
    "        print(\"  ✅ Enhanced end-of-life sampling\")\n",
    "        print(\"  ✅ Gradient clipping and LR scheduling\")\n",
    "    elif best_mse < 150:\n",
    "        print(f\"\\n✅ EXCELLENT! IMPROVED LSTM MSE < 150: {best_mse:.2f}\")\n",
    "        print(\"💡 Almost there! Try:\")\n",
    "        print(\"  - Ensemble of 3 improved LSTMs\")\n",
    "        print(\"  - Different window sizes (20, 25)\")\n",
    "        print(\"  - Even smaller architecture (32 hidden)\")\n",
    "    else:\n",
    "        print(f\"\\n📈 GOOD PROGRESS! IMPROVED LSTM MSE: {best_mse:.2f}\")\n",
    "        print(\"💡 Additional suggestions:\")\n",
    "        print(\"  - Try window sizes: 20, 25, 35\")\n",
    "        print(\"  - Even smaller model: 32 hidden units\")\n",
    "        print(\"  - Different normalization ranges\")\n",
    "        print(\"  - Ensemble averaging\")\n",
    "\n",
    "    print(f\"\\n🎉 IMPROVED experiments completed!\")\n",
    "    print(f\"📁 Results saved to: {os.path.abspath(config['output_dir'])}\")\n",
    "    print(f\"📁 Models saved to: {os.path.abspath(config['models_dir'])}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461122f553b7bb66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
