{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## import necessary libraries for pruning",
   "id": "757f942cf3b37399"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T22:45:13.937180Z",
     "start_time": "2025-03-31T22:45:12.959643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch, sys, os\n",
    "import torch.nn as nn\n",
    "import logging, torch.onnx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from mask_mobile_net import MobileNetV2\n",
    "from cnn.resNet.utils import calculate_cost\n",
    "from cnn.resNet.resnet_example import get_data_loaders\n",
    "from thop import profile\n",
    "from torch import optim"
   ],
   "id": "9a41fc6188331cb3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### asuming model size",
   "id": "6eb761352231dd62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T22:48:01.482265Z",
     "start_time": "2025-03-31T22:48:01.472539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def calculate_block_contributions(model, input_size=(2, 3, 32, 32)):\n",
    "    # Get the device of the model\n",
    "    device = next(model.parameters()).device\n",
    "    # Create a dummy input tensor\n",
    "    dummy_input = torch.randn(input_size).to(device)\n",
    "\n",
    "    # Profile initial layers (conv1, bn1, relu)\n",
    "    initial_layers = nn.Sequential(model.conv1, model.bn1, model.relu)\n",
    "    macs_initial, _ = profile(initial_layers, inputs=(dummy_input,), verbose=False)\n",
    "    params_initial = sum(p.numel() for p in initial_layers.parameters())\n",
    "\n",
    "    # Pass input through initial layers\n",
    "    x = initial_layers(dummy_input)\n",
    "\n",
    "    # Define and profile each block sequentially\n",
    "    blocks = [model.block1, model.block2, model.block3, model.block4,\n",
    "              model.block5, model.block6, model.block7]\n",
    "    macs_blocks = []\n",
    "    params_blocks = []\n",
    "\n",
    "    for block in blocks:\n",
    "        macs, _ = profile(block, inputs=(x,), verbose=False)\n",
    "        macs_blocks.append(macs)\n",
    "        params = sum(p.numel() for p in block.parameters())\n",
    "        params_blocks.append(params)\n",
    "        x = block(x)  # Update the input for the next block\n",
    "\n",
    "    # Profile final layers (conv2, bn2, avgpool, fc)\n",
    "    final_layers = nn.Sequential(model.conv2, model.bn2, model.avgpool, nn.Flatten(start_dim=1), model.fc)\n",
    "    macs_final, _ = profile(final_layers, inputs=(x,), verbose=False)\n",
    "    params_final = sum(p.numel() for p in final_layers.parameters())\n",
    "\n",
    "    # Combine initial and final contributions into fixed parts\n",
    "    macs_fixed = macs_initial + macs_final\n",
    "    params_fixed = params_initial + params_final\n",
    "    print(f\"macs_blocks: {macs_blocks}\")\n",
    "    print(f\"params_blocks: {params_blocks}\")\n",
    "    print(f\"macs_fixed: {macs_fixed}\")\n",
    "    print(f\"params_fixed: {params_fixed}\")\n",
    "    return macs_blocks, params_blocks, macs_fixed, params_fixed"
   ],
   "id": "472f7147f76002fd",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Training model",
   "id": "832b7920d819d995"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T22:48:42.512687Z",
     "start_time": "2025-03-31T22:48:42.505768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_with_constraints(model, train_loader, criterion, optimizer, device,\n",
    "                          lambda_macs, lambda_size, macs_blocks, params_blocks,\n",
    "                          macs_fixed, params_fixed):\n",
    "    \"\"\"Train the model with penalties to enforce MACs and size constraints.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        classification_loss = criterion(outputs, labels)\n",
    "\n",
    "        # Compute expected MACs and size\n",
    "        mask_weights = torch.sigmoid(model.mask)\n",
    "        expected_macs = macs_fixed + sum(mask_weights[i] * macs_blocks[i] for i in range(7))\n",
    "        expected_size = (params_fixed + sum(mask_weights[i] * params_blocks[i] for i in range(7))) * 4 / 1e6  # MB\n",
    "\n",
    "        # Penalties for exceeding thresholds\n",
    "\n",
    "        macs_penalty = torch.relu(expected_macs - model.mac_threshold)\n",
    "        size_penalty = torch.relu(expected_size - model.size_threshold)\n",
    "\n",
    "        macs_penalty = macs_penalty.to(device)\n",
    "        size_penalty = size_penalty.to(device)\n",
    "\n",
    "\n",
    "        #print(f\"classification_loss device: {classification_loss.device}\")\n",
    "\n",
    "        # Total loss\n",
    "        loss = classification_loss + lambda_macs * macs_penalty + lambda_size * size_penalty\n",
    "        #print(f\"Before backward: mask = {model.mask.data}\")\n",
    "        loss.backward()\n",
    "        #print(f\"After backward: mask = {model.mask.data}\")\n",
    "\n",
    "        optimizer.step()\n",
    "        #print(f\"After optimizer step: mask = {model.mask.data}\")\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc"
   ],
   "id": "ca7b422618d3844c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### plotting function",
   "id": "7660dc143f42360d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T22:49:21.028072Z",
     "start_time": "2025-03-31T22:49:21.021788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Plotting function\n",
    "def plot_metrics(epochs, losses, accuracies, macs_list, sizes_list):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "    axs[0, 0].plot(range(1, epochs + 1), losses, label='Loss')\n",
    "    axs[0, 0].set_title('Training Loss')\n",
    "    axs[0, 0].set_xlabel('Epoch')\n",
    "    axs[0, 0].set_ylabel('Loss')\n",
    "    axs[0, 0].legend()\n",
    "\n",
    "    axs[0, 1].plot(range(1, epochs + 1), accuracies, label='Accuracy', color='orange')\n",
    "    axs[0, 1].set_title('Training Accuracy')\n",
    "    axs[0, 1].set_xlabel('Epoch')\n",
    "    axs[0, 1].set_ylabel('Accuracy (%)')\n",
    "    axs[0, 1].legend()\n",
    "\n",
    "    axs[1, 0].plot(range(1, epochs + 1), macs_list, label='MACs', color='green')\n",
    "    axs[1, 0].set_title('Model MACs')\n",
    "    axs[1, 0].set_xlabel('Epoch')\n",
    "    axs[1, 0].set_ylabel('MACs')\n",
    "    axs[1, 0].legend()\n",
    "\n",
    "    axs[1, 1].plot(range(1, epochs + 1), sizes_list, label='Size', color='red')\n",
    "    axs[1, 1].set_title('Model Size (MB)')\n",
    "    axs[1, 1].set_xlabel('Epoch')\n",
    "    axs[1, 1].set_ylabel('Size (MB)')\n",
    "    axs[1, 1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('output/mobile_net_soft_pruning_metrices.png')\n",
    "    plt.show()"
   ],
   "id": "1cb0f146995b1bbc",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Main fucntion",
   "id": "8df5f2991db05a4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T22:50:01.508173Z",
     "start_time": "2025-03-31T22:50:01.498273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initialize model with thresholds\n",
    "    size_threshold = 2.0  # MB\n",
    "    mac_threshold = 10000   # Example MACs threshold (adjust as needed)\n",
    "    # todo: accuracy threshold should be implemented here\n",
    "    model = MobileNetV2(num_classes=10, size_threshold=size_threshold, mac_threshold=mac_threshold).to(device)\n",
    "\n",
    "\n",
    "    #torch.save(model.state_dict(), f\"output/before_train_mobile_net_v2.pth\")\n",
    "    #convert_to_onnx(model, f\"output/onnx/before_train_mobile_net_v2.onnx\")\n",
    "\n",
    "    # for name, param in model.named_parameters():\n",
    "    #     print(f\"name: {name}: {param.device}\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    # for group in optimizer.param_groups:\n",
    "    #     for p in group['params']:\n",
    "    #         state = optimizer.state[p]\n",
    "    #         if state:\n",
    "    #             print(f\"Parameter {p.device}, exp_avg: {state['exp_avg'].device}\")\n",
    "\n",
    "\n",
    "\n",
    "    train_loader, _ = get_data_loaders('./data')\n",
    "\n",
    "    # Precompute MACs and parameter contributions\n",
    "    macs_blocks, params_blocks, macs_fixed, params_fixed = calculate_block_contributions(model)\n",
    "\n",
    "    # Hyperparameters for penalties\n",
    "    lambda_macs = 1e-4  # Adjust based on scale of MACs\n",
    "    lambda_size = 1e-2  # Adjust based on scale of size\n",
    "\n",
    "    # Log initial architecture\n",
    "    print(\"Before Training Architecture:\", model.get_network_description())\n",
    "    initial_macs = macs_fixed + sum(torch.sigmoid(model.mask[i]) * macs_blocks[i] for i in range(7))\n",
    "    initial_size = (params_fixed + sum(torch.sigmoid(model.mask[i]) * params_blocks[i] for i in range(7))) * 4 / 1e6\n",
    "    print(f\"Initial MACs: {initial_macs:.2e}, Initial Size: {initial_size:.2f} MB\")\n",
    "\n",
    "    # Metric tracking lists\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    macs_list = []\n",
    "    sizes_list = []\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        loss, acc = train_with_constraints(model, train_loader, criterion, optimizer, device, lambda_macs, lambda_size, macs_blocks, params_blocks, macs_fixed, params_fixed)\n",
    "\n",
    "        # Compute current MACs and size for logging\n",
    "        mask_weights = torch.sigmoid(model.mask)\n",
    "        current_macs = macs_fixed + sum(mask_weights[i] * macs_blocks[i] for i in range(7))\n",
    "        current_size = (params_fixed + sum(mask_weights[i] * params_blocks[i] for i in range(7))) * 4 / 1e6\n",
    "\n",
    "        # Store metrics\n",
    "        # Append metrics, ensuring they are CPU scalars\n",
    "        losses.append(loss.item() if isinstance(loss, torch.Tensor) else loss)\n",
    "        accuracies.append(acc.item() if isinstance(acc, torch.Tensor) else acc)\n",
    "        macs_list.append(current_macs.cpu().item() if isinstance(current_macs, torch.Tensor) else current_macs)\n",
    "        sizes_list.append(current_size.cpu().item() if isinstance(current_size, torch.Tensor) else current_size)\n",
    "\n",
    "        logging.info(f\"Epoch {epoch+1}: Loss: {loss:.4f}, Accuracy: {acc:.2f}%, \"\n",
    "                     f\"MACs: {current_macs:.2e}, Size: {current_size:.2f} MB\")\n",
    "        logging.info(f\"Network: {model.get_network_description()}\")\n",
    "\n",
    "        # todo: implement stopping criteria here\n",
    "        # todo: currently stopped imidiately after the condition is met without any further training\n",
    "        # Check if thresholds are met\n",
    "        if current_macs <= mac_threshold and current_size <= size_threshold:\n",
    "            logging.info(\"Thresholds satisfied!\")\n",
    "            continue\n",
    "\n",
    "\n",
    "    torch.save(model.state_dict(), f\"output/structural_prune_after_train_mobile_net_v2.pth\")\n",
    "    #convert_to_onnx(model, f\"output/onnx/after_train_mobile_net_v2.onnx\")\n",
    "    # Log final architecture\n",
    "    final_mask_weights = torch.sigmoid(model.mask)\n",
    "    final_macs = macs_fixed + sum(final_mask_weights[i] * macs_blocks[i] for i in range(7))\n",
    "    final_size = (params_fixed + sum(final_mask_weights[i] * params_blocks[i] for i in range(7))) * 4 / 1e6\n",
    "    print(f\"Final Architecture: {model.get_network_description()}\")\n",
    "    print(f\"Final MACs: {final_macs:.2e}, Final Size: {final_size:.2f} MB\")\n",
    "    # Plot the metrics\n",
    "    plot_metrics(len(losses), losses, accuracies, macs_list, sizes_list)\n",
    "    \"\"\"\n",
    "    example_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "    onnx_path = f\"output/onnx/structural_prune_after_train_mobile_net_v2.onnx\"\n",
    "\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        example_input,\n",
    "        onnx_path,\n",
    "        export_params=True,\n",
    "        opset_version=12,\n",
    "        do_constant_folding=True,\n",
    "        input_names=['input'],\n",
    "        output_names=['output'],\n",
    "        dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    "    )\n",
    "    print(f\"✅ Model saved as ONNX to {onnx_path}\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(example_input)\n",
    "        print(output.shape)\n",
    "    \"\"\"\n"
   ],
   "id": "a081dfa8d469688a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "aae6043192cf82dc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Structural Pruning",
   "id": "47b173af29bb95b2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Seed Network",
   "id": "354ebe46f66b305"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T19:09:47.797077Z",
     "start_time": "2025-04-02T19:09:47.791983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, expansion=6):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.use_res_connect = self.stride == 1 and in_channels == out_channels\n",
    "\n",
    "        # Standard PyTorch layers (NO torch_pruning wrappers needed)\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels * expansion, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels * expansion)\n",
    "        self.relu = nn.ReLU6(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels * expansion, in_channels * expansion, kernel_size=3,\n",
    "            stride=stride, padding=1, groups=in_channels * expansion, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels * expansion)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels * expansion, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x if self.use_res_connect else None\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.use_res_connect:\n",
    "            return identity + out\n",
    "        else:\n",
    "            return out"
   ],
   "id": "a24b84a3da910fbd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Mask Network",
   "id": "3b79a870c0525a46"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T19:05:10.048906Z",
     "start_time": "2025-04-02T19:05:10.042694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        # --- Remove mask-related parameters ---\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU6(inplace=True)\n",
    "\n",
    "        # Define blocks (no mask_index or mask)\n",
    "        self.block1 = InvertedResidual(32, 16, stride=1)\n",
    "        self.block2 = InvertedResidual(16, 24, stride=2)\n",
    "        self.block3 = InvertedResidual(24, 32, stride=2)\n",
    "        self.block4 = InvertedResidual(32, 64, stride=2)\n",
    "        self.block5 = InvertedResidual(64, 96, stride=1)\n",
    "        self.block6 = InvertedResidual(96, 160, stride=2)\n",
    "        self.block7 = InvertedResidual(160, 320, stride=1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(1280)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(1280, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # --- Remove mask-based block skipping ---\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "        x = self.block7(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "id": "4ff2c1a222fd8925",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Save model as ONNX",
   "id": "f9ffae637a847074"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T19:23:27.432470Z",
     "start_time": "2025-04-02T19:23:27.428630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_model_as_onnx(model, example_input, output_path):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    # Export to ONNX\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        example_input,\n",
    "        output_path,\n",
    "        export_params=True,\n",
    "        opset_version=13,\n",
    "        input_names=['input'],\n",
    "        output_names=['output'],\n",
    "        dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    "    )\n",
    "    print(f\"✅ Model saved as ONNX to {output_path}\")"
   ],
   "id": "d2728bbcf95c1cf8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Main function for Pruning",
   "id": "c5d82a9106f08621"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T19:31:16.770477Z",
     "start_time": "2025-04-02T19:29:08.847751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_pruning as tp\n",
    "from torch import optim\n",
    "from cnn.resNet.resnet_example import get_data_loaders\n",
    "\n",
    "def calculate_macs(model, example_input):\n",
    "    macs, params = tp.utils.count_ops_and_params(model, example_input)\n",
    "    return macs\n",
    "\n",
    "\n",
    "def prune_model(model, example_input, target_macs):\n",
    "    # 1. Define pruning ratio based on MACs\n",
    "    current_macs = calculate_macs(model, example_input)\n",
    "    macs_sparsity = 1 - (target_macs / current_macs)\n",
    "\n",
    "    # todo: can Implement different pruner strategies here based on the importance scoring function,\n",
    "    # todo: ref: main_imagenet.py file of a torch_pruning repo\n",
    "    # 2. Initialize pruner\n",
    "    pruner = tp.pruner.MagnitudePruner(\n",
    "        model,\n",
    "        example_input,\n",
    "        importance=tp.importance.MagnitudeImportance(p=2),  # L2 norm\n",
    "        ch_sparsity= 0.5, # todo: I can set different sparsity for each layer,  I will apply sparsity based on the macs and flops\n",
    "        root_module_types=[nn.Conv2d, nn.Linear],  # Layers to prune\n",
    "        ignored_layers=[model.fc],  # DO NOT prune the final classifier!\n",
    "    )\n",
    "\n",
    "    # 3. Prune\n",
    "    pruner.step()\n",
    "\n",
    "    return model\n",
    "\n",
    "def print_model_metrics(model, example_input, label):\n",
    "    macs = calculate_macs(model, example_input)\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    size_mb = params * 4 / 1e6  # 4 bytes per float32\n",
    "    print(f\"{label}: MACs={macs:.2e}, Size={size_mb:.2f} MB\")\n",
    "\n",
    "# Usage in main():\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, device, num_epochs=20):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in train_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # todo: try to set different optimizer after pruning , early stopping, scheduler, # of epochs for fine tuning, pruning\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}: Loss={epoch_loss:.4f}, Accuracy={epoch_acc:.2f}%\")\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MobileNetV2(num_classes=10).to(device)\n",
    "    example_input = torch.randn(1, 3, 32, 32).to(device)  # CIFAR-10 input shape\n",
    "\n",
    "    # Save initial model (before pruning)\n",
    "    torch.save(model.state_dict(), \"output/mobilenetv2_before_pruning.pth\")\n",
    "    save_model_as_onnx(model, example_input, \"output/onnx/mobilenetv2_before_pruning.onnx\")\n",
    "\n",
    "    # Train and prune\n",
    "    train_loader, test_loader = get_data_loaders('./data')\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    model = train_model(model, train_loader, criterion, optimizer, device, num_epochs=10)\n",
    "\n",
    "    # Prune\n",
    "    initial_macs = calculate_macs(model, example_input)\n",
    "    target_macs = initial_macs // 2\n",
    "    print_model_metrics(model, example_input, \"Before Pruning\")\n",
    "    model = prune_model(model, example_input, target_macs)\n",
    "    print_model_metrics(model, example_input, \"After Pruning\")\n",
    "    # Save pruned model\n",
    "    torch.save(model.state_dict(), \"output/mobilenetv2_after_pruning.pth\")\n",
    "    save_model_as_onnx(model, example_input, \"output/mobilenetv2_after_pruning.onnx\")\n",
    "\n",
    "    # Fine-tune and save final model\n",
    "    model = train_model(model, train_loader, criterion, optimizer, device, num_epochs=10)\n",
    "    torch.save(model.state_dict(), \"output/mobilenetv2_final.pth\")\n",
    "    save_model_as_onnx(model, example_input, \"output/mobilenetv2_final.onnx\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "31dbf996f0b7b17e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved as ONNX to output/mobilenetv2_before_pruning.onnx\n",
      "Using dataset directory: /home/muis/thesis/github-repo/master-thesis/cnn/mobile_net_v2/data\n",
      "Epoch 1: Loss=1.6700, Accuracy=38.68%\n",
      "Epoch 2: Loss=1.2926, Accuracy=53.77%\n",
      "Epoch 3: Loss=1.1241, Accuracy=60.28%\n",
      "Epoch 4: Loss=0.9963, Accuracy=65.26%\n",
      "Epoch 5: Loss=0.9004, Accuracy=68.39%\n",
      "Epoch 6: Loss=0.8265, Accuracy=71.05%\n",
      "Epoch 7: Loss=0.7562, Accuracy=73.67%\n",
      "Epoch 8: Loss=0.7054, Accuracy=75.24%\n",
      "Epoch 9: Loss=0.6582, Accuracy=77.14%\n",
      "Epoch 10: Loss=0.6139, Accuracy=78.47%\n",
      "Before Pruning: MACs=6.06e+06, Size=4.68 MB\n",
      "After Pruning: MACs=1.84e+06, Size=1.22 MB\n",
      "✅ Model saved as ONNX to output/mobilenetv2_after_pruning.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muis/.virtualenvs/master-thesis/lib/python3.12/site-packages/torch_pruning/pruner/algorithms/base_pruner.py:87: UserWarning: ch_sparsity is deprecated in v1.3.0. Please use pruning_ratio.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=4.2010, Accuracy=20.21%\n",
      "Epoch 2: Loss=4.1631, Accuracy=20.47%\n",
      "Epoch 3: Loss=4.1648, Accuracy=20.54%\n",
      "Epoch 4: Loss=4.1589, Accuracy=20.54%\n",
      "Epoch 5: Loss=4.1633, Accuracy=20.63%\n",
      "Epoch 6: Loss=4.1515, Accuracy=20.66%\n",
      "Epoch 7: Loss=4.1579, Accuracy=20.66%\n",
      "Epoch 8: Loss=4.1605, Accuracy=20.71%\n",
      "Epoch 9: Loss=4.1630, Accuracy=20.70%\n",
      "Epoch 10: Loss=4.1623, Accuracy=20.57%\n",
      "✅ Model saved as ONNX to output/mobilenetv2_final.onnx\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T19:31:34.693160Z",
     "start_time": "2025-04-02T19:31:34.681316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import netron\n",
    "netron.start(\"output/mobilenetv2_before_pruning.onnx\")  # Before pruning\n",
    "netron.start(\"output/mobilenetv2_after_pruning.onnx\")   # After pruning"
   ],
   "id": "96ea6d6d2e9c872e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'output/mobilenetv2_before_pruning.onnx' at http://localhost:8080\n",
      "Serving 'output/mobilenetv2_after_pruning.onnx' at http://localhost:8081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('localhost', 8081)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
