{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## import necessary libraries for pruning",
   "id": "757f942cf3b37399"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:50:18.567757Z",
     "start_time": "2025-04-07T12:50:15.634313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_pruning as tp\n",
    "from torch import optim\n",
    "from cnn.resNet.resnet_example import get_data_loaders\n",
    "import torch\n",
    "from torch import nn"
   ],
   "id": "e290ea0d2979ffd0",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Structural Pruning",
   "id": "47b173af29bb95b2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Seed Network",
   "id": "354ebe46f66b305"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:50:47.389271Z",
     "start_time": "2025-04-07T12:50:47.382903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, expansion=6):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.use_res_connect = self.stride == 1 and in_channels == out_channels\n",
    "\n",
    "        # Standard PyTorch layers (NO torch_pruning wrappers needed)\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels * expansion, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels * expansion)\n",
    "        self.relu = nn.ReLU6(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels * expansion, in_channels * expansion, kernel_size=3,\n",
    "            stride=stride, padding=1, groups=in_channels * expansion, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels * expansion)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels * expansion, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x if self.use_res_connect else None\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.use_res_connect:\n",
    "            return identity + out\n",
    "        else:\n",
    "            return out"
   ],
   "id": "a24b84a3da910fbd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Mask Network",
   "id": "3b79a870c0525a46"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:50:52.501761Z",
     "start_time": "2025-04-07T12:50:52.495684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        # --- Remove mask-related parameters ---\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU6(inplace=True)\n",
    "\n",
    "        # Define blocks (no mask_index or mask)\n",
    "        self.block1 = InvertedResidual(32, 16, stride=1)\n",
    "        self.block2 = InvertedResidual(16, 24, stride=2)\n",
    "        self.block3 = InvertedResidual(24, 32, stride=2)\n",
    "        self.block4 = InvertedResidual(32, 64, stride=2)\n",
    "        self.block5 = InvertedResidual(64, 96, stride=1)\n",
    "        self.block6 = InvertedResidual(96, 160, stride=2)\n",
    "        self.block7 = InvertedResidual(160, 320, stride=1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(1280)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(1280, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # --- Remove mask-based block skipping ---\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "        x = self.block7(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "id": "4ff2c1a222fd8925",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Save model as ONNX",
   "id": "f9ffae637a847074"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:51:05.937994Z",
     "start_time": "2025-04-07T12:51:05.934252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_model_as_onnx(model, example_input, output_path):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    # Export to ONNX\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        example_input,\n",
    "        output_path,\n",
    "        export_params=True,\n",
    "        opset_version=13,\n",
    "        input_names=['input'],\n",
    "        output_names=['output'],\n",
    "        dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    "    )\n",
    "    print(f\"âœ… Model saved as ONNX to {output_path}\")"
   ],
   "id": "d2728bbcf95c1cf8",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Calculate MACs",
   "id": "10f9e1fbd42f1d81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:51:09.359784Z",
     "start_time": "2025-04-07T12:51:09.356604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_macs(model, example_input):\n",
    "    macs, params = tp.utils.count_ops_and_params(model, example_input)\n",
    "    return macs"
   ],
   "id": "8ecefbc13515ddd4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Magnitude-Pruner as Importance function for Pruning",
   "id": "c5d82a9106f08621"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def prune_model(model, example_input, target_macs):\n",
    "    # 1. Define pruning ratio based on MACs\n",
    "    current_macs = calculate_macs(model, example_input)\n",
    "    macs_sparsity = 1 - (target_macs / current_macs)\n",
    "\n",
    "    # todo: can Implement different pruner strategies here based on the importance scoring function,\n",
    "    # todo: ref: main_imagenet.py file of a torch_pruning repo\n",
    "    #model.eval()\n",
    "    # 2. Initialize pruner\n",
    "    pruner = tp.pruner.MagnitudePruner(\n",
    "        model,\n",
    "        example_input,\n",
    "        importance=tp.importance.MagnitudeImportance(p=2),  # L2 norm\n",
    "        ch_sparsity= 0.5, # todo: I can set different sparsity for each layer,  I will apply sparsity based on the macs and flops\n",
    "        root_module_types=[nn.Conv2d, nn.Linear],  # Layers to prune\n",
    "        ignored_layers=[model.fc],  # DO NOT prune the final classifier!\n",
    "    )\n",
    "\n",
    "    # 3. Prune\n",
    "    pruner.step()\n",
    "\n",
    "    return model"
   ],
   "id": "f4e1b85d497cffb7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define Strategy-to-Pruner Mapping",
   "id": "4eccd0d9be97ba2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T21:03:48.605825Z",
     "start_time": "2025-04-07T21:03:48.579645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_pruning import (\n",
    "    pruner,\n",
    "    importance\n",
    ")\n",
    "\n",
    "STRATEGIES = {\n",
    "    'magnitude': {\n",
    "        'pruner': pruner.MagnitudePruner,\n",
    "        'importance': importance.MagnitudeImportance(p=2),  # L2 norm\n",
    "    },\n",
    "    'bn_scale': {\n",
    "        'pruner': pruner.BNScalePruner,\n",
    "        'importance': importance.BNScaleImportance(),\n",
    "    },\n",
    "    'group_norm': {\n",
    "        'pruner': pruner.GroupNormPruner,\n",
    "        'importance': importance.GroupNormImportance(p=2),  # L2 norm\n",
    "    },\n",
    "    'random': {\n",
    "        'pruner': pruner.RandomPruner,\n",
    "        'importance': importance.RandomImportance(),\n",
    "    }\n",
    "}"
   ],
   "id": "32b4fe8aaed4e4bb",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch_pruning.pruner.importance' has no attribute 'GroupNormImportance'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[29]\u001B[39m\u001B[32m, line 17\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch_pruning\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m      2\u001B[39m     pruner,\n\u001B[32m      3\u001B[39m     importance\n\u001B[32m      4\u001B[39m )\n\u001B[32m      6\u001B[39m STRATEGIES = {\n\u001B[32m      7\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mmagnitude\u001B[39m\u001B[33m'\u001B[39m: {\n\u001B[32m      8\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mpruner\u001B[39m\u001B[33m'\u001B[39m: pruner.MagnitudePruner,\n\u001B[32m      9\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mimportance\u001B[39m\u001B[33m'\u001B[39m: importance.MagnitudeImportance(p=\u001B[32m2\u001B[39m),  \u001B[38;5;66;03m# L2 norm\u001B[39;00m\n\u001B[32m     10\u001B[39m     },\n\u001B[32m     11\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mbn_scale\u001B[39m\u001B[33m'\u001B[39m: {\n\u001B[32m     12\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mpruner\u001B[39m\u001B[33m'\u001B[39m: pruner.BNScalePruner,\n\u001B[32m     13\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mimportance\u001B[39m\u001B[33m'\u001B[39m: importance.BNScaleImportance(),\n\u001B[32m     14\u001B[39m     },\n\u001B[32m     15\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mgroup_norm\u001B[39m\u001B[33m'\u001B[39m: {\n\u001B[32m     16\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mpruner\u001B[39m\u001B[33m'\u001B[39m: pruner.GroupNormPruner,\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mimportance\u001B[39m\u001B[33m'\u001B[39m: \u001B[43mimportance\u001B[49m\u001B[43m.\u001B[49m\u001B[43mGroupNormImportance\u001B[49m(p=\u001B[32m2\u001B[39m),  \u001B[38;5;66;03m# L2 norm\u001B[39;00m\n\u001B[32m     18\u001B[39m     },\n\u001B[32m     19\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mrandom\u001B[39m\u001B[33m'\u001B[39m: {\n\u001B[32m     20\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mpruner\u001B[39m\u001B[33m'\u001B[39m: pruner.RandomPruner,\n\u001B[32m     21\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mimportance\u001B[39m\u001B[33m'\u001B[39m: importance.RandomImportance(),\n\u001B[32m     22\u001B[39m     }\n\u001B[32m     23\u001B[39m }\n",
      "\u001B[31mAttributeError\u001B[39m: module 'torch_pruning.pruner.importance' has no attribute 'GroupNormImportance'"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prune with different strategies",
   "id": "3ab54a4a53a64822"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T21:05:15.333297Z",
     "start_time": "2025-04-07T21:05:15.327678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prune_with_strategies(model, example_input, target_macs, strategies):\n",
    "    results = {}\n",
    "    original_state = model.state_dict().copy()\n",
    "\n",
    "    for strategy_name in strategies:\n",
    "        # Reset model to original state\n",
    "        model.load_state_dict(original_state)\n",
    "\n",
    "        # Clone model for this strategy\n",
    "        model_copy = tp.utils.clone_model(model)\n",
    "\n",
    "        # Initialize pruner for this strategy\n",
    "        strategy = STRATEGIES[strategy_name]\n",
    "        pruner_class = strategy['pruner']\n",
    "        importance = strategy['importance']\n",
    "\n",
    "        pruner = pruner_class(\n",
    "            model_copy,\n",
    "            example_input,\n",
    "            importance=importance,\n",
    "            ch_sparsity=0.5,  # Target 50% sparsity\n",
    "            root_module_types=[nn.Conv2d],  # Target Conv2d layers\n",
    "            ignored_layers=[model_copy.fc],  # Skip classifier\n",
    "        )\n",
    "        pruner.step()  # Execute pruning\n",
    "\n",
    "        # Calculate metrics\n",
    "        macs = calculate_macs(model_copy, example_input)\n",
    "        params = sum(p.numel() for p in model_copy.parameters())\n",
    "        size_mb = params * 4 / 1e6\n",
    "\n",
    "        results[strategy_name] = {\n",
    "            'macs': macs,\n",
    "            'size_mb': size_mb,\n",
    "            'accuracy': None\n",
    "        }\n",
    "\n",
    "        # Save pruned model\n",
    "        torch.save(model_copy.state_dict(), f\"output/mobilenetv2_{strategy_name}.pth\")\n",
    "\n",
    "    return results"
   ],
   "id": "565e7a3ce29eeb37",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Compare Pruning Strategies results",
   "id": "d150297f3700265d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compare_results(results, test_loader, device):\n",
    "    for strategy_name, metrics in results.items():\n",
    "        # Rebuild model\n",
    "        model = MobileNetV2(num_classes=10).to(device)\n",
    "        model.load_state_dict(torch.load(f\"output/mobilenetv2_{strategy_name}.pth\"))\n",
    "\n",
    "        # Test accuracy\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        metrics['accuracy'] = 100 * correct / total\n",
    "        print(f\"{strategy_name}:\")\n",
    "        print(f\"  MACs: {metrics['macs']:.2e}\")\n",
    "        print(f\"  Size: {metrics['size_mb']:.2f} MB\")\n",
    "        print(f\"  Accuracy: {metrics['accuracy']:.2f}%\")\n",
    "        print(\"-\" * 40)"
   ],
   "id": "18154f4cc384ff46"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Print Model Metrics",
   "id": "446f47b679a8a586"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:51:15.165931Z",
     "start_time": "2025-04-07T12:51:15.162308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_model_metrics(model, example_input, label):\n",
    "    macs = calculate_macs(model, example_input)\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    size_mb = params * 4 / 1e6  # 4 bytes per float32\n",
    "    print(f\"{label}: MACs={macs:.2e}, Size={size_mb:.2f} MB\")"
   ],
   "id": "23d858c712419dec",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Training",
   "id": "e9ac3f0474d15ef5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:51:26.580492Z",
     "start_time": "2025-04-07T12:51:26.574997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, device, num_epochs=20):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in train_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # todo: try to set different optimizer after pruning , early stopping, scheduler, # of epochs for fine tuning, pruning\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}: Loss={epoch_loss:.4f}, Accuracy={epoch_acc:.2f}%\")\n",
    "    return model"
   ],
   "id": "4aab40f9c70ebb71",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Main function",
   "id": "b3b64f23fed5d12"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pprint\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MobileNetV2(num_classes=10).to(device)\n",
    "example_input = torch.randn(1, 3, 32, 32).to(device)  # CIFAR-10 input shape\n",
    "\n",
    "DG = tp.DependencyGraph().build_dependency(model, example_inputs=example_input, verbose=True)\n",
    "all_groups = list(DG.get_all_groups())\n",
    "#print(\"Number of Groups: %d\"%len(all_groups))\n",
    "#print(\"The last Group:\", all_groups[-1])\n",
    "\n",
    "for key in all_groups:\n",
    "    print(f\"{key}\")\n",
    "\n",
    "# tp.utils.draw_dependency_graph(DG, save_as='output/draw_dep_graph.png', title=None)\n",
    "# tp.utils.draw_groups(DG, save_as='output/draw_groups.png', title=None)\n",
    "# tp.utils.draw_computational_graph(DG, save_as='output/draw_comp_graph.png', title=None)\n"
   ],
   "id": "bce1f3369d907d97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MobileNetV2(num_classes=10).to(device)\n",
    "    example_input = torch.randn(1, 3, 32, 32).to(device)  # CIFAR-10 input shape\n",
    "\n",
    "    # Save initial model (before pruning)\n",
    "    torch.save(model.state_dict(), \"output/mobilenetv2_before_pruning.pth\")\n",
    "    save_model_as_onnx(model, example_input, \"output/onnx/mobilenetv2_before_pruning.onnx\")\n",
    "\n",
    "    # Train and prune\n",
    "    train_loader, test_loader = get_data_loaders('./data')\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    model = train_model(model, train_loader, criterion, optimizer, device, num_epochs=10)\n",
    "\n",
    "    # Prune\n",
    "    initial_macs = calculate_macs(model, example_input)\n",
    "    target_macs = initial_macs // 2\n",
    "    print_model_metrics(model, example_input, \"Before Pruning\")\n",
    "    model = prune_model(model, example_input, target_macs)\n",
    "    print_model_metrics(model, example_input, \"After Pruning\")\n",
    "    # Save pruned model\n",
    "    torch.save(model.state_dict(), \"output/mobilenetv2_after_pruning.pth\")\n",
    "    save_model_as_onnx(model, example_input, \"output/mobilenetv2_after_pruning.onnx\")\n",
    "\n",
    "    # Fine-tune and save final model\n",
    "    model = train_model(model, train_loader, criterion, optimizer, device, num_epochs=10)\n",
    "    torch.save(model.state_dict(), \"output/mobilenetv2_final.pth\")\n",
    "    save_model_as_onnx(model, example_input, \"output/mobilenetv2_final.onnx\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "31dbf996f0b7b17e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualize the model",
   "id": "11d8a3b9e42d08bd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T19:31:34.693160Z",
     "start_time": "2025-04-02T19:31:34.681316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import netron\n",
    "netron.start(\"output/mobilenetv2_before_pruning.onnx\")  # Before pruning\n",
    "netron.start(\"output/mobilenetv2_after_pruning.onnx\")   # After pruning"
   ],
   "id": "96ea6d6d2e9c872e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'output/mobilenetv2_before_pruning.onnx' at http://localhost:8080\n",
      "Serving 'output/mobilenetv2_after_pruning.onnx' at http://localhost:8081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('localhost', 8081)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
