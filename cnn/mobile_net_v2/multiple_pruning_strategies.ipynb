{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "377de838",
   "metadata": {},
   "source": [
    "## import necessary libraries for pruning"
   ]
  },
  {
   "cell_type": "code",
   "id": "7b6381473b81b890",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T13:16:39.913062Z",
     "start_time": "2025-05-15T13:16:39.909091Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_pruning as tp\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "from torch_pruning.pruner.algorithms.scheduler import linear_scheduler\n",
    "from torchsummary import summary\n",
    "\n",
    "from cnn.resNet.resnet_example import get_data_loaders\n",
    "import torch\n",
    "from torch import nn"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "id": "631981174f5d8d8a",
   "metadata": {},
   "source": [
    "### Seed Network"
   ]
  },
  {
   "cell_type": "code",
   "id": "248e7c99c6815764",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T11:13:49.325015Z",
     "start_time": "2025-05-15T11:13:49.320096Z"
    }
   },
   "source": [
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, expansion=6):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.use_res_connect = self.stride == 1 and in_channels == out_channels\n",
    "\n",
    "        # Standard PyTorch layers (NO torch_pruning wrappers needed)\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels * expansion, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels * expansion)\n",
    "        self.relu = nn.ReLU6(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels * expansion, in_channels * expansion, kernel_size=3,\n",
    "            stride=stride, padding=1, groups=in_channels * expansion, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels * expansion)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels * expansion, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x if self.use_res_connect else None\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.use_res_connect:\n",
    "            return identity + out\n",
    "        else:\n",
    "            return out"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "6431a8ad17e1d446",
   "metadata": {},
   "source": [
    "### Mask Network"
   ]
  },
  {
   "cell_type": "code",
   "id": "4da304cf4cf9f871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T11:13:52.315960Z",
     "start_time": "2025-05-15T11:13:52.308772Z"
    }
   },
   "source": [
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        # --- Remove mask-related parameters ---\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU6(inplace=True)\n",
    "\n",
    "        # Define blocks (no mask_index or mask)\n",
    "        self.block1 = InvertedResidual(32, 16, stride=1)\n",
    "        self.block2 = InvertedResidual(16, 24, stride=2)\n",
    "        self.block3 = InvertedResidual(24, 32, stride=2)\n",
    "        self.block4 = InvertedResidual(32, 64, stride=2)\n",
    "        self.block5 = InvertedResidual(64, 96, stride=1)\n",
    "        self.block6 = InvertedResidual(96, 160, stride=2)\n",
    "        self.block7 = InvertedResidual(160, 320, stride=1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(1280)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(1280, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # --- Remove mask-based block skipping ---\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "        x = self.block7(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "4ad82bf3520f8612",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T11:13:54.990947Z",
     "start_time": "2025-05-15T11:13:54.949339Z"
    }
   },
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "7ebb1e087d2f0cd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T11:13:56.302735Z",
     "start_time": "2025-05-15T11:13:56.296690Z"
    }
   },
   "source": [
    "def save_model_as_onnx(model, example_input, output_path):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    # Export to ONNX\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        example_input,\n",
    "        output_path,\n",
    "        export_params=True,\n",
    "        opset_version=13,\n",
    "        input_names=['input'],\n",
    "        output_names=['output'],\n",
    "        dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    "    )\n",
    "    print(f\"✅ Model saved as ONNX to {output_path}\")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "3e9a817a37b770da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T11:13:58.328096Z",
     "start_time": "2025-05-15T11:13:58.323868Z"
    }
   },
   "source": [
    "def calculate_macs(model, example_input):\n",
    "    macs, params = tp.utils.count_ops_and_params(model, example_input)\n",
    "    return macs, params"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "5b29391c83349f69",
   "metadata": {},
   "source": [
    "### compare results of different pruning strategies"
   ]
  },
  {
   "cell_type": "code",
   "id": "becad7e59744f0dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T11:13:59.578723Z",
     "start_time": "2025-05-15T11:13:59.574462Z"
    }
   },
   "source": [
    "def compare_results(results):\n",
    "    print(\"\\n=== Pruning Strategy Comparison ===\")\n",
    "    print(f\"{'Strategy':<12} | {'MACs':<12} | {'Size (MB)':<10} | {'Accuracy (%)':<12}\")\n",
    "    print(\"-\" * 55)\n",
    "    for strategy, metrics in results.items():\n",
    "        print(f\"{strategy:<12} | {metrics['macs']:.2e} | {metrics['size_mb']:>9.2f} | {metrics['accuracy']:>12.2f}\")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "df0e1911de55ade6",
   "metadata": {},
   "source": [
    "### compare and plot results"
   ]
  },
  {
   "cell_type": "code",
   "id": "5feb4387794b8311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T13:16:48.988204Z",
     "start_time": "2025-05-15T13:16:48.975208Z"
    }
   },
   "source": [
    "def compare_results_and_plot(results_dict, strategies_config, output_dir='output'):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    metrics_data = results_dict\n",
    "\n",
    "    print(\"\\n=== Pruning Strategy Comparison ===\")\n",
    "    header = f\"{'Strategy':<35} | {'MACs':<12} | {'Params':<12} | {'Size (MiB)':<10} | {'Accuracy (%)':<12}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "\n",
    "    if 'initial' in metrics_data:\n",
    "        strat_name = 'initial'\n",
    "        metrics = metrics_data[strat_name]\n",
    "        print(f\"{strat_name:<35} | {metrics['macs']:.2e} | {metrics['params']:.2e} | {metrics['size_mib']:>9.2f} | {metrics['accuracy']:>12.2f}\")\n",
    "\n",
    "    sorted_strategy_keys = sorted(strategies_config.keys())\n",
    "\n",
    "    for strategy_key_orig in sorted_strategy_keys:\n",
    "        strat_name_pruned = f\"{strategy_key_orig}_pruned_not_finetuned\"\n",
    "        if strat_name_pruned in metrics_data:\n",
    "            metrics = metrics_data[strat_name_pruned]\n",
    "            print(f\"{strat_name_pruned:<35} | {metrics['macs']:.2e} | {metrics['params']:.2e} | {metrics['size_mib']:>9.2f} | {metrics['accuracy']:>12.2f}\")\n",
    "\n",
    "        strat_name_final = strategy_key_orig\n",
    "        if strat_name_final in metrics_data:\n",
    "            metrics = metrics_data[strat_name_final]\n",
    "            print(f\"{strat_name_final:<35} | {metrics['macs']:.2e} | {metrics['params']:.2e} | {metrics['size_mib']:>9.2f} | {metrics['accuracy']:>12.2f}\")\n",
    "\n",
    "    plot_strategies_final_names = ['initial'] + sorted_strategy_keys\n",
    "\n",
    "    metric_keys_to_plot = ['macs', 'params', 'size_mib', 'accuracy']\n",
    "    titles = {\n",
    "        'macs': 'MACs Comparison (Final Models)',\n",
    "        'params': 'Parameters Comparison (Final Models)',\n",
    "        'size_mib': 'Model Size (MiB) Comparison (Final Models)',\n",
    "        'accuracy': 'Accuracy (%) Comparison (Final Models)'\n",
    "    }\n",
    "    y_labels = {\n",
    "        'macs': 'MACs',\n",
    "        'params': 'Parameters',\n",
    "        'size_mib': 'Size (MiB)',\n",
    "        'accuracy': 'Accuracy (%)'\n",
    "    }\n",
    "\n",
    "    num_strategies_for_plot = len(plot_strategies_final_names)\n",
    "\n",
    "    # Fix for MatplotlibDeprecationWarning and color generation\n",
    "    colors_cmap = plt.colormaps.get_cmap('tab10') # Get the colormap object\n",
    "\n",
    "    for metric_key in metric_keys_to_plot:\n",
    "        values = []\n",
    "        valid_strategies_for_plot = []\n",
    "        for strategy_name_for_plot in plot_strategies_final_names:\n",
    "            if strategy_name_for_plot in metrics_data:\n",
    "                actual_key_in_results = strategy_name_for_plot\n",
    "                if actual_key_in_results in metrics_data and metric_key in metrics_data[actual_key_in_results]:\n",
    "                    values.append(metrics_data[actual_key_in_results][metric_key])\n",
    "                    valid_strategies_for_plot.append(strategy_name_for_plot)\n",
    "\n",
    "        if not values:\n",
    "            print(f\"Skipping plot for {metric_key} as no data was found.\")\n",
    "            continue\n",
    "\n",
    "        plt.figure(figsize=(max(12, int(1.5 * len(valid_strategies_for_plot))), 7)) # Dynamic width, ensure int\n",
    "\n",
    "        # Generate colors for the valid strategies being plotted\n",
    "        bar_colors = [colors_cmap(i % colors_cmap.N) for i in range(len(valid_strategies_for_plot))]\n",
    "        bars = plt.bar(valid_strategies_for_plot, values, color=bar_colors)\n",
    "\n",
    "        plt.xlabel('Strategy')\n",
    "        plt.ylabel(y_labels[metric_key])\n",
    "        plt.title(titles[metric_key])\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "        for bar in bars:\n",
    "            yval = bar.get_height()\n",
    "            if metric_key in ['macs', 'params']:\n",
    "                 plt.text(bar.get_x() + bar.get_width()/2., yval, f'{yval:.2e}', ha='center', va='bottom')\n",
    "            else:\n",
    "                 plt.text(bar.get_x() + bar.get_width()/2., yval, f'{yval:.2f}', ha='center', va='bottom')\n",
    "\n",
    "        if 'initial' in metrics_data and metric_key in metrics_data['initial']:\n",
    "            initial_value = metrics_data['initial'][metric_key]\n",
    "            # Fix for ValueError: Invalid format specifier\n",
    "            if metric_key in [\"macs\", \"params\"]:\n",
    "                label_text = f'Initial ({initial_value:.2e})'\n",
    "            else:\n",
    "                label_text = f'Initial ({initial_value:.2f})'\n",
    "            plt.axhline(y=initial_value, color='r', linestyle='--', label=label_text)\n",
    "\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f'{metric_key}_comparison_final.png'))\n",
    "        plt.close()\n",
    "    print(f\"✅ Comparison plots saved to {output_dir}\")"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "23869493d2f36a72",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "615130e04992f7ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T11:14:10.966286Z",
     "start_time": "2025-05-15T11:14:10.961864Z"
    }
   },
   "source": [
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "bbd2e296738ea559",
   "metadata": {},
   "source": [
    "### Utility function to save the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "b7f8aa766a2fa06a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T11:14:13.129551Z",
     "start_time": "2025-05-15T11:14:13.124948Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "def save_model(model, path, example_input=None):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    torch.save(model.state_dict(), path)\n",
    "    if example_input is not None:\n",
    "        onnx_path = path.replace('.pth', '.onnx')\n",
    "        save_model_as_onnx(model, example_input, onnx_path)\n",
    "\n",
    "def load_model_state(model_class, path, device, *args, **kwargs):\n",
    "    # *args, **kwargs are for model_class constructor (e.g. num_classes)\n",
    "    model = model_class(*args, **kwargs)\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    model.to(device)\n",
    "    print(f\"✅ Model loaded from {path} to {device}\")\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "89740bc4e512ecde",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "5484dc87c1b63c28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T12:48:44.298326Z",
     "start_time": "2025-05-15T12:48:44.292367Z"
    }
   },
   "source": [
    "def evaluate_model(model, test_loader, example_input, device):\n",
    "    model.eval()\n",
    "    # Calculate metrics\n",
    "    macs, params = calculate_macs(model, example_input)\n",
    "    # params = sum(p.numel() for p in model.parameters())\n",
    "    size_mb = params * 4 / 1e6\n",
    "\n",
    "    # Calculate accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = [d.to(device) for d in data]\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total if total > 0 else 0\n",
    "    return {\n",
    "        'macs': macs,\n",
    "        'params': params,\n",
    "        'size_mib': size_mb,\n",
    "        'accuracy': accuracy\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "78f7147c66b6d346",
   "metadata": {},
   "source": [
    "### Prune the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "6532a7494fc3fcbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T11:14:23.126606Z",
     "start_time": "2025-05-15T11:14:23.120762Z"
    }
   },
   "source": [
    "def prune_model(model, example_input, target_macs, strategy, iterative_steps=5):\n",
    "    #, iterative_pruning_ratio_scheduler=linear_scheduler()):\n",
    "    if isinstance(strategy['importance'], tp.importance.TaylorImportance):\n",
    "        pruning_ratio = 0.1\n",
    "    else:\n",
    "        pruning_ratio = 0.5\n",
    "\n",
    "    pruner = strategy['pruner'](\n",
    "        model,\n",
    "        example_input,\n",
    "        importance=strategy['importance'],\n",
    "        iterative_steps=iterative_steps,\n",
    "        ch_sparsity=pruning_ratio,  # Initial sparsity\n",
    "        #iterative_pruning_ratio_scheduler=iterative_pruning_ratio_scheduler,\n",
    "        root_module_types=[nn.Conv2d],\n",
    "        ignored_layers=[model.fc],\n",
    "    )\n",
    "\n",
    "    current_macs, base_nparams = calculate_macs(model, example_input)\n",
    "    # while current_macs > target_macs:\n",
    "    #     pruner.step()\n",
    "    #     current_macs = calculate_macs(model, example_input)\n",
    "\n",
    "\n",
    "    for i in range(iterative_steps):\n",
    "            if isinstance(strategy['importance'], tp.importance.TaylorImportance):\n",
    "                loss = model(example_input).sum() # a dummy loss for TaylorImportance\n",
    "                loss.backward()\n",
    "            for g in pruner.step(interactive=True):\n",
    "                g.prune()\n",
    "            macs, nparams = tp.utils.count_ops_and_params(model, example_input)\n",
    "            #print(model(example_input).shape)\n",
    "            print(\n",
    "                \"  Iter %d/%d, Params: %.2f M => %.2f M\"\n",
    "                % (i + 1, iterative_steps, base_nparams / 1e6, nparams / 1e6)\n",
    "            )\n",
    "            print(\n",
    "                \"  Iter %d/%d, MACs: %.2f G => %.2f G\"\n",
    "                % (i + 1, iterative_steps, current_macs / 1e9, macs / 1e9)\n",
    "            )\n",
    "\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "6adb22651c74e5f0",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "a6e1edc8a36e5260",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T11:14:30.151466Z",
     "start_time": "2025-05-15T11:14:30.144597Z"
    }
   },
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, device, num_epochs, val_loader=None, strategy_name=\"\"):\n",
    "\n",
    "    model.to(device)\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs, labels = [d.to(device) for d in data]\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader) if len(train_loader) > 0 else 0\n",
    "        epoch_acc = 100 * correct_train / total_train if total_train > 0 else 0\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['train_acc'].append(epoch_acc)\n",
    "\n",
    "        log_msg = f\"Strategy: {strategy_name} - Epoch {epoch+1}/{num_epochs}: Train Loss={epoch_loss:.4f}, Train Acc={epoch_acc:.2f}%\"\n",
    "\n",
    "        if val_loader:\n",
    "            model.eval()\n",
    "            running_val_loss = 0.0\n",
    "            correct_val = 0\n",
    "            total_val = 0\n",
    "            with torch.no_grad():\n",
    "                for data_val in val_loader:\n",
    "                    inputs_val, labels_val = [d.to(device) for d in data_val]\n",
    "                    outputs_val = model(inputs_val)\n",
    "                    val_loss_item = criterion(outputs_val, labels_val)\n",
    "                    running_val_loss += val_loss_item.item()\n",
    "                    _, predicted_val = torch.max(outputs_val.data, 1)\n",
    "                    total_val += labels_val.size(0)\n",
    "                    correct_val += (predicted_val == labels_val).sum().item()\n",
    "\n",
    "            epoch_val_loss = running_val_loss / len(val_loader) if len(val_loader) > 0 else 0\n",
    "            epoch_val_acc = 100 * correct_val / total_val if total_val > 0 else 0\n",
    "            history['val_loss'].append(epoch_val_loss)\n",
    "            history['val_acc'].append(epoch_val_acc)\n",
    "            log_msg += f\", Val Loss={epoch_val_loss:.4f}, Val Acc={epoch_val_acc:.2f}%\"\n",
    "        else: # Ensure val_loss and val_acc have same length as train for plotting if no val\n",
    "            history['val_loss'].append(None)\n",
    "            history['val_acc'].append(None)\n",
    "        print(log_msg)\n",
    "    return model, history"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Plotting fine-tuning curves",
   "id": "336281ff4136c31"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T13:17:03.570657Z",
     "start_time": "2025-05-15T13:17:03.563592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_finetuning_curves(history, strategy_name, output_dir, model_macs):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history['train_loss'], 'bo-', label='Training Loss')\n",
    "    if history.get('val_loss') and any(v is not None for v in history['val_loss']):\n",
    "        plt.plot(epochs, history['val_loss'], 'ro-', label='Validation Loss')\n",
    "    plt.title(f'Loss vs. Epochs ({strategy_name})\\nMACs: {model_macs:.2e}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history['train_acc'], 'bo-', label='Training Accuracy')\n",
    "    if history.get('val_acc') and any(v is not None for v in history['val_acc']):\n",
    "        plt.plot(epochs, history['val_acc'], 'ro-', label='Validation Accuracy')\n",
    "    plt.title(f'Accuracy vs. Epochs ({strategy_name})\\nMACs: {model_macs:.2e}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plot_path = os.path.join(output_dir, f\"{strategy_name.replace(' ', '_').replace('/', '_')}_finetuning_curves.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "    print(f\"✅ Fine-tuning curves saved to {plot_path}\")"
   ],
   "id": "b4a43f15e22c98b2",
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "id": "b26416e6ff76416a",
   "metadata": {},
   "source": [
    "### Main workflow"
   ]
  },
  {
   "cell_type": "code",
   "id": "bdf93b3196076098",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T13:17:24.510630Z",
     "start_time": "2025-05-15T13:17:24.498448Z"
    }
   },
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'strategies': {\n",
    "            'magnitude': {\n",
    "                'pruner': tp.pruner.MagnitudePruner,\n",
    "                'importance': tp.importance.MagnitudeImportance(p=2),\n",
    "            },\n",
    "            'bn_scale': {\n",
    "                'pruner': tp.pruner.BNScalePruner,\n",
    "                'importance': tp.importance.BNScaleImportance(),\n",
    "            },\n",
    "            # todo: check the examples for the following strategies, why it is giving error\n",
    "            'group_norm': {\n",
    "                'pruner': tp.pruner.GroupNormPruner,\n",
    "                'importance': tp.importance.GroupMagnitudeImportance(p=1),\n",
    "            },\n",
    "            'random': {\n",
    "                'pruner': tp.pruner.MagnitudePruner,\n",
    "                'importance': tp.importance.RandomImportance(),\n",
    "            },\n",
    "            'Taylor': {\n",
    "                'pruner': tp.pruner.MagnitudePruner,\n",
    "                'importance': tp.importance.TaylorImportance()\n",
    "            },\n",
    "            'Hessian': {\n",
    "                'pruner': tp.pruner.MagnitudePruner,\n",
    "                'importance': tp.importance.GroupHessianImportance()\n",
    "            },\n",
    "            'lamp': {\n",
    "                'pruner': tp.pruner.MagnitudePruner,\n",
    "                'importance': tp.importance.LAMPImportance(p=2)\n",
    "            },\n",
    "            'geometry': {\n",
    "                'pruner': tp.pruner.MagnitudePruner,\n",
    "                'importance': tp.importance.FPGMImportance()\n",
    "            },\n",
    "            #todo: implement growing reg pruning\n",
    "        },\n",
    "        #todo: different types of schedulers can be added\n",
    "        #'iterative_pruning_ratio_scheduler': linear_scheduler(),\n",
    "        'target_macs_sparsity': 0.5,\n",
    "        'train_epochs': 10,\n",
    "        'fine_tune_epochs': 20,\n",
    "        'data_dir': './data',\n",
    "        'output_dir': './output/strategies',\n",
    "        'iterative_steps': 5,\n",
    "    }\n",
    "\n",
    "    # Initialize model and data\n",
    "    model = MobileNetV2(num_classes=10).to(device)\n",
    "    train_loader, test_loader = get_data_loaders(config['data_dir'])\n",
    "    example_input = torch.randn(1, 3, 32, 32).to(device) #fixed input\n",
    "\n",
    "    # Workflow execution\n",
    "    initial_model_path = os.path.join(config['output_dir'], \"mobilenetv2_initial.pth\")\n",
    "\n",
    "    if not os.path.exists(initial_model_path):\n",
    "        # 1. Initial training\n",
    "        model, _ = train_model(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            criterion=nn.CrossEntropyLoss().to(device),\n",
    "            optimizer=optim.Adam(model.parameters(), lr=0.001),\n",
    "            device=device,\n",
    "            num_epochs=config['train_epochs']\n",
    "        )\n",
    "        save_model(model, initial_model_path, example_input)\n",
    "\n",
    "    # 2. Pruning and evaluation workflow\n",
    "    results = {}\n",
    "    initial_metrics = evaluate_model(model, test_loader, example_input, device)\n",
    "    results['initial'] = initial_metrics\n",
    "\n",
    "    # Pruning and evaluation workflow\n",
    "    initial_macs, initial_params = calculate_macs(model, example_input)\n",
    "    target_macs = initial_macs * config['target_macs_sparsity']\n",
    "    print(f\"initial value: target_macs={target_macs:.2f}\")\n",
    "    for strategy_name in config['strategies']:\n",
    "        # 2a. Prepare fresh model for each strategy\n",
    "        model_copy = load_model(MobileNetV2(num_classes=10).to(device), initial_model_path)\n",
    "\n",
    "        # 2b. Perform pruning\n",
    "        \"\"\" this it normal pruning without threshold\n",
    "        pruned_model = prune_model(\n",
    "            model=model_copy,\n",
    "            example_input=example_input,\n",
    "            target_macs=target_macs,\n",
    "            strategy=config['strategies'][strategy_name],\n",
    "            iterative_steps=config['iterative_steps'],\n",
    "            #iterative_pruning_ratio_scheduler=config['iterative_pruning_ratio_scheduler'],\n",
    "        ) \"\"\"\n",
    "\n",
    "        pruned_model = gr_prune_model_with_threshold(\n",
    "            model=model_copy,\n",
    "            example_input=example_input,\n",
    "            target_macs=1e9,\n",
    "            target_size_mb=5,\n",
    "            strategy=config['strategies'][strategy_name],\n",
    "            iterative_steps=config['iterative_steps']\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        target_macs_value = 3.0e6\n",
    "        target_params_value = 5.0e6\n",
    "        pruned_model = gem_prune_model_by_threshold(\n",
    "            model=model_copy,\n",
    "            example_input=example_input,\n",
    "            target_macs=target_macs_value,     # <-- Pass target MACs\n",
    "            target_params=target_params_value, # <-- Pass target Params\n",
    "            strategy=config['strategies'][strategy_name],\n",
    "            max_iterations=100, # Adjust as needed\n",
    "            step_ch_sparsity=0.1 # Tune this - smaller might be safer but slower\n",
    "        )\n",
    "        \"\"\"\n",
    "        print(f\"--- Evaluating Pruned Model (Before Fine-tuning) for {strategy_name} ---\")\n",
    "        metrics_pruned_before_ft = evaluate_model(\n",
    "            pruned_model,\n",
    "            test_loader,\n",
    "            example_input,\n",
    "            device)\n",
    "        results[f\"{strategy_name}_pruned_not_finetuned\"] = metrics_pruned_before_ft\n",
    "        print(f\"Metrics for {strategy_name} (Pruned, Before FT): {metrics_pruned_before_ft}\")\n",
    "        pruned_bf_ft_path = os.path.join(config['output_dir'], f\"mobilenetv2_{strategy_name}_pruned_not_finetuned.pth\")\n",
    "        save_model(pruned_model, pruned_bf_ft_path, example_input=example_input)\n",
    "\n",
    "        # 2c. Save pruned model\n",
    "        pruned_path = os.path.join(config['output_dir'], f\"mobilenetv2_{strategy_name}_pruned.pth\")\n",
    "        save_model(pruned_model, pruned_path, example_input)\n",
    "\n",
    "        print(f\"--- Fine-tuning Pruned Model for {strategy_name} ---\")\n",
    "        # 2d. Fine-tune\n",
    "        # todo: lr, more epochs, early stopping\n",
    "        fine_tuned_model, finetuning_history = train_model(\n",
    "            model=pruned_model,\n",
    "            train_loader=train_loader,\n",
    "            criterion=nn.CrossEntropyLoss().to(device),\n",
    "            optimizer=optim.Adam(pruned_model.parameters(), lr=0.001),\n",
    "            device=device,\n",
    "            num_epochs=config['fine_tune_epochs'],\n",
    "            val_loader=test_loader,\n",
    "            strategy_name=strategy_name\n",
    "        )\n",
    "        # fine_tuned_model = train_model(\n",
    "        #     model=pruned_model,\n",
    "        #     train_loader=train_loader,\n",
    "        #     criterion=nn.CrossEntropyLoss().to(device),\n",
    "        #     optimizer=optim.Adam(pruned_model.parameters(), lr=0.001),\n",
    "        #     device=device,\n",
    "        #     num_epochs=config['fine_tune_epochs']\n",
    "        # )\n",
    "\n",
    "        # 2e. Evaluate\n",
    "        current_model_macs, _ = calculate_macs(fine_tuned_model, example_input)\n",
    "        plot_finetuning_curves(finetuning_history, strategy_name, config['output_dir'], current_model_macs)\n",
    "        print(f\"--- Evaluating Fine-tuned Model for {strategy_name} ---\")\n",
    "        final_metrics = evaluate_model(\n",
    "            model=fine_tuned_model,\n",
    "            test_loader=test_loader,\n",
    "            example_input=example_input,\n",
    "            device=device\n",
    "        )\n",
    "        results[strategy_name] = final_metrics\n",
    "        # 2f. Save final model\n",
    "        final_path = os.path.join(config['output_dir'], f\"mobilenetv2_{strategy_name}_final.pth\")\n",
    "        save_model(fine_tuned_model, final_path, example_input)\n",
    "\n",
    "    # 3. Compare results\n",
    "    compare_results_and_plot(results, config['strategies'],output_dir=config['output_dir'])\n",
    "    print(\"Workflow completed successfully!\")"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "6d51f760-3726-4028-98a7-02e0105ebd82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T13:38:00.001881Z",
     "start_time": "2025-05-15T13:17:37.381250Z"
    }
   },
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset directory: /home/muis/thesis/github-repo/master-thesis/cnn/mobile_net_v2/data\n",
      "Strategy:  - Epoch 1/10: Train Loss=1.6695, Train Acc=38.93%\n",
      "Strategy:  - Epoch 2/10: Train Loss=1.2928, Train Acc=53.76%\n",
      "Strategy:  - Epoch 3/10: Train Loss=1.1056, Train Acc=61.06%\n",
      "Strategy:  - Epoch 4/10: Train Loss=0.9676, Train Acc=66.08%\n",
      "Strategy:  - Epoch 5/10: Train Loss=0.8755, Train Acc=69.48%\n",
      "Strategy:  - Epoch 6/10: Train Loss=0.8023, Train Acc=72.04%\n",
      "Strategy:  - Epoch 7/10: Train Loss=0.7414, Train Acc=74.19%\n",
      "Strategy:  - Epoch 8/10: Train Loss=0.6926, Train Acc=75.61%\n",
      "Strategy:  - Epoch 9/10: Train Loss=0.6443, Train Acc=77.22%\n",
      "Strategy:  - Epoch 10/10: Train Loss=0.6004, Train Acc=78.87%\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_initial.onnx\n",
      "initial value: target_macs=3029893.00\n",
      "Initial MACs: 0.006 G, Size: 4.46 MB\n",
      "After pruning: MACs 0.005 G, Size 3.63 MB\n",
      "Pruning targets achieved.\n",
      "--- Evaluating Pruned Model (Before Fine-tuning) for magnitude ---\n",
      "Metrics for magnitude (Pruned, Before FT): {'macs': 4924394.0, 'params': 950314, 'size_mib': 3.801256, 'accuracy': 52.94}\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_magnitude_pruned_not_finetuned.onnx\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_magnitude_pruned.onnx\n",
      "--- Fine-tuning Pruned Model for magnitude ---\n",
      "Strategy: magnitude - Epoch 1/20: Train Loss=0.6479, Train Acc=77.16%, Val Loss=0.8013, Val Acc=72.81%\n",
      "Strategy: magnitude - Epoch 2/20: Train Loss=0.5823, Train Acc=79.60%, Val Loss=0.7500, Val Acc=74.84%\n",
      "Strategy: magnitude - Epoch 3/20: Train Loss=0.5460, Train Acc=80.71%, Val Loss=0.7367, Val Acc=75.03%\n",
      "Strategy: magnitude - Epoch 4/20: Train Loss=0.5200, Train Acc=81.66%, Val Loss=0.7478, Val Acc=75.45%\n",
      "Strategy: magnitude - Epoch 5/20: Train Loss=0.4825, Train Acc=82.79%, Val Loss=0.7609, Val Acc=75.04%\n",
      "Strategy: magnitude - Epoch 6/20: Train Loss=0.4601, Train Acc=83.61%, Val Loss=0.7194, Val Acc=75.99%\n",
      "Strategy: magnitude - Epoch 7/20: Train Loss=0.4396, Train Acc=84.14%, Val Loss=0.7316, Val Acc=76.19%\n",
      "Strategy: magnitude - Epoch 8/20: Train Loss=0.4157, Train Acc=85.25%, Val Loss=0.7188, Val Acc=76.56%\n",
      "Strategy: magnitude - Epoch 9/20: Train Loss=0.3981, Train Acc=85.71%, Val Loss=0.7465, Val Acc=75.83%\n",
      "Strategy: magnitude - Epoch 10/20: Train Loss=0.3740, Train Acc=86.54%, Val Loss=0.7609, Val Acc=76.03%\n",
      "Strategy: magnitude - Epoch 11/20: Train Loss=0.3596, Train Acc=87.20%, Val Loss=0.7383, Val Acc=77.16%\n",
      "Strategy: magnitude - Epoch 12/20: Train Loss=0.3452, Train Acc=87.64%, Val Loss=0.7791, Val Acc=75.68%\n",
      "Strategy: magnitude - Epoch 13/20: Train Loss=0.3307, Train Acc=88.06%, Val Loss=0.7709, Val Acc=76.26%\n",
      "Strategy: magnitude - Epoch 14/20: Train Loss=0.3164, Train Acc=88.59%, Val Loss=0.7921, Val Acc=75.84%\n",
      "Strategy: magnitude - Epoch 15/20: Train Loss=0.3024, Train Acc=89.24%, Val Loss=0.7834, Val Acc=76.63%\n",
      "Strategy: magnitude - Epoch 16/20: Train Loss=0.2925, Train Acc=89.44%, Val Loss=0.7869, Val Acc=76.19%\n",
      "Strategy: magnitude - Epoch 17/20: Train Loss=0.2753, Train Acc=90.06%, Val Loss=0.7807, Val Acc=76.72%\n",
      "Strategy: magnitude - Epoch 18/20: Train Loss=0.2643, Train Acc=90.55%, Val Loss=0.8320, Val Acc=75.76%\n",
      "Strategy: magnitude - Epoch 19/20: Train Loss=0.2638, Train Acc=90.45%, Val Loss=0.8471, Val Acc=76.31%\n",
      "Strategy: magnitude - Epoch 20/20: Train Loss=0.2444, Train Acc=91.32%, Val Loss=0.8716, Val Acc=76.22%\n",
      "✅ Fine-tuning curves saved to ./output/strategies/magnitude_finetuning_curves.png\n",
      "--- Evaluating Fine-tuned Model for magnitude ---\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_magnitude_final.onnx\n",
      "Initial MACs: 0.006 G, Size: 4.46 MB\n",
      "After pruning: MACs 0.005 G, Size 3.63 MB\n",
      "Pruning targets achieved.\n",
      "--- Evaluating Pruned Model (Before Fine-tuning) for bn_scale ---\n",
      "Metrics for bn_scale (Pruned, Before FT): {'macs': 4924394.0, 'params': 950314, 'size_mib': 3.801256, 'accuracy': 57.67}\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_bn_scale_pruned_not_finetuned.onnx\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_bn_scale_pruned.onnx\n",
      "--- Fine-tuning Pruned Model for bn_scale ---\n",
      "Strategy: bn_scale - Epoch 1/20: Train Loss=0.6546, Train Acc=76.98%, Val Loss=0.7506, Val Acc=73.95%\n",
      "Strategy: bn_scale - Epoch 2/20: Train Loss=0.5865, Train Acc=79.39%, Val Loss=0.7287, Val Acc=75.18%\n",
      "Strategy: bn_scale - Epoch 3/20: Train Loss=0.5427, Train Acc=80.73%, Val Loss=0.7376, Val Acc=75.06%\n",
      "Strategy: bn_scale - Epoch 4/20: Train Loss=0.5145, Train Acc=81.84%, Val Loss=0.7461, Val Acc=75.03%\n",
      "Strategy: bn_scale - Epoch 5/20: Train Loss=0.4880, Train Acc=82.65%, Val Loss=0.7185, Val Acc=75.46%\n",
      "Strategy: bn_scale - Epoch 6/20: Train Loss=0.4595, Train Acc=83.67%, Val Loss=0.7368, Val Acc=75.22%\n",
      "Strategy: bn_scale - Epoch 7/20: Train Loss=0.4395, Train Acc=84.27%, Val Loss=0.7095, Val Acc=75.86%\n",
      "Strategy: bn_scale - Epoch 8/20: Train Loss=0.4155, Train Acc=85.24%, Val Loss=0.7425, Val Acc=75.44%\n",
      "Strategy: bn_scale - Epoch 9/20: Train Loss=0.4019, Train Acc=85.64%, Val Loss=0.7528, Val Acc=75.39%\n",
      "Strategy: bn_scale - Epoch 10/20: Train Loss=0.3800, Train Acc=86.54%, Val Loss=0.7952, Val Acc=75.22%\n",
      "Strategy: bn_scale - Epoch 11/20: Train Loss=0.3649, Train Acc=86.80%, Val Loss=0.7459, Val Acc=76.27%\n",
      "Strategy: bn_scale - Epoch 12/20: Train Loss=0.3463, Train Acc=87.43%, Val Loss=0.7559, Val Acc=76.17%\n",
      "Strategy: bn_scale - Epoch 13/20: Train Loss=0.3291, Train Acc=88.10%, Val Loss=0.8029, Val Acc=74.71%\n",
      "Strategy: bn_scale - Epoch 14/20: Train Loss=0.3208, Train Acc=88.37%, Val Loss=0.7642, Val Acc=76.33%\n",
      "Strategy: bn_scale - Epoch 15/20: Train Loss=0.3061, Train Acc=88.90%, Val Loss=0.7796, Val Acc=76.21%\n",
      "Strategy: bn_scale - Epoch 16/20: Train Loss=0.2895, Train Acc=89.58%, Val Loss=0.8146, Val Acc=76.13%\n",
      "Strategy: bn_scale - Epoch 17/20: Train Loss=0.2857, Train Acc=89.56%, Val Loss=0.8217, Val Acc=76.16%\n",
      "Strategy: bn_scale - Epoch 18/20: Train Loss=0.2711, Train Acc=90.16%, Val Loss=0.8291, Val Acc=75.53%\n",
      "Strategy: bn_scale - Epoch 19/20: Train Loss=0.2574, Train Acc=90.70%, Val Loss=0.8336, Val Acc=75.75%\n",
      "Strategy: bn_scale - Epoch 20/20: Train Loss=0.2484, Train Acc=91.13%, Val Loss=0.8416, Val Acc=75.81%\n",
      "✅ Fine-tuning curves saved to ./output/strategies/bn_scale_finetuning_curves.png\n",
      "--- Evaluating Fine-tuned Model for bn_scale ---\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_bn_scale_final.onnx\n",
      "Initial MACs: 0.006 G, Size: 4.46 MB\n",
      "After pruning: MACs 0.005 G, Size 3.63 MB\n",
      "Pruning targets achieved.\n",
      "--- Evaluating Pruned Model (Before Fine-tuning) for group_norm ---\n",
      "Metrics for group_norm (Pruned, Before FT): {'macs': 4924394.0, 'params': 950314, 'size_mib': 3.801256, 'accuracy': 51.65}\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_group_norm_pruned_not_finetuned.onnx\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_group_norm_pruned.onnx\n",
      "--- Fine-tuning Pruned Model for group_norm ---\n",
      "Strategy: group_norm - Epoch 1/20: Train Loss=0.6410, Train Acc=77.60%, Val Loss=0.7634, Val Acc=73.72%\n",
      "Strategy: group_norm - Epoch 2/20: Train Loss=0.5797, Train Acc=79.48%, Val Loss=0.7487, Val Acc=74.33%\n",
      "Strategy: group_norm - Epoch 3/20: Train Loss=0.5404, Train Acc=80.87%, Val Loss=0.7595, Val Acc=74.74%\n",
      "Strategy: group_norm - Epoch 4/20: Train Loss=0.5065, Train Acc=82.07%, Val Loss=0.7430, Val Acc=74.89%\n",
      "Strategy: group_norm - Epoch 5/20: Train Loss=0.4842, Train Acc=82.90%, Val Loss=0.7297, Val Acc=75.21%\n",
      "Strategy: group_norm - Epoch 6/20: Train Loss=0.4554, Train Acc=83.76%, Val Loss=0.7308, Val Acc=75.66%\n",
      "Strategy: group_norm - Epoch 7/20: Train Loss=0.4406, Train Acc=84.29%, Val Loss=0.7163, Val Acc=75.91%\n",
      "Strategy: group_norm - Epoch 8/20: Train Loss=0.4136, Train Acc=85.21%, Val Loss=0.7397, Val Acc=76.02%\n",
      "Strategy: group_norm - Epoch 9/20: Train Loss=0.3922, Train Acc=85.95%, Val Loss=0.7405, Val Acc=75.81%\n",
      "Strategy: group_norm - Epoch 10/20: Train Loss=0.3799, Train Acc=86.52%, Val Loss=0.7744, Val Acc=75.35%\n",
      "Strategy: group_norm - Epoch 11/20: Train Loss=0.3581, Train Acc=87.25%, Val Loss=0.7520, Val Acc=76.03%\n",
      "Strategy: group_norm - Epoch 12/20: Train Loss=0.3418, Train Acc=87.63%, Val Loss=0.7742, Val Acc=75.84%\n",
      "Strategy: group_norm - Epoch 13/20: Train Loss=0.3297, Train Acc=88.34%, Val Loss=0.7620, Val Acc=76.03%\n",
      "Strategy: group_norm - Epoch 14/20: Train Loss=0.3128, Train Acc=88.77%, Val Loss=0.7931, Val Acc=75.58%\n",
      "Strategy: group_norm - Epoch 15/20: Train Loss=0.2977, Train Acc=89.22%, Val Loss=0.8434, Val Acc=74.86%\n",
      "Strategy: group_norm - Epoch 16/20: Train Loss=0.2943, Train Acc=89.35%, Val Loss=0.8334, Val Acc=75.67%\n",
      "Strategy: group_norm - Epoch 17/20: Train Loss=0.2738, Train Acc=90.15%, Val Loss=0.8455, Val Acc=75.40%\n",
      "Strategy: group_norm - Epoch 18/20: Train Loss=0.2684, Train Acc=90.24%, Val Loss=0.8202, Val Acc=76.08%\n",
      "Strategy: group_norm - Epoch 19/20: Train Loss=0.2584, Train Acc=90.61%, Val Loss=0.8314, Val Acc=75.76%\n",
      "Strategy: group_norm - Epoch 20/20: Train Loss=0.2453, Train Acc=91.12%, Val Loss=0.8267, Val Acc=76.53%\n",
      "✅ Fine-tuning curves saved to ./output/strategies/group_norm_finetuning_curves.png\n",
      "--- Evaluating Fine-tuned Model for group_norm ---\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_group_norm_final.onnx\n",
      "Initial MACs: 0.006 G, Size: 4.46 MB\n",
      "After pruning: MACs 0.005 G, Size 3.63 MB\n",
      "Pruning targets achieved.\n",
      "--- Evaluating Pruned Model (Before Fine-tuning) for random ---\n",
      "Metrics for random (Pruned, Before FT): {'macs': 4924394.0, 'params': 950314, 'size_mib': 3.801256, 'accuracy': 23.66}\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_random_pruned_not_finetuned.onnx\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_random_pruned.onnx\n",
      "--- Fine-tuning Pruned Model for random ---\n",
      "Strategy: random - Epoch 1/20: Train Loss=0.7098, Train Acc=75.39%, Val Loss=0.7602, Val Acc=73.41%\n",
      "Strategy: random - Epoch 2/20: Train Loss=0.6081, Train Acc=78.71%, Val Loss=0.7634, Val Acc=73.01%\n",
      "Strategy: random - Epoch 3/20: Train Loss=0.5780, Train Acc=79.59%, Val Loss=0.7215, Val Acc=74.58%\n",
      "Strategy: random - Epoch 4/20: Train Loss=0.5299, Train Acc=81.19%, Val Loss=0.7187, Val Acc=75.51%\n",
      "Strategy: random - Epoch 5/20: Train Loss=0.5015, Train Acc=82.29%, Val Loss=0.7354, Val Acc=74.86%\n",
      "Strategy: random - Epoch 6/20: Train Loss=0.4783, Train Acc=83.28%, Val Loss=0.7238, Val Acc=75.66%\n",
      "Strategy: random - Epoch 7/20: Train Loss=0.4529, Train Acc=83.79%, Val Loss=0.7415, Val Acc=75.70%\n",
      "Strategy: random - Epoch 8/20: Train Loss=0.4286, Train Acc=84.77%, Val Loss=0.7508, Val Acc=75.61%\n",
      "Strategy: random - Epoch 9/20: Train Loss=0.4087, Train Acc=85.49%, Val Loss=0.7507, Val Acc=75.92%\n",
      "Strategy: random - Epoch 10/20: Train Loss=0.3927, Train Acc=85.94%, Val Loss=0.7658, Val Acc=76.16%\n",
      "Strategy: random - Epoch 11/20: Train Loss=0.3798, Train Acc=86.32%, Val Loss=0.7522, Val Acc=75.66%\n",
      "Strategy: random - Epoch 12/20: Train Loss=0.3546, Train Acc=87.33%, Val Loss=0.7558, Val Acc=75.90%\n",
      "Strategy: random - Epoch 13/20: Train Loss=0.3367, Train Acc=87.87%, Val Loss=0.7675, Val Acc=75.85%\n",
      "Strategy: random - Epoch 14/20: Train Loss=0.3199, Train Acc=88.73%, Val Loss=0.8018, Val Acc=76.04%\n",
      "Strategy: random - Epoch 15/20: Train Loss=0.3104, Train Acc=88.88%, Val Loss=0.7770, Val Acc=76.54%\n",
      "Strategy: random - Epoch 16/20: Train Loss=0.2954, Train Acc=89.43%, Val Loss=0.7812, Val Acc=76.32%\n",
      "Strategy: random - Epoch 17/20: Train Loss=0.2879, Train Acc=89.65%, Val Loss=0.8146, Val Acc=76.39%\n",
      "Strategy: random - Epoch 18/20: Train Loss=0.2685, Train Acc=90.27%, Val Loss=0.8147, Val Acc=76.49%\n",
      "Strategy: random - Epoch 19/20: Train Loss=0.2584, Train Acc=90.73%, Val Loss=0.8419, Val Acc=75.69%\n",
      "Strategy: random - Epoch 20/20: Train Loss=0.2518, Train Acc=90.99%, Val Loss=0.8364, Val Acc=76.34%\n",
      "✅ Fine-tuning curves saved to ./output/strategies/random_finetuning_curves.png\n",
      "--- Evaluating Fine-tuned Model for random ---\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_random_final.onnx\n",
      "Initial MACs: 0.006 G, Size: 4.46 MB\n",
      "Step 1/5: MACs 0.005 G, Size 3.63 MB\n",
      "Targets reached at step 1\n",
      "Pruning targets achieved.\n",
      "--- Evaluating Pruned Model (Before Fine-tuning) for Taylor ---\n",
      "Metrics for Taylor (Pruned, Before FT): {'macs': 4924394.0, 'params': 950314, 'size_mib': 3.801256, 'accuracy': 38.01}\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_Taylor_pruned_not_finetuned.onnx\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_Taylor_pruned.onnx\n",
      "--- Fine-tuning Pruned Model for Taylor ---\n",
      "Strategy: Taylor - Epoch 1/20: Train Loss=0.6939, Train Acc=75.92%, Val Loss=0.7647, Val Acc=73.81%\n",
      "Strategy: Taylor - Epoch 2/20: Train Loss=0.6036, Train Acc=79.07%, Val Loss=0.7549, Val Acc=74.18%\n",
      "Strategy: Taylor - Epoch 3/20: Train Loss=0.5659, Train Acc=80.38%, Val Loss=0.7707, Val Acc=73.99%\n",
      "Strategy: Taylor - Epoch 4/20: Train Loss=0.5332, Train Acc=81.19%, Val Loss=0.7327, Val Acc=75.01%\n",
      "Strategy: Taylor - Epoch 5/20: Train Loss=0.4969, Train Acc=82.48%, Val Loss=0.7190, Val Acc=75.61%\n",
      "Strategy: Taylor - Epoch 6/20: Train Loss=0.4692, Train Acc=83.32%, Val Loss=0.7251, Val Acc=75.38%\n",
      "Strategy: Taylor - Epoch 7/20: Train Loss=0.4491, Train Acc=83.98%, Val Loss=0.7321, Val Acc=75.45%\n",
      "Strategy: Taylor - Epoch 8/20: Train Loss=0.4260, Train Acc=84.95%, Val Loss=0.7566, Val Acc=75.86%\n",
      "Strategy: Taylor - Epoch 9/20: Train Loss=0.4086, Train Acc=85.32%, Val Loss=0.7453, Val Acc=75.96%\n",
      "Strategy: Taylor - Epoch 10/20: Train Loss=0.3869, Train Acc=86.44%, Val Loss=0.7818, Val Acc=75.11%\n",
      "Strategy: Taylor - Epoch 11/20: Train Loss=0.3651, Train Acc=87.07%, Val Loss=0.7724, Val Acc=74.91%\n",
      "Strategy: Taylor - Epoch 12/20: Train Loss=0.3562, Train Acc=87.35%, Val Loss=0.7799, Val Acc=75.53%\n",
      "Strategy: Taylor - Epoch 13/20: Train Loss=0.3359, Train Acc=88.05%, Val Loss=0.7767, Val Acc=76.13%\n",
      "Strategy: Taylor - Epoch 14/20: Train Loss=0.3191, Train Acc=88.59%, Val Loss=0.7815, Val Acc=76.00%\n",
      "Strategy: Taylor - Epoch 15/20: Train Loss=0.3078, Train Acc=89.08%, Val Loss=0.8031, Val Acc=75.82%\n",
      "Strategy: Taylor - Epoch 16/20: Train Loss=0.2965, Train Acc=89.34%, Val Loss=0.7809, Val Acc=76.19%\n",
      "Strategy: Taylor - Epoch 17/20: Train Loss=0.2855, Train Acc=89.70%, Val Loss=0.8411, Val Acc=75.89%\n",
      "Strategy: Taylor - Epoch 18/20: Train Loss=0.2764, Train Acc=89.89%, Val Loss=0.8292, Val Acc=75.67%\n",
      "Strategy: Taylor - Epoch 19/20: Train Loss=0.2594, Train Acc=90.74%, Val Loss=0.8134, Val Acc=75.71%\n",
      "Strategy: Taylor - Epoch 20/20: Train Loss=0.2511, Train Acc=90.89%, Val Loss=0.8333, Val Acc=76.31%\n",
      "✅ Fine-tuning curves saved to ./output/strategies/Taylor_finetuning_curves.png\n",
      "--- Evaluating Fine-tuned Model for Taylor ---\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_Taylor_final.onnx\n",
      "Initial MACs: 0.006 G, Size: 4.46 MB\n",
      "After pruning: MACs 0.006 G, Size 4.46 MB\n",
      "Pruning targets achieved.\n",
      "--- Evaluating Pruned Model (Before Fine-tuning) for Hessian ---\n",
      "Metrics for Hessian (Pruned, Before FT): {'macs': 6059786.0, 'params': 1169642, 'size_mib': 4.678568, 'accuracy': 73.78}\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_Hessian_pruned_not_finetuned.onnx\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_Hessian_pruned.onnx\n",
      "--- Fine-tuning Pruned Model for Hessian ---\n",
      "Strategy: Hessian - Epoch 1/20: Train Loss=0.5757, Train Acc=79.72%, Val Loss=0.7372, Val Acc=74.95%\n",
      "Strategy: Hessian - Epoch 2/20: Train Loss=0.5329, Train Acc=81.07%, Val Loss=0.7710, Val Acc=73.88%\n",
      "Strategy: Hessian - Epoch 3/20: Train Loss=0.5011, Train Acc=82.29%, Val Loss=0.7597, Val Acc=74.68%\n",
      "Strategy: Hessian - Epoch 4/20: Train Loss=0.4757, Train Acc=83.18%, Val Loss=0.7545, Val Acc=74.49%\n",
      "Strategy: Hessian - Epoch 5/20: Train Loss=0.4487, Train Acc=84.23%, Val Loss=0.7671, Val Acc=75.01%\n",
      "Strategy: Hessian - Epoch 6/20: Train Loss=0.4265, Train Acc=84.98%, Val Loss=0.7542, Val Acc=75.09%\n",
      "Strategy: Hessian - Epoch 7/20: Train Loss=0.4041, Train Acc=85.66%, Val Loss=0.7293, Val Acc=75.89%\n",
      "Strategy: Hessian - Epoch 8/20: Train Loss=0.3805, Train Acc=86.46%, Val Loss=0.7439, Val Acc=75.76%\n",
      "Strategy: Hessian - Epoch 9/20: Train Loss=0.3681, Train Acc=86.79%, Val Loss=0.7385, Val Acc=76.10%\n",
      "Strategy: Hessian - Epoch 10/20: Train Loss=0.3490, Train Acc=87.46%, Val Loss=0.7403, Val Acc=76.22%\n",
      "Strategy: Hessian - Epoch 11/20: Train Loss=0.3290, Train Acc=88.17%, Val Loss=0.7785, Val Acc=75.77%\n",
      "Strategy: Hessian - Epoch 12/20: Train Loss=0.3200, Train Acc=88.63%, Val Loss=0.8046, Val Acc=75.64%\n",
      "Strategy: Hessian - Epoch 13/20: Train Loss=0.3026, Train Acc=89.23%, Val Loss=0.8047, Val Acc=75.45%\n",
      "Strategy: Hessian - Epoch 14/20: Train Loss=0.2865, Train Acc=89.72%, Val Loss=0.8003, Val Acc=76.81%\n",
      "Strategy: Hessian - Epoch 15/20: Train Loss=0.2782, Train Acc=90.06%, Val Loss=0.8171, Val Acc=75.69%\n",
      "Strategy: Hessian - Epoch 16/20: Train Loss=0.2659, Train Acc=90.47%, Val Loss=0.8169, Val Acc=75.61%\n",
      "Strategy: Hessian - Epoch 17/20: Train Loss=0.2493, Train Acc=91.09%, Val Loss=0.8446, Val Acc=76.07%\n",
      "Strategy: Hessian - Epoch 18/20: Train Loss=0.2430, Train Acc=91.27%, Val Loss=0.8566, Val Acc=76.05%\n",
      "Strategy: Hessian - Epoch 19/20: Train Loss=0.2345, Train Acc=91.76%, Val Loss=0.8617, Val Acc=76.28%\n",
      "Strategy: Hessian - Epoch 20/20: Train Loss=0.2276, Train Acc=91.85%, Val Loss=0.8366, Val Acc=75.86%\n",
      "✅ Fine-tuning curves saved to ./output/strategies/Hessian_finetuning_curves.png\n",
      "--- Evaluating Fine-tuned Model for Hessian ---\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_Hessian_final.onnx\n",
      "Initial MACs: 0.006 G, Size: 4.46 MB\n",
      "After pruning: MACs 0.005 G, Size 3.63 MB\n",
      "Pruning targets achieved.\n",
      "--- Evaluating Pruned Model (Before Fine-tuning) for lamp ---\n",
      "Metrics for lamp (Pruned, Before FT): {'macs': 4924394.0, 'params': 950314, 'size_mib': 3.801256, 'accuracy': 52.94}\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_lamp_pruned_not_finetuned.onnx\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_lamp_pruned.onnx\n",
      "--- Fine-tuning Pruned Model for lamp ---\n",
      "Strategy: lamp - Epoch 1/20: Train Loss=0.6477, Train Acc=77.25%, Val Loss=0.7550, Val Acc=74.69%\n",
      "Strategy: lamp - Epoch 2/20: Train Loss=0.5839, Train Acc=79.37%, Val Loss=0.7533, Val Acc=74.63%\n",
      "Strategy: lamp - Epoch 3/20: Train Loss=0.5506, Train Acc=80.53%, Val Loss=0.7269, Val Acc=74.95%\n",
      "Strategy: lamp - Epoch 4/20: Train Loss=0.5204, Train Acc=81.70%, Val Loss=0.7331, Val Acc=75.49%\n",
      "Strategy: lamp - Epoch 5/20: Train Loss=0.4879, Train Acc=82.55%, Val Loss=0.7227, Val Acc=75.58%\n",
      "Strategy: lamp - Epoch 6/20: Train Loss=0.4612, Train Acc=83.53%, Val Loss=0.7337, Val Acc=75.44%\n",
      "Strategy: lamp - Epoch 7/20: Train Loss=0.4345, Train Acc=84.62%, Val Loss=0.7295, Val Acc=76.16%\n",
      "Strategy: lamp - Epoch 8/20: Train Loss=0.4128, Train Acc=85.10%, Val Loss=0.7584, Val Acc=75.06%\n",
      "Strategy: lamp - Epoch 9/20: Train Loss=0.3976, Train Acc=85.79%, Val Loss=0.7418, Val Acc=76.28%\n",
      "Strategy: lamp - Epoch 10/20: Train Loss=0.3751, Train Acc=86.67%, Val Loss=0.7426, Val Acc=76.40%\n",
      "Strategy: lamp - Epoch 11/20: Train Loss=0.3584, Train Acc=87.05%, Val Loss=0.7552, Val Acc=76.17%\n",
      "Strategy: lamp - Epoch 12/20: Train Loss=0.3490, Train Acc=87.43%, Val Loss=0.7516, Val Acc=76.13%\n",
      "Strategy: lamp - Epoch 13/20: Train Loss=0.3267, Train Acc=88.29%, Val Loss=0.8161, Val Acc=75.58%\n",
      "Strategy: lamp - Epoch 14/20: Train Loss=0.3150, Train Acc=88.62%, Val Loss=0.8024, Val Acc=76.63%\n",
      "Strategy: lamp - Epoch 15/20: Train Loss=0.2949, Train Acc=89.40%, Val Loss=0.7876, Val Acc=76.68%\n",
      "Strategy: lamp - Epoch 16/20: Train Loss=0.2854, Train Acc=89.68%, Val Loss=0.8090, Val Acc=75.94%\n",
      "Strategy: lamp - Epoch 17/20: Train Loss=0.2772, Train Acc=89.86%, Val Loss=0.8083, Val Acc=76.03%\n",
      "Strategy: lamp - Epoch 18/20: Train Loss=0.2636, Train Acc=90.46%, Val Loss=0.8278, Val Acc=76.20%\n",
      "Strategy: lamp - Epoch 19/20: Train Loss=0.2567, Train Acc=90.76%, Val Loss=0.8401, Val Acc=76.11%\n",
      "Strategy: lamp - Epoch 20/20: Train Loss=0.2444, Train Acc=91.24%, Val Loss=0.8368, Val Acc=76.33%\n",
      "✅ Fine-tuning curves saved to ./output/strategies/lamp_finetuning_curves.png\n",
      "--- Evaluating Fine-tuned Model for lamp ---\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_lamp_final.onnx\n",
      "Initial MACs: 0.006 G, Size: 4.46 MB\n",
      "After pruning: MACs 0.005 G, Size 3.63 MB\n",
      "Pruning targets achieved.\n",
      "--- Evaluating Pruned Model (Before Fine-tuning) for geometry ---\n",
      "Metrics for geometry (Pruned, Before FT): {'macs': 4924394.0, 'params': 950314, 'size_mib': 3.801256, 'accuracy': 47.12}\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_geometry_pruned_not_finetuned.onnx\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_geometry_pruned.onnx\n",
      "--- Fine-tuning Pruned Model for geometry ---\n",
      "Strategy: geometry - Epoch 1/20: Train Loss=0.6541, Train Acc=76.98%, Val Loss=0.7598, Val Acc=73.42%\n",
      "Strategy: geometry - Epoch 2/20: Train Loss=0.5863, Train Acc=79.41%, Val Loss=0.7649, Val Acc=73.33%\n",
      "Strategy: geometry - Epoch 3/20: Train Loss=0.5537, Train Acc=80.56%, Val Loss=0.7155, Val Acc=75.55%\n",
      "Strategy: geometry - Epoch 4/20: Train Loss=0.5156, Train Acc=81.87%, Val Loss=0.7552, Val Acc=74.36%\n",
      "Strategy: geometry - Epoch 5/20: Train Loss=0.4868, Train Acc=82.69%, Val Loss=0.7362, Val Acc=75.42%\n",
      "Strategy: geometry - Epoch 6/20: Train Loss=0.4618, Train Acc=83.58%, Val Loss=0.7323, Val Acc=76.00%\n",
      "Strategy: geometry - Epoch 7/20: Train Loss=0.4394, Train Acc=84.64%, Val Loss=0.7273, Val Acc=76.23%\n",
      "Strategy: geometry - Epoch 8/20: Train Loss=0.4184, Train Acc=85.29%, Val Loss=0.7445, Val Acc=75.95%\n",
      "Strategy: geometry - Epoch 9/20: Train Loss=0.3973, Train Acc=85.93%, Val Loss=0.7273, Val Acc=76.55%\n",
      "Strategy: geometry - Epoch 10/20: Train Loss=0.3776, Train Acc=86.59%, Val Loss=0.7309, Val Acc=76.47%\n",
      "Strategy: geometry - Epoch 11/20: Train Loss=0.3614, Train Acc=87.12%, Val Loss=0.7541, Val Acc=76.23%\n",
      "Strategy: geometry - Epoch 12/20: Train Loss=0.3395, Train Acc=87.87%, Val Loss=0.7709, Val Acc=76.55%\n",
      "Strategy: geometry - Epoch 13/20: Train Loss=0.3270, Train Acc=88.46%, Val Loss=0.7664, Val Acc=76.50%\n",
      "Strategy: geometry - Epoch 14/20: Train Loss=0.3174, Train Acc=88.56%, Val Loss=0.7943, Val Acc=75.89%\n",
      "Strategy: geometry - Epoch 15/20: Train Loss=0.3040, Train Acc=89.14%, Val Loss=0.8228, Val Acc=75.43%\n",
      "Strategy: geometry - Epoch 16/20: Train Loss=0.2985, Train Acc=89.27%, Val Loss=0.8006, Val Acc=76.54%\n",
      "Strategy: geometry - Epoch 17/20: Train Loss=0.2771, Train Acc=89.92%, Val Loss=0.8262, Val Acc=76.15%\n",
      "Strategy: geometry - Epoch 18/20: Train Loss=0.2701, Train Acc=90.30%, Val Loss=0.8108, Val Acc=76.40%\n",
      "Strategy: geometry - Epoch 19/20: Train Loss=0.2587, Train Acc=90.77%, Val Loss=0.8448, Val Acc=75.73%\n",
      "Strategy: geometry - Epoch 20/20: Train Loss=0.2470, Train Acc=90.90%, Val Loss=0.8340, Val Acc=76.34%\n",
      "✅ Fine-tuning curves saved to ./output/strategies/geometry_finetuning_curves.png\n",
      "--- Evaluating Fine-tuned Model for geometry ---\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_geometry_final.onnx\n",
      "\n",
      "=== Pruning Strategy Comparison ===\n",
      "Strategy                            | MACs         | Params       | Size (MiB) | Accuracy (%)\n",
      "---------------------------------------------------------------------------------------------\n",
      "initial                             | 6.06e+06 | 1.17e+06 |      4.68 |        73.78\n",
      "Hessian_pruned_not_finetuned        | 6.06e+06 | 1.17e+06 |      4.68 |        73.78\n",
      "Hessian                             | 6.06e+06 | 1.17e+06 |      4.68 |        75.86\n",
      "Taylor_pruned_not_finetuned         | 4.92e+06 | 9.50e+05 |      3.80 |        38.01\n",
      "Taylor                              | 4.92e+06 | 9.50e+05 |      3.80 |        76.31\n",
      "bn_scale_pruned_not_finetuned       | 4.92e+06 | 9.50e+05 |      3.80 |        57.67\n",
      "bn_scale                            | 4.92e+06 | 9.50e+05 |      3.80 |        75.81\n",
      "geometry_pruned_not_finetuned       | 4.92e+06 | 9.50e+05 |      3.80 |        47.12\n",
      "geometry                            | 4.92e+06 | 9.50e+05 |      3.80 |        76.34\n",
      "group_norm_pruned_not_finetuned     | 4.92e+06 | 9.50e+05 |      3.80 |        51.65\n",
      "group_norm                          | 4.92e+06 | 9.50e+05 |      3.80 |        76.53\n",
      "lamp_pruned_not_finetuned           | 4.92e+06 | 9.50e+05 |      3.80 |        52.94\n",
      "lamp                                | 4.92e+06 | 9.50e+05 |      3.80 |        76.33\n",
      "magnitude_pruned_not_finetuned      | 4.92e+06 | 9.50e+05 |      3.80 |        52.94\n",
      "magnitude                           | 4.92e+06 | 9.50e+05 |      3.80 |        76.22\n",
      "random_pruned_not_finetuned         | 4.92e+06 | 9.50e+05 |      3.80 |        23.66\n",
      "random                              | 4.92e+06 | 9.50e+05 |      3.80 |        76.34\n",
      "✅ Comparison plots saved to ./output/strategies\n",
      "Workflow completed successfully!\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "id": "238badca29395cae",
   "metadata": {},
   "source": [
    "### Load the saved Onnx model and convert to Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "229d26f48f444268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T12:24:13.022499Z",
     "start_time": "2025-04-10T12:24:12.993796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ONNX model loaded and verified.\n",
      "✅ ONNX model converted to PyTorch.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from onnx2torch import convert\n",
    "\n",
    "# Step 1: Load the ONNX model\n",
    "onnx_model_path = './output/strategies/mobilenetv2_bn_scale_final.onnx'\n",
    "onnx_model = onnx.load(onnx_model_path)\n",
    "onnx.checker.check_model(onnx_model)  # Verify the ONNX model\n",
    "print(\"✅ ONNX model loaded and verified.\")\n",
    "\n",
    "# Step 2: Convert ONNX to PyTorch\n",
    "torch_model = convert(onnx_model)\n",
    "print(\"✅ ONNX model converted to PyTorch.\")\n",
    "tp.utils.print_tool.before_pruning(torch_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38ba67685c8f9c69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T12:24:21.518145Z",
     "start_time": "2025-04-10T12:24:21.512261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "GraphModule                                             --\n",
      "├─Conv2d: 1-1                                           448\n",
      "├─OnnxConstant: 1-2                                     --\n",
      "├─OnnxConstant: 1-3                                     --\n",
      "├─ReLU6: 1-4                                            --\n",
      "├─Conv2d: 1-5                                           1,632\n",
      "├─OnnxConstant: 1-6                                     --\n",
      "├─OnnxConstant: 1-7                                     --\n",
      "├─ReLU6: 1-8                                            --\n",
      "├─Conv2d: 1-9                                           960\n",
      "├─OnnxConstant: 1-10                                    --\n",
      "├─OnnxConstant: 1-11                                    --\n",
      "├─ReLU6: 1-12                                           --\n",
      "├─Conv2d: 1-13                                          776\n",
      "├─Conv2d: 1-14                                          432\n",
      "├─OnnxConstant: 1-15                                    --\n",
      "├─OnnxConstant: 1-16                                    --\n",
      "├─ReLU6: 1-17                                           --\n",
      "├─Conv2d: 1-18                                          480\n",
      "├─OnnxConstant: 1-19                                    --\n",
      "├─OnnxConstant: 1-20                                    --\n",
      "├─ReLU6: 1-21                                           --\n",
      "├─Conv2d: 1-22                                          588\n",
      "├─Conv2d: 1-23                                          936\n",
      "├─OnnxConstant: 1-24                                    --\n",
      "├─OnnxConstant: 1-25                                    --\n",
      "├─ReLU6: 1-26                                           --\n",
      "├─Conv2d: 1-27                                          720\n",
      "├─OnnxConstant: 1-28                                    --\n",
      "├─OnnxConstant: 1-29                                    --\n",
      "├─ReLU6: 1-30                                           --\n",
      "├─Conv2d: 1-31                                          1,168\n",
      "├─Conv2d: 1-32                                          1,632\n",
      "├─OnnxConstant: 1-33                                    --\n",
      "├─OnnxConstant: 1-34                                    --\n",
      "├─ReLU6: 1-35                                           --\n",
      "├─Conv2d: 1-36                                          960\n",
      "├─OnnxConstant: 1-37                                    --\n",
      "├─OnnxConstant: 1-38                                    --\n",
      "├─ReLU6: 1-39                                           --\n",
      "├─Conv2d: 1-40                                          3,104\n",
      "├─Conv2d: 1-41                                          6,336\n",
      "├─OnnxConstant: 1-42                                    --\n",
      "├─OnnxConstant: 1-43                                    --\n",
      "├─ReLU6: 1-44                                           --\n",
      "├─Conv2d: 1-45                                          1,920\n",
      "├─OnnxConstant: 1-46                                    --\n",
      "├─OnnxConstant: 1-47                                    --\n",
      "├─ReLU6: 1-48                                           --\n",
      "├─Conv2d: 1-49                                          9,264\n",
      "├─Conv2d: 1-50                                          14,112\n",
      "├─OnnxConstant: 1-51                                    --\n",
      "├─OnnxConstant: 1-52                                    --\n",
      "├─ReLU6: 1-53                                           --\n",
      "├─Conv2d: 1-54                                          2,880\n",
      "├─OnnxConstant: 1-55                                    --\n",
      "├─OnnxConstant: 1-56                                    --\n",
      "├─ReLU6: 1-57                                           --\n",
      "├─Conv2d: 1-58                                          23,120\n",
      "├─Conv2d: 1-59                                          38,880\n",
      "├─OnnxConstant: 1-60                                    --\n",
      "├─OnnxConstant: 1-61                                    --\n",
      "├─ReLU6: 1-62                                           --\n",
      "├─Conv2d: 1-63                                          4,800\n",
      "├─OnnxConstant: 1-64                                    --\n",
      "├─OnnxConstant: 1-65                                    --\n",
      "├─ReLU6: 1-66                                           --\n",
      "├─Conv2d: 1-67                                          76,960\n",
      "├─Conv2d: 1-68                                          103,040\n",
      "├─OnnxConstant: 1-69                                    --\n",
      "├─OnnxConstant: 1-70                                    --\n",
      "├─ReLU6: 1-71                                           --\n",
      "├─OnnxGlobalAveragePoolWithKnownInputShape: 1-72        --\n",
      "├─Flatten: 1-73                                         --\n",
      "├─Linear: 1-74                                          6,410\n",
      "================================================================================\n",
      "Total params: 301,558\n",
      "Trainable params: 301,558\n",
      "Non-trainable params: 0\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "print(summary(torch_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d1dd20bc238d90a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T10:39:54.201742Z",
     "start_time": "2025-04-10T10:39:54.150874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "GraphModule                                             --\n",
      "├─Conv2d: 1-1                                           896\n",
      "├─OnnxConstant: 1-2                                     --\n",
      "├─OnnxConstant: 1-3                                     --\n",
      "├─ReLU6: 1-4                                            --\n",
      "├─Conv2d: 1-5                                           6,336\n",
      "├─OnnxConstant: 1-6                                     --\n",
      "├─OnnxConstant: 1-7                                     --\n",
      "├─ReLU6: 1-8                                            --\n",
      "├─Conv2d: 1-9                                           1,920\n",
      "├─OnnxConstant: 1-10                                    --\n",
      "├─OnnxConstant: 1-11                                    --\n",
      "├─ReLU6: 1-12                                           --\n",
      "├─Conv2d: 1-13                                          3,088\n",
      "├─Conv2d: 1-14                                          1,632\n",
      "├─OnnxConstant: 1-15                                    --\n",
      "├─OnnxConstant: 1-16                                    --\n",
      "├─ReLU6: 1-17                                           --\n",
      "├─Conv2d: 1-18                                          960\n",
      "├─OnnxConstant: 1-19                                    --\n",
      "├─OnnxConstant: 1-20                                    --\n",
      "├─ReLU6: 1-21                                           --\n",
      "├─Conv2d: 1-22                                          2,328\n",
      "├─Conv2d: 1-23                                          3,600\n",
      "├─OnnxConstant: 1-24                                    --\n",
      "├─OnnxConstant: 1-25                                    --\n",
      "├─ReLU6: 1-26                                           --\n",
      "├─Conv2d: 1-27                                          1,440\n",
      "├─OnnxConstant: 1-28                                    --\n",
      "├─OnnxConstant: 1-29                                    --\n",
      "├─ReLU6: 1-30                                           --\n",
      "├─Conv2d: 1-31                                          4,640\n",
      "├─Conv2d: 1-32                                          6,336\n",
      "├─OnnxConstant: 1-33                                    --\n",
      "├─OnnxConstant: 1-34                                    --\n",
      "├─ReLU6: 1-35                                           --\n",
      "├─Conv2d: 1-36                                          1,920\n",
      "├─OnnxConstant: 1-37                                    --\n",
      "├─OnnxConstant: 1-38                                    --\n",
      "├─ReLU6: 1-39                                           --\n",
      "├─Conv2d: 1-40                                          12,352\n",
      "├─Conv2d: 1-41                                          24,960\n",
      "├─OnnxConstant: 1-42                                    --\n",
      "├─OnnxConstant: 1-43                                    --\n",
      "├─ReLU6: 1-44                                           --\n",
      "├─Conv2d: 1-45                                          3,840\n",
      "├─OnnxConstant: 1-46                                    --\n",
      "├─OnnxConstant: 1-47                                    --\n",
      "├─ReLU6: 1-48                                           --\n",
      "├─Conv2d: 1-49                                          36,960\n",
      "├─Conv2d: 1-50                                          55,872\n",
      "├─OnnxConstant: 1-51                                    --\n",
      "├─OnnxConstant: 1-52                                    --\n",
      "├─ReLU6: 1-53                                           --\n",
      "├─Conv2d: 1-54                                          5,760\n",
      "├─OnnxConstant: 1-55                                    --\n",
      "├─OnnxConstant: 1-56                                    --\n",
      "├─ReLU6: 1-57                                           --\n",
      "├─Conv2d: 1-58                                          92,320\n",
      "├─Conv2d: 1-59                                          154,560\n",
      "├─OnnxConstant: 1-60                                    --\n",
      "├─OnnxConstant: 1-61                                    --\n",
      "├─ReLU6: 1-62                                           --\n",
      "├─Conv2d: 1-63                                          9,600\n",
      "├─OnnxConstant: 1-64                                    --\n",
      "├─OnnxConstant: 1-65                                    --\n",
      "├─ReLU6: 1-66                                           --\n",
      "├─Conv2d: 1-67                                          307,520\n",
      "├─Conv2d: 1-68                                          410,880\n",
      "├─OnnxConstant: 1-69                                    --\n",
      "├─OnnxConstant: 1-70                                    --\n",
      "├─ReLU6: 1-71                                           --\n",
      "├─OnnxGlobalAveragePoolWithKnownInputShape: 1-72        --\n",
      "├─Flatten: 1-73                                         --\n",
      "├─Linear: 1-74                                          12,810\n",
      "================================================================================\n",
      "Total params: 1,162,530\n",
      "Trainable params: 1,162,530\n",
      "Non-trainable params: 0\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torchinfo import summary\n",
    "print(summary(torch_model))\n",
    "#tp.utils.print_tool.after_pruning(torch_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de5ca7f1456a3d2",
   "metadata": {},
   "source": [
    "### Load the converted Pytorch model and fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1ece7efcc1c6179",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:41:44.435126Z",
     "start_time": "2025-04-09T13:37:33.019618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset directory: /home/muis/thesis/github-repo/master-thesis/cnn/mobile_net_v2/data\n",
      "Epoch 1/50: Loss=0.6039, Accuracy=78.76%\n",
      "Epoch 2/50: Loss=0.6009, Accuracy=78.70%\n",
      "Epoch 3/50: Loss=0.5960, Accuracy=78.91%\n",
      "Epoch 4/50: Loss=0.5975, Accuracy=78.81%\n",
      "Epoch 5/50: Loss=0.5957, Accuracy=78.92%\n",
      "Epoch 6/50: Loss=0.5969, Accuracy=78.82%\n",
      "Epoch 7/50: Loss=0.6109, Accuracy=78.42%\n",
      "Epoch 8/50: Loss=0.6080, Accuracy=78.65%\n",
      "Epoch 9/50: Loss=0.6081, Accuracy=78.52%\n",
      "Epoch 10/50: Loss=0.6090, Accuracy=78.53%\n",
      "Epoch 11/50: Loss=0.6294, Accuracy=77.73%\n",
      "Epoch 12/50: Loss=0.6354, Accuracy=77.75%\n",
      "Epoch 13/50: Loss=0.6369, Accuracy=77.76%\n",
      "Epoch 14/50: Loss=0.6398, Accuracy=77.80%\n",
      "Epoch 15/50: Loss=0.6449, Accuracy=77.49%\n",
      "Epoch 16/50: Loss=0.6451, Accuracy=77.21%\n",
      "Epoch 17/50: Loss=0.6569, Accuracy=76.93%\n",
      "Epoch 18/50: Loss=0.6594, Accuracy=76.96%\n",
      "Epoch 19/50: Loss=0.6644, Accuracy=76.68%\n",
      "Epoch 20/50: Loss=0.6890, Accuracy=76.04%\n",
      "Epoch 21/50: Loss=0.7159, Accuracy=75.11%\n",
      "Epoch 22/50: Loss=0.7258, Accuracy=74.65%\n",
      "Epoch 23/50: Loss=0.7349, Accuracy=74.31%\n",
      "Epoch 24/50: Loss=0.7270, Accuracy=74.58%\n",
      "Epoch 25/50: Loss=0.7467, Accuracy=74.14%\n",
      "Epoch 26/50: Loss=0.7675, Accuracy=73.00%\n",
      "Epoch 27/50: Loss=0.8084, Accuracy=72.25%\n",
      "Epoch 28/50: Loss=0.7989, Accuracy=72.42%\n",
      "Epoch 29/50: Loss=0.8117, Accuracy=72.01%\n",
      "Epoch 30/50: Loss=0.8219, Accuracy=71.50%\n",
      "Epoch 31/50: Loss=0.8353, Accuracy=71.06%\n",
      "Epoch 32/50: Loss=0.8406, Accuracy=70.78%\n",
      "Epoch 33/50: Loss=0.8447, Accuracy=71.01%\n",
      "Epoch 34/50: Loss=0.8858, Accuracy=69.39%\n",
      "Epoch 35/50: Loss=0.8922, Accuracy=69.14%\n",
      "Epoch 36/50: Loss=0.8901, Accuracy=69.15%\n",
      "Epoch 37/50: Loss=0.8982, Accuracy=68.85%\n",
      "Epoch 38/50: Loss=0.9320, Accuracy=67.87%\n",
      "Epoch 39/50: Loss=0.9501, Accuracy=67.43%\n",
      "Epoch 40/50: Loss=0.9214, Accuracy=68.09%\n",
      "Epoch 41/50: Loss=0.9657, Accuracy=66.49%\n",
      "Epoch 42/50: Loss=1.0036, Accuracy=65.34%\n",
      "Epoch 43/50: Loss=1.1095, Accuracy=61.36%\n",
      "Epoch 44/50: Loss=1.0304, Accuracy=64.18%\n",
      "Epoch 45/50: Loss=1.0052, Accuracy=65.13%\n",
      "Epoch 46/50: Loss=1.0153, Accuracy=64.64%\n",
      "Epoch 47/50: Loss=1.0694, Accuracy=63.06%\n",
      "Epoch 48/50: Loss=1.0667, Accuracy=62.99%\n",
      "Epoch 49/50: Loss=1.0831, Accuracy=62.41%\n",
      "Epoch 50/50: Loss=1.1073, Accuracy=61.28%\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = get_data_loaders('./data')\n",
    "# Example usage\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch_model = torch_model.to(device)\n",
    "\n",
    "tp.utils.print_tool.before_pruning(torch_model)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(torch_model.parameters(), lr=0.001)\n",
    "num_epochs = 50\n",
    "\n",
    "fine_tuned_model = train_model(torch_model, train_loader, criterion, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2269b7d3b40915",
   "metadata": {},
   "source": [
    "### Plotting params results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e570a6196c46943",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:05:22.667967Z",
     "start_time": "2025-04-10T13:05:22.317180Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data: Total parameters for each model\n",
    "strategies = ['Initial', 'Magnitude', 'BN Scale', 'Group Norm', 'Random', 'Taylor', 'Hessian', 'Lamp']\n",
    "params = [\n",
    "    1162530,  # Initial model (from your query)\n",
    "    305350,   # Magnitude (from output: 0.31M after pruning, assuming final tuned model)\n",
    "    301558,   # BN Scale (from your query and output: 0.31M after pruning)\n",
    "    305350,   # Group Norm (from output: 0.31M after pruning, assuming similar to magnitude)\n",
    "    305350,   # Random (from output: 0.31M after pruning, assuming similar to magnitude)\n",
    "    949650,   # Taylor (from output: 0.95M after pruning)\n",
    "    1162530,  # Hessian (from output: 1.17M, no reduction observed)\n",
    "    305350    # Lamp (from output: 0.31M after pruning)\n",
    "]\n",
    "initial_params = params[0]\n",
    "\n",
    "# Calculate percentage reduction for each strategy\n",
    "reductions = [((initial_params - p) / initial_params * 100) for p in params]\n",
    "\n",
    "# Colors for each strategy\n",
    "colors = ['gray', 'blue', 'green', 'red', 'purple', 'orange', 'brown', 'pink']\n",
    "\n",
    "# Create bar chart\n",
    "plt.figure(figsize=(14, 8))\n",
    "bars = plt.bar(strategies, params, color=colors)\n",
    "\n",
    "# Add value labels and percentage reduction\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:,}\\n({reductions[i]:.1f}%)' if i > 0 else f'{height:,}',\n",
    "             ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Add horizontal line for initial parameters\n",
    "plt.axhline(y=initial_params, color='gray', linestyle='--', label='Initial Parameters')\n",
    "\n",
    "# Customize the chart\n",
    "plt.xlabel('Pruning Strategy')\n",
    "plt.ylabel('Total Parameters')\n",
    "plt.title('Comparison of Total Parameters Across Pruning Strategies')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the chart to a file (since we're not displaying it interactively)\n",
    "plt.savefig('output/pruning_comparison.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3546bf41b88f86",
   "metadata": {},
   "source": [
    "### comparison for MACs, params, size_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24effc323e5da8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:12:58.906564Z",
     "start_time": "2025-04-10T14:12:58.499793Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data: Metrics for each model\n",
    "strategies = ['Initial', 'Magnitude', 'BN Scale', 'Group Norm', 'Random', 'Taylor', 'Hessian', 'Lamp']\n",
    "metrics = {\n",
    "    'params': [1162530, 305350, 301558, 305350, 305350, 949650, 1162530, 305350],  # Total parameters\n",
    "    'macs': [6060000, 1840000, 1840000, 1840000, 1840000, 4920000, 6060000, 1840000],  # MACs\n",
    "    'size_mb': [4.68, 1.22, 1.22, 1.22, 1.22, 3.80, 4.68, 1.22]  # Model size in MB\n",
    "}\n",
    "initial_metrics = {k: v[0] for k, v in metrics.items()}\n",
    "\n",
    "# Calculate percentage reductions\n",
    "reductions = {k: [((initial_metrics[k] - v) / initial_metrics[k] * 100) for v in values] for k, values in metrics.items()}\n",
    "\n",
    "# Colors for each strategy\n",
    "colors = ['gray', 'blue', 'green', 'red', 'purple', 'orange', 'brown', 'pink']\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 18))\n",
    "\n",
    "# Plot each metric\n",
    "for i, (metric_name, values) in enumerate(metrics.items()):\n",
    "    ax = axes[i]\n",
    "    bars = ax.bar(strategies, values, color=colors)\n",
    "\n",
    "    # Add value labels and percentage reduction\n",
    "    for j, bar in enumerate(bars):\n",
    "        height = bar.get_height()\n",
    "        label = f'{height:,}' if metric_name != 'size_mb' else f'{height:.2f}'\n",
    "        if j > 0:\n",
    "            label += f'\\n({reductions[metric_name][j]:.1f}%)'\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height, label, ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    # Add horizontal line for initial metric\n",
    "    ax.axhline(y=initial_metrics[metric_name], color='gray', linestyle='--', label='Initial')\n",
    "\n",
    "    # Customize subplot\n",
    "    ax.set_xlabel('Pruning Strategy')\n",
    "    ax.set_ylabel(metric_name.replace('_', ' ').title())\n",
    "    ax.set_title(f'Comparison of {metric_name.replace(\"_\", \" \").title()} Across Pruning Strategies')\n",
    "    ax.set_xticks(range(len(strategies)))\n",
    "    ax.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "\n",
    "# Adjust layout and save\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/pruning_metrics_comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6946f1a5fde43aaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T19:10:40.275735Z",
     "start_time": "2025-04-15T19:10:39.666362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "epochs = list(range(1, 11))\n",
    "train_acc = [18.48, 21.53, 21.21, 23.94, 26.32, 29.75, 31.91, 34.05, 36.34, 36.77]\n",
    "valid_acc = [21.93, 20.94, 22.23, 25.33, 27.88, 30.41, 33.33, 35.23, 37.02, 38.57]\n",
    "test_acc = [21.90, 21.01, 22.10, 24.86, 27.84, 31.08, 33.47, 35.38, 37.53, 38.45]\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "bar_width = 0.25\n",
    "x = np.arange(len(epochs))\n",
    "\n",
    "# Create bars\n",
    "plt.bar(x - bar_width, train_acc, bar_width, label='Train Accuracy', color='skyblue')\n",
    "plt.bar(x, valid_acc, bar_width, label='Validation Accuracy', color='lightgreen')\n",
    "plt.bar(x + bar_width, test_acc, bar_width, label='Test Accuracy', color='salmon')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Model Accuracy per Epoch')\n",
    "plt.xticks(x, epochs)\n",
    "plt.legend()\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('darts_accuracy_bar_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dea4c672dce55",
   "metadata": {},
   "source": [
    "### Gr: prune with threshold"
   ]
  },
  {
   "cell_type": "code",
   "id": "59ea3f26d421e293",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T11:15:03.055878Z",
     "start_time": "2025-05-15T11:15:03.048841Z"
    }
   },
   "source": [
    "#def gr_prune_model_with_threshold(model, example_input, target_macs, target_size_mb, strategy, max_iterative_steps=20, max_sparsity=0.9):\n",
    "def gr_prune_model_with_threshold(model, example_input, target_macs, target_size_mb, strategy, iterative_steps=5):\n",
    "    \"\"\"\n",
    "    Prune the model based on the specified strategy and targets.\n",
    "    \"\"\"\n",
    "    # Calculate initial metrics\n",
    "    current_macs, nparams = tp.utils.count_ops_and_params(model, example_input)\n",
    "    current_size_mb = sum(p.numel() * p.element_size() for p in model.parameters()) / (1024 ** 2)\n",
    "\n",
    "    print(f\"Initial MACs: {current_macs / 1e9:.3f} G, Size: {current_size_mb:.2f} MB\")\n",
    "\n",
    "    # Define pruning ratio (adjust based on targets if needed)\n",
    "    pruning_ratio = 0.5  # Example: 50% sparsity, adjust as needed\n",
    "\n",
    "    if isinstance(strategy['importance'], tp.importance.TaylorImportance):\n",
    "        # TaylorImportance requires gradients per step\n",
    "        pruner = strategy['pruner'](\n",
    "            model,\n",
    "            example_input,\n",
    "            importance=strategy['importance'],\n",
    "            iterative_steps=1,  # Handle iterations manually\n",
    "            ch_sparsity=pruning_ratio / iterative_steps,  # Prune a portion each step\n",
    "            root_module_types=[nn.Conv2d],\n",
    "            ignored_layers=[model.fc]\n",
    "        )\n",
    "        for i in range(iterative_steps):\n",
    "            model.zero_grad()\n",
    "            loss = model(example_input).sum()  # Dummy loss for gradients\n",
    "            loss.backward()\n",
    "            pruner.step()  # Apply pruning for this step\n",
    "            current_macs, _ = tp.utils.count_ops_and_params(model, example_input)\n",
    "            current_size_mb = sum(p.numel() * p.element_size() for p in model.parameters()) / (1024 ** 2)\n",
    "            print(f\"Step {i+1}/{iterative_steps}: MACs {current_macs / 1e9:.3f} G, Size {current_size_mb:.2f} MB\")\n",
    "            if current_macs <= target_macs and current_size_mb <= target_size_mb:\n",
    "                print(f\"Targets reached at step {i+1}\")\n",
    "                break\n",
    "            model.zero_grad()\n",
    "    else:\n",
    "        # Other strategies can prune in one go with iterative_steps\n",
    "        pruner = strategy['pruner'](\n",
    "            model,\n",
    "            example_input,\n",
    "            importance=strategy['importance'],\n",
    "            iterative_steps=iterative_steps,\n",
    "            ch_sparsity=pruning_ratio,\n",
    "            root_module_types=[nn.Conv2d],\n",
    "            ignored_layers=[model.fc]\n",
    "        )\n",
    "        pruner.step()  # Perform pruning over all steps\n",
    "        current_macs, _ = tp.utils.count_ops_and_params(model, example_input)\n",
    "        current_size_mb = sum(p.numel() * p.element_size() for p in model.parameters()) / (1024 ** 2)\n",
    "        print(f\"After pruning: MACs {current_macs / 1e9:.3f} G, Size {current_size_mb:.2f} MB\")\n",
    "\n",
    "    # Final check\n",
    "    if current_macs <= target_macs and current_size_mb <= target_size_mb:\n",
    "        print(\"Pruning targets achieved.\")\n",
    "    else:\n",
    "        print(\"Warning: Pruning targets not fully achieved.\")\n",
    "\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "ed9159eb03e0d570",
   "metadata": {},
   "source": [
    "### Gem: Prune with threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "572d5d540d81ce45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:15:38.633900Z",
     "start_time": "2025-04-29T03:15:38.623094Z"
    }
   },
   "outputs": [],
   "source": [
    "import time # Optional: for adding time limits or tracking\n",
    "\n",
    "# Assume calculate_macs is defined as before:\n",
    "# def calculate_macs(model, example_input):\n",
    "#     macs, params = tp.utils.count_ops_and_params(model, example_input)\n",
    "#     return macs, params\n",
    "\n",
    "def gem_prune_model_by_threshold(model, example_input, target_macs, target_params, strategy, max_iterations=100, step_ch_sparsity=0.1):\n",
    "    \"\"\"\n",
    "    Prunes the model iteratively until both MACs and parameter count are below\n",
    "    the specified thresholds, or max_iterations is reached.\n",
    "\n",
    "    Args:\n",
    "        model: The PyTorch model to prune.\n",
    "        example_input: Example input tensor for MACs calculation and pruner.\n",
    "        target_macs: The desired maximum MAC count.\n",
    "        target_params: The desired maximum parameter count.\n",
    "        strategy: Dictionary containing 'pruner' and 'importance'.\n",
    "        max_iterations (int): Safety limit for the number of pruning steps.\n",
    "        step_ch_sparsity (float): Channel sparsity target for each individual pruning step.\n",
    "                                  Influences how many candidates `pruner.step` proposes.\n",
    "                                  Smaller values lead to potentially finer steps.\n",
    "\n",
    "    Returns:\n",
    "        The pruned model.\n",
    "    \"\"\"\n",
    "    device = example_input.device\n",
    "    model.to(device) # Ensure model is on the correct device\n",
    "\n",
    "    print(f\"--- Starting Pruning (Strategy: {strategy['importance'].__class__.__name__}) ---\")\n",
    "    print(f\"Target MACs: {target_macs:,.0f}, Target Params: {target_params:,.0f}\")\n",
    "\n",
    "    # Instantiate the pruner\n",
    "    # Note: 'iterative_steps' in init is less critical here as the while loop controls iteration.\n",
    "    pruner = strategy['pruner'](\n",
    "        model,\n",
    "        example_input,\n",
    "        importance=strategy['importance'],\n",
    "        ch_sparsity=step_ch_sparsity, # Target sparsity *per step*\n",
    "        root_module_types=[nn.Conv2d], # Focus pruning on Conv layers\n",
    "        ignored_layers=[model.fc], # Don't prune the final classifier\n",
    "        # Optional: other pruner args like round_to might be useful depending on strategy/model\n",
    "        # round_to=8, # Example: commonly used for hardware efficiency\n",
    "    )\n",
    "\n",
    "    # Get initial state\n",
    "    current_macs, current_params = calculate_macs(model, example_input)\n",
    "    initial_macs, initial_params = current_macs, current_params # Keep for logging\n",
    "    print(f\"Initial | MACs: {current_macs:,.0f}, Params: {current_params:,.0f}\")\n",
    "\n",
    "    iteration = 0\n",
    "    model.eval() # Ensure model is in eval mode for pruning logic unless Taylor\n",
    "\n",
    "    while (current_macs > target_macs or current_params > target_params) and iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        macs_before_step = current_macs\n",
    "        params_before_step = current_params\n",
    "\n",
    "        # --- Special handling for Importance methods requiring gradients ---\n",
    "        if isinstance(strategy['importance'], (tp.importance.TaylorImportance, tp.importance.GroupHessianImportance)):\n",
    "             model.train() # Need gradients\n",
    "             # Ensure requires_grad is True if it was turned off\n",
    "             for param in model.parameters():\n",
    "                 param.requires_grad_(True)\n",
    "\n",
    "             loss = model(example_input).mean() # Use mean or sum as dummy loss\n",
    "             try:\n",
    "                 loss.backward() # Calculate gradients needed for importance\n",
    "             except Exception as e:\n",
    "                 print(f\"Error during backward pass for importance calc (Iter {iteration}): {e}\")\n",
    "                 # Decide how to handle: break, skip step, etc.\n",
    "                 break # Safer to stop if backward fails\n",
    "\n",
    "        # --- Perform one step of interactive pruning ---\n",
    "        try:\n",
    "            # Get the next set of pruning candidates based on current importance\n",
    "            pruning_groups = list(pruner.step(interactive=True))\n",
    "        except Exception as e:\n",
    "             print(f\"Error during pruner.step() (Iter {iteration}): {e}\")\n",
    "             # Handle potential errors during dependency analysis or importance scoring\n",
    "             break # Stop if pruner step fails\n",
    "\n",
    "        if not pruning_groups:\n",
    "            print(f\"Iteration {iteration}: Pruner found no more candidates. Stopping.\")\n",
    "            break # No more structures can be pruned according to the strategy/dependencies\n",
    "\n",
    "        # --- Apply the pruning ---\n",
    "        for group in pruning_groups:\n",
    "            group.prune()\n",
    "\n",
    "        # --- Clean up gradients if calculated ---\n",
    "        if isinstance(strategy['importance'], (tp.importance.TaylorImportance, tp.importance.GroupHessianImportance)):\n",
    "            # Zero gradients to prevent interference with potential future training/fine-tuning\n",
    "            model.zero_grad()\n",
    "            model.eval() # Switch back to eval mode after grad calculation\n",
    "\n",
    "        # --- Recalculate metrics ---\n",
    "        # It's crucial to recalculate AFTER pruning is applied\n",
    "        current_macs, current_params = calculate_macs(model, example_input)\n",
    "\n",
    "        # --- Log progress ---\n",
    "        print(\n",
    "            f\"Iter {iteration: >3}/{max_iterations} | \"\n",
    "            f\"MACs: {macs_before_step:,.0f} -> {current_macs:,.0f} \"\n",
    "            f\"({(macs_before_step-current_macs)/macs_before_step*100:+.1f}%) | \"\n",
    "            f\"Params: {params_before_step:,.0f} -> {current_params:,.0f} \"\n",
    "            f\"({(params_before_step-current_params)/params_before_step*100:+.1f}%)\"\n",
    "        )\n",
    "\n",
    "        # --- Check for Stagnation (optional but recommended) ---\n",
    "        if current_macs >= macs_before_step and current_params >= params_before_step:\n",
    "            print(f\"Iteration {iteration}: No reduction in MACs or Params this step. Stopping to prevent loop.\")\n",
    "            # This might happen if the only prunable groups left have negligible impact\n",
    "            # or if there's an issue with the importance/pruning logic.\n",
    "            break\n",
    "\n",
    "    # --- Final Status Report ---\n",
    "    print(f\"--- Finished Pruning (Strategy: {strategy['importance'].__class__.__name__}) ---\")\n",
    "    if iteration >= max_iterations:\n",
    "        print(f\"Warning: Reached maximum pruning iterations ({max_iterations}).\")\n",
    "\n",
    "    final_macs, final_params = calculate_macs(model, example_input)\n",
    "    print(f\"Initial | MACs: {initial_macs:,.0f}, Params: {initial_params:,.0f}\")\n",
    "    print(f\"Final   | MACs: {final_macs:,.0f}, Params: {final_params:,.0f}\")\n",
    "    print(f\"Target  | MACs: {target_macs:,.0f}, Params: {target_params:,.0f}\")\n",
    "\n",
    "    macs_reduction = (initial_macs - final_macs) / initial_macs * 100 if initial_macs > 0 else 0\n",
    "    params_reduction = (initial_params - final_params) / initial_params * 100 if initial_params > 0 else 0\n",
    "    print(f\"Reduction | MACs: {macs_reduction:.2f}%, Params: {params_reduction:.2f}%\")\n",
    "\n",
    "    if final_macs > target_macs or final_params > target_params:\n",
    "         print(\"Warning: Pruning finished, but target threshold(s) were not fully met.\")\n",
    "\n",
    "    model.eval() # Ensure model is in eval mode finally\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
