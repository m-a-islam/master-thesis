{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "377de838",
   "metadata": {},
   "source": [
    "## import necessary libraries for pruning"
   ]
  },
  {
   "cell_type": "code",
   "id": "7b6381473b81b890",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T09:46:07.081881Z",
     "start_time": "2025-04-10T09:46:04.961287Z"
    }
   },
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_pruning as tp\n",
    "\n",
    "from torch import optim\n",
    "from torch_pruning.pruner.algorithms.scheduler import linear_scheduler\n",
    "from torchsummary import summary\n",
    "\n",
    "from cnn.resNet.resnet_example import get_data_loaders\n",
    "import torch\n",
    "from torch import nn"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "631981174f5d8d8a",
   "metadata": {},
   "source": [
    "### Seed Network"
   ]
  },
  {
   "cell_type": "code",
   "id": "248e7c99c6815764",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T13:01:53.469349Z",
     "start_time": "2025-04-08T13:01:53.461690Z"
    }
   },
   "source": [
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, expansion=6):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.use_res_connect = self.stride == 1 and in_channels == out_channels\n",
    "\n",
    "        # Standard PyTorch layers (NO torch_pruning wrappers needed)\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels * expansion, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels * expansion)\n",
    "        self.relu = nn.ReLU6(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels * expansion, in_channels * expansion, kernel_size=3,\n",
    "            stride=stride, padding=1, groups=in_channels * expansion, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels * expansion)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels * expansion, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x if self.use_res_connect else None\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.use_res_connect:\n",
    "            return identity + out\n",
    "        else:\n",
    "            return out"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "6431a8ad17e1d446",
   "metadata": {},
   "source": [
    "### Mask Network"
   ]
  },
  {
   "cell_type": "code",
   "id": "4da304cf4cf9f871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T13:01:53.544465Z",
     "start_time": "2025-04-08T13:01:53.539461Z"
    }
   },
   "source": [
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        # --- Remove mask-related parameters ---\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU6(inplace=True)\n",
    "\n",
    "        # Define blocks (no mask_index or mask)\n",
    "        self.block1 = InvertedResidual(32, 16, stride=1)\n",
    "        self.block2 = InvertedResidual(16, 24, stride=2)\n",
    "        self.block3 = InvertedResidual(24, 32, stride=2)\n",
    "        self.block4 = InvertedResidual(32, 64, stride=2)\n",
    "        self.block5 = InvertedResidual(64, 96, stride=1)\n",
    "        self.block6 = InvertedResidual(96, 160, stride=2)\n",
    "        self.block7 = InvertedResidual(160, 320, stride=1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(1280)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(1280, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # --- Remove mask-based block skipping ---\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "        x = self.block7(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "4ad82bf3520f8612",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T13:01:54.967471Z",
     "start_time": "2025-04-08T13:01:54.877544Z"
    }
   },
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "7ebb1e087d2f0cd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T13:01:56.964260Z",
     "start_time": "2025-04-08T13:01:56.959786Z"
    }
   },
   "source": [
    "def save_model_as_onnx(model, example_input, output_path):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    # Export to ONNX\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        example_input,\n",
    "        output_path,\n",
    "        export_params=True,\n",
    "        opset_version=13,\n",
    "        input_names=['input'],\n",
    "        output_names=['output'],\n",
    "        dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    "    )\n",
    "    print(f\"✅ Model saved as ONNX to {output_path}\")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "3e9a817a37b770da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T13:01:58.669048Z",
     "start_time": "2025-04-08T13:01:58.665126Z"
    }
   },
   "source": [
    "def calculate_macs(model, example_input):\n",
    "    macs, params = tp.utils.count_ops_and_params(model, example_input)\n",
    "    return macs, params"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "5b29391c83349f69",
   "metadata": {},
   "source": [
    "### compare results of different pruning strategies"
   ]
  },
  {
   "cell_type": "code",
   "id": "becad7e59744f0dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T13:02:01.047231Z",
     "start_time": "2025-04-08T13:02:01.043197Z"
    }
   },
   "source": [
    "def compare_results(results):\n",
    "    print(\"\\n=== Pruning Strategy Comparison ===\")\n",
    "    print(f\"{'Strategy':<12} | {'MACs':<12} | {'Size (MB)':<10} | {'Accuracy (%)':<12}\")\n",
    "    print(\"-\" * 55)\n",
    "    for strategy, metrics in results.items():\n",
    "        print(f\"{strategy:<12} | {metrics['macs']:.2e} | {metrics['size_mb']:>9.2f} | {metrics['accuracy']:>12.2f}\")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "23869493d2f36a72",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "615130e04992f7ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T13:02:02.265863Z",
     "start_time": "2025-04-08T13:02:02.260798Z"
    }
   },
   "source": [
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "bbd2e296738ea559",
   "metadata": {},
   "source": [
    "### Utility function to save the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "b7f8aa766a2fa06a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T13:02:03.870642Z",
     "start_time": "2025-04-08T13:02:03.866847Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "def save_model(model, path, example_input=None):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    torch.save(model.state_dict(), path)\n",
    "    if example_input is not None:\n",
    "        onnx_path = path.replace('.pth', '.onnx')\n",
    "        save_model_as_onnx(model, example_input, onnx_path)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "89740bc4e512ecde",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "5484dc87c1b63c28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T13:48:50.929206Z",
     "start_time": "2025-04-08T13:48:50.924061Z"
    }
   },
   "source": [
    "def evaluate_model(model, test_loader, example_input, device):\n",
    "    model.eval()\n",
    "    # Calculate metrics\n",
    "    macs, _ = calculate_macs(model, example_input)\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    size_mb = params * 4 / 1e6\n",
    "\n",
    "    # Calculate accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = [d.to(device) for d in data]\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return {\n",
    "        'macs': macs,\n",
    "        'size_mb': size_mb,\n",
    "        'accuracy': 100 * correct / total\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "78f7147c66b6d346",
   "metadata": {},
   "source": [
    "### Prune the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "6532a7494fc3fcbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T13:14:19.638440Z",
     "start_time": "2025-04-08T13:14:19.633141Z"
    }
   },
   "source": [
    "def prune_model(model, example_input, target_macs, strategy, iterative_steps=5, iterative_pruning_ratio_scheduler=linear_scheduler()):\n",
    "    if isinstance(strategy['importance'], tp.importance.TaylorImportance):\n",
    "        pruning_ratio = 0.1\n",
    "    else:\n",
    "        pruning_ratio = 0.5\n",
    "\n",
    "    pruner = strategy['pruner'](\n",
    "        model,\n",
    "        example_input,\n",
    "        importance=strategy['importance'],\n",
    "        iterative_steps=iterative_steps,\n",
    "        ch_sparsity=pruning_ratio,  # Initial sparsity\n",
    "        iterative_pruning_ratio_scheduler=iterative_pruning_ratio_scheduler,\n",
    "        root_module_types=[nn.Conv2d],\n",
    "        ignored_layers=[model.fc],\n",
    "    )\n",
    "\n",
    "    current_macs, base_nparams = calculate_macs(model, example_input)\n",
    "    # while current_macs > target_macs:\n",
    "    #     pruner.step()\n",
    "    #     current_macs = calculate_macs(model, example_input)\n",
    "\n",
    "\n",
    "    for i in range(iterative_steps):\n",
    "            if isinstance(strategy['importance'], tp.importance.TaylorImportance):\n",
    "                loss = model(example_input).sum() # a dummy loss for TaylorImportance\n",
    "                loss.backward()\n",
    "            for g in pruner.step(interactive=True):\n",
    "                g.prune()\n",
    "            macs, nparams = tp.utils.count_ops_and_params(model, example_input)\n",
    "            print(model(example_input).shape)\n",
    "            print(\n",
    "                \"  Iter %d/%d, Params: %.2f M => %.2f M\"\n",
    "                % (i + 1, iterative_steps, base_nparams / 1e6, nparams / 1e6)\n",
    "            )\n",
    "            print(\n",
    "                \"  Iter %d/%d, MACs: %.2f G => %.2f G\"\n",
    "                % (i + 1, iterative_steps, current_macs / 1e9, macs / 1e9)\n",
    "            )\n",
    "\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "6adb22651c74e5f0",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "a6e1edc8a36e5260",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:34:32.036260Z",
     "start_time": "2025-04-09T13:34:32.031252Z"
    }
   },
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, device, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in train_loader:\n",
    "            inputs, labels = [d.to(device) for d in data]\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}: Loss={epoch_loss:.4f}, Accuracy={epoch_acc:.2f}%\")\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "b26416e6ff76416a",
   "metadata": {},
   "source": [
    "### Main workflow"
   ]
  },
  {
   "cell_type": "code",
   "id": "bdf93b3196076098",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T13:15:07.398189Z",
     "start_time": "2025-04-08T13:15:07.388665Z"
    }
   },
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'strategies': {\n",
    "            'magnitude': {\n",
    "                'pruner': tp.pruner.MagnitudePruner,\n",
    "                'importance': tp.importance.MagnitudeImportance(p=2),\n",
    "            },\n",
    "            'bn_scale': {\n",
    "                'pruner': tp.pruner.BNScalePruner,\n",
    "                'importance': tp.importance.BNScaleImportance(),\n",
    "            },\n",
    "            # todo: check the examples for the following strategies, why it is giving error\n",
    "            'group_norm': {\n",
    "                'pruner': tp.pruner.GroupNormPruner,\n",
    "                'importance': tp.importance.GroupMagnitudeImportance(p=1),\n",
    "            },\n",
    "            'random': {\n",
    "                'pruner': tp.pruner.MagnitudePruner,\n",
    "                'importance': tp.importance.RandomImportance(),\n",
    "            },\n",
    "            'Taylor': {\n",
    "                'pruner': tp.pruner.MagnitudePruner,\n",
    "                'importance': tp.importance.TaylorImportance()\n",
    "            },\n",
    "            'Hessian': {\n",
    "                'pruner': tp.pruner.MagnitudePruner,\n",
    "                'importance': tp.importance.GroupHessianImportance()\n",
    "            },\n",
    "            'lamp': {\n",
    "                'pruner': tp.pruner.MagnitudePruner,\n",
    "                'importance': tp.importance.LAMPImportance(p=2)\n",
    "            },\n",
    "            #todo: implement growing reg pruning\n",
    "        },\n",
    "        #todo: different types of schedulers can be added\n",
    "        'iterative_pruning_ratio_scheduler': linear_scheduler(),\n",
    "        'target_macs_sparsity': 0.5,\n",
    "        'train_epochs': 10,\n",
    "        'fine_tune_epochs': 20,\n",
    "        'data_dir': './data',\n",
    "        'output_dir': './output/strategies',\n",
    "        'iterative_steps': 5,\n",
    "    }\n",
    "\n",
    "    # Initialize model and data\n",
    "    model = MobileNetV2(num_classes=10).to(device)\n",
    "    train_loader, test_loader = get_data_loaders(config['data_dir'])\n",
    "    example_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "\n",
    "    # Workflow execution\n",
    "    initial_model_path = os.path.join(config['output_dir'], \"mobilenetv2_initial.pth\")\n",
    "\n",
    "    if not os.path.exists(initial_model_path):\n",
    "        # 1. Initial training\n",
    "        model = train_model(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            criterion=nn.CrossEntropyLoss().to(device),\n",
    "            optimizer=optim.Adam(model.parameters(), lr=0.001),\n",
    "            device=device,\n",
    "            num_epochs=config['train_epochs']\n",
    "        )\n",
    "        save_model(model, initial_model_path, example_input)\n",
    "\n",
    "    # 2. Pruning and evaluation workflow\n",
    "    results = {}\n",
    "    initial_macs, initial_params = calculate_macs(model, example_input)\n",
    "    target_macs = initial_macs * config['target_macs_sparsity']\n",
    "\n",
    "    for strategy_name in config['strategies']:\n",
    "        # 2a. Prepare fresh model for each strategy\n",
    "        model_copy = load_model(MobileNetV2(num_classes=10).to(device), initial_model_path)\n",
    "\n",
    "        # 2b. Perform pruning\n",
    "        pruned_model = prune_model(\n",
    "            model=model_copy,\n",
    "            example_input=example_input,\n",
    "            target_macs=target_macs,\n",
    "            strategy=config['strategies'][strategy_name],\n",
    "            iterative_steps=config['iterative_steps'],\n",
    "            'iterative_pruning_ratio_scheduler'=config['iterative_pruning_ratio_scheduler'],\n",
    "        )\n",
    "\n",
    "        # 2c. Save pruned model\n",
    "        pruned_path = os.path.join(config['output_dir'], f\"mobilenetv2_{strategy_name}_pruned.pth\")\n",
    "        save_model(pruned_model, pruned_path, example_input)\n",
    "\n",
    "        # 2d. Fine-tune\n",
    "        # todo: lr, more epochs, early stopping\n",
    "        fine_tuned_model = train_model(\n",
    "            model=pruned_model,\n",
    "            train_loader=train_loader,\n",
    "            criterion=nn.CrossEntropyLoss().to(device),\n",
    "            optimizer=optim.Adam(pruned_model.parameters(), lr=0.001),\n",
    "            device=device,\n",
    "            num_epochs=config['fine_tune_epochs']\n",
    "        )\n",
    "\n",
    "        # 2e. Evaluate\n",
    "        results[strategy_name] = evaluate_model(\n",
    "            model=fine_tuned_model,\n",
    "            test_loader=test_loader,\n",
    "            example_input=example_input,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # 2f. Save final model\n",
    "        final_path = os.path.join(config['output_dir'], f\"mobilenetv2_{strategy_name}_final.pth\")\n",
    "        save_model(fine_tuned_model, final_path, example_input)\n",
    "\n",
    "    # 3. Compare results\n",
    "    compare_results(results)\n",
    "    print(\"Workflow completed successfully!\")"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "6d51f760-3726-4028-98a7-02e0105ebd82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T13:58:27.369445Z",
     "start_time": "2025-04-08T13:49:06.194839Z"
    }
   },
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset directory: /home/muis/thesis/github-repo/master-thesis/cnn/mobile_net_v2/data\n",
      "Epoch 1/10: Loss=1.6531, Accuracy=39.32%\n",
      "Epoch 2/10: Loss=1.2808, Accuracy=54.42%\n",
      "Epoch 3/10: Loss=1.0993, Accuracy=61.08%\n",
      "Epoch 4/10: Loss=0.9806, Accuracy=65.62%\n",
      "Epoch 5/10: Loss=0.8908, Accuracy=69.04%\n",
      "Epoch 6/10: Loss=0.8198, Accuracy=71.39%\n",
      "Epoch 7/10: Loss=0.7561, Accuracy=73.34%\n",
      "Epoch 8/10: Loss=0.7010, Accuracy=75.39%\n",
      "Epoch 9/10: Loss=0.6570, Accuracy=77.17%\n",
      "Epoch 10/10: Loss=0.6133, Accuracy=78.39%\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_initial.onnx\n",
      "torch.Size([1, 10])\n",
      "  Iter 1/5, Params: 1.17 M => 0.95 M\n",
      "  Iter 1/5, MACs: 0.01 G => 0.00 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 2/5, Params: 1.17 M => 0.76 M\n",
      "  Iter 2/5, MACs: 0.01 G => 0.00 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 3/5, Params: 1.17 M => 0.58 M\n",
      "  Iter 3/5, MACs: 0.01 G => 0.00 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 4/5, Params: 1.17 M => 0.43 M\n",
      "  Iter 4/5, MACs: 0.01 G => 0.00 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 5/5, Params: 1.17 M => 0.31 M\n",
      "  Iter 5/5, MACs: 0.01 G => 0.00 G\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_magnitude_pruned.onnx\n",
      "Epoch 1/10: Loss=1.2023, Accuracy=58.46%\n",
      "Epoch 2/10: Loss=0.9148, Accuracy=67.94%\n",
      "Epoch 3/10: Loss=0.8350, Accuracy=70.50%\n",
      "Epoch 4/10: Loss=0.7797, Accuracy=72.40%\n",
      "Epoch 5/10: Loss=0.7465, Accuracy=73.57%\n",
      "Epoch 6/10: Loss=0.7137, Accuracy=74.99%\n",
      "Epoch 7/10: Loss=0.6858, Accuracy=75.68%\n",
      "Epoch 8/10: Loss=0.6600, Accuracy=76.70%\n",
      "Epoch 9/10: Loss=0.6362, Accuracy=77.46%\n",
      "Epoch 10/10: Loss=0.6172, Accuracy=78.13%\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_magnitude_final.onnx\n",
      "torch.Size([1, 10])\n",
      "  Iter 1/5, Params: 1.17 M => 0.95 M\n",
      "  Iter 1/5, MACs: 0.01 G => 0.00 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 2/5, Params: 1.17 M => 0.76 M\n",
      "  Iter 2/5, MACs: 0.01 G => 0.00 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 3/5, Params: 1.17 M => 0.58 M\n",
      "  Iter 3/5, MACs: 0.01 G => 0.00 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 4/5, Params: 1.17 M => 0.43 M\n",
      "  Iter 4/5, MACs: 0.01 G => 0.00 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 5/5, Params: 1.17 M => 0.31 M\n",
      "  Iter 5/5, MACs: 0.01 G => 0.00 G\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_bn_scale_pruned.onnx\n",
      "Epoch 1/10: Loss=1.2008, Accuracy=58.19%\n",
      "Epoch 2/10: Loss=0.9163, Accuracy=67.77%\n",
      "Epoch 3/10: Loss=0.8324, Accuracy=70.76%\n",
      "Epoch 4/10: Loss=0.7848, Accuracy=72.49%\n",
      "Epoch 5/10: Loss=0.7425, Accuracy=73.78%\n",
      "Epoch 6/10: Loss=0.7078, Accuracy=74.90%\n",
      "Epoch 7/10: Loss=0.6838, Accuracy=75.92%\n",
      "Epoch 8/10: Loss=0.6564, Accuracy=76.72%\n",
      "Epoch 9/10: Loss=0.6338, Accuracy=77.45%\n",
      "Epoch 10/10: Loss=0.6149, Accuracy=78.31%\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_bn_scale_final.onnx\n",
      "torch.Size([1, 10])\n",
      "  Iter 1/5, Params: 1.17 M => 0.95 M\n",
      "  Iter 1/5, MACs: 0.01 G => 0.00 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 2/5, Params: 1.17 M => 0.76 M\n",
      "  Iter 2/5, MACs: 0.01 G => 0.00 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 3/5, Params: 1.17 M => 0.58 M\n",
      "  Iter 3/5, MACs: 0.01 G => 0.00 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 4/5, Params: 1.17 M => 0.43 M\n",
      "  Iter 4/5, MACs: 0.01 G => 0.00 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 5/5, Params: 1.17 M => 0.31 M\n",
      "  Iter 5/5, MACs: 0.01 G => 0.00 G\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_group_norm_pruned.onnx\n",
      "Epoch 1/10: Loss=1.1556, Accuracy=59.98%\n",
      "Epoch 2/10: Loss=0.8871, Accuracy=68.74%\n",
      "Epoch 3/10: Loss=0.8069, Accuracy=71.46%\n",
      "Epoch 4/10: Loss=0.7628, Accuracy=72.95%\n",
      "Epoch 5/10: Loss=0.7187, Accuracy=74.69%\n",
      "Epoch 6/10: Loss=0.6864, Accuracy=75.61%\n",
      "Epoch 7/10: Loss=0.6548, Accuracy=76.73%\n",
      "Epoch 8/10: Loss=0.6329, Accuracy=77.61%\n",
      "Epoch 9/10: Loss=0.6098, Accuracy=78.26%\n",
      "Epoch 10/10: Loss=0.5920, Accuracy=78.84%\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_group_norm_final.onnx\n",
      "torch.Size([1, 10])\n",
      "  Iter 1/5, Params: 1.17 M => 0.95 M\n",
      "  Iter 1/5, MACs: 0.01 G => 0.00 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 2/5, Params: 1.17 M => 0.76 M\n",
      "  Iter 2/5, MACs: 0.01 G => 0.00 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 3/5, Params: 1.17 M => 0.58 M\n",
      "  Iter 3/5, MACs: 0.01 G => 0.00 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 4/5, Params: 1.17 M => 0.43 M\n",
      "  Iter 4/5, MACs: 0.01 G => 0.00 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 5/5, Params: 1.17 M => 0.31 M\n",
      "  Iter 5/5, MACs: 0.01 G => 0.00 G\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_random_pruned.onnx\n",
      "Epoch 1/10: Loss=1.2752, Accuracy=54.27%\n",
      "Epoch 2/10: Loss=0.9665, Accuracy=65.86%\n",
      "Epoch 3/10: Loss=0.8716, Accuracy=69.26%\n",
      "Epoch 4/10: Loss=0.8115, Accuracy=71.39%\n",
      "Epoch 5/10: Loss=0.7692, Accuracy=72.76%\n",
      "Epoch 6/10: Loss=0.7309, Accuracy=74.21%\n",
      "Epoch 7/10: Loss=0.7063, Accuracy=74.93%\n",
      "Epoch 8/10: Loss=0.6732, Accuracy=76.14%\n",
      "Epoch 9/10: Loss=0.6493, Accuracy=76.95%\n",
      "Epoch 10/10: Loss=0.6281, Accuracy=77.70%\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_random_final.onnx\n",
      "torch.Size([1, 10])\n",
      "  Iter 1/5, Params: 1.17 M => 1.12 M\n",
      "  Iter 1/5, MACs: 0.01 G => 0.01 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 2/5, Params: 1.17 M => 1.08 M\n",
      "  Iter 2/5, MACs: 0.01 G => 0.01 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 3/5, Params: 1.17 M => 1.03 M\n",
      "  Iter 3/5, MACs: 0.01 G => 0.01 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 4/5, Params: 1.17 M => 0.99 M\n",
      "  Iter 4/5, MACs: 0.01 G => 0.01 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 5/5, Params: 1.17 M => 0.95 M\n",
      "  Iter 5/5, MACs: 0.01 G => 0.00 G\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_Taylor_pruned.onnx\n",
      "Epoch 1/10: Loss=0.6969, Accuracy=75.39%\n",
      "Epoch 2/10: Loss=0.6172, Accuracy=78.42%\n",
      "Epoch 3/10: Loss=0.5741, Accuracy=79.85%\n",
      "Epoch 4/10: Loss=0.5350, Accuracy=81.20%\n",
      "Epoch 5/10: Loss=0.5087, Accuracy=82.03%\n",
      "Epoch 6/10: Loss=0.4830, Accuracy=82.78%\n",
      "Epoch 7/10: Loss=0.4525, Accuracy=83.98%\n",
      "Epoch 8/10: Loss=0.4390, Accuracy=84.65%\n",
      "Epoch 9/10: Loss=0.4121, Accuracy=85.27%\n",
      "Epoch 10/10: Loss=0.3937, Accuracy=86.01%\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_Taylor_final.onnx\n",
      "torch.Size([1, 10])\n",
      "  Iter 1/5, Params: 1.17 M => 1.17 M\n",
      "  Iter 1/5, MACs: 0.01 G => 0.01 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 2/5, Params: 1.17 M => 1.17 M\n",
      "  Iter 2/5, MACs: 0.01 G => 0.01 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 3/5, Params: 1.17 M => 1.17 M\n",
      "  Iter 3/5, MACs: 0.01 G => 0.01 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 4/5, Params: 1.17 M => 1.17 M\n",
      "  Iter 4/5, MACs: 0.01 G => 0.01 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 5/5, Params: 1.17 M => 1.17 M\n",
      "  Iter 5/5, MACs: 0.01 G => 0.01 G\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_Hessian_pruned.onnx\n",
      "Epoch 1/10: Loss=0.5836, Accuracy=79.66%\n",
      "Epoch 2/10: Loss=0.5434, Accuracy=80.78%\n",
      "Epoch 3/10: Loss=0.5178, Accuracy=81.72%\n",
      "Epoch 4/10: Loss=0.4927, Accuracy=82.67%\n",
      "Epoch 5/10: Loss=0.4590, Accuracy=83.74%\n",
      "Epoch 6/10: Loss=0.4393, Accuracy=84.56%\n",
      "Epoch 7/10: Loss=0.4131, Accuracy=85.27%\n",
      "Epoch 8/10: Loss=0.3945, Accuracy=85.93%\n",
      "Epoch 9/10: Loss=0.3734, Accuracy=86.54%\n",
      "Epoch 10/10: Loss=0.3592, Accuracy=87.24%\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_Hessian_final.onnx\n",
      "torch.Size([1, 10])\n",
      "  Iter 1/5, Params: 1.17 M => 0.95 M\n",
      "  Iter 1/5, MACs: 0.01 G => 0.00 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 2/5, Params: 1.17 M => 0.76 M\n",
      "  Iter 2/5, MACs: 0.01 G => 0.00 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 3/5, Params: 1.17 M => 0.58 M\n",
      "  Iter 3/5, MACs: 0.01 G => 0.00 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 4/5, Params: 1.17 M => 0.43 M\n",
      "  Iter 4/5, MACs: 0.01 G => 0.00 G\n",
      "torch.Size([1, 10])\n",
      "  Iter 5/5, Params: 1.17 M => 0.31 M\n",
      "  Iter 5/5, MACs: 0.01 G => 0.00 G\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_lamp_pruned.onnx\n",
      "Epoch 1/10: Loss=1.2001, Accuracy=58.47%\n",
      "Epoch 2/10: Loss=0.9165, Accuracy=67.74%\n",
      "Epoch 3/10: Loss=0.8334, Accuracy=70.70%\n",
      "Epoch 4/10: Loss=0.7841, Accuracy=72.44%\n",
      "Epoch 5/10: Loss=0.7461, Accuracy=73.68%\n",
      "Epoch 6/10: Loss=0.7155, Accuracy=74.88%\n",
      "Epoch 7/10: Loss=0.6832, Accuracy=75.86%\n",
      "Epoch 8/10: Loss=0.6664, Accuracy=76.50%\n",
      "Epoch 9/10: Loss=0.6420, Accuracy=77.44%\n",
      "Epoch 10/10: Loss=0.6216, Accuracy=78.07%\n",
      "✅ Model saved as ONNX to ./output/strategies/mobilenetv2_lamp_final.onnx\n",
      "\n",
      "=== Pruning Strategy Comparison ===\n",
      "Strategy     | MACs         | Size (MB)  | Accuracy (%)\n",
      "-------------------------------------------------------\n",
      "magnitude    | 1.84e+06 |      1.22 |        73.39\n",
      "bn_scale     | 1.84e+06 |      1.22 |        73.03\n",
      "group_norm   | 1.84e+06 |      1.22 |        74.27\n",
      "random       | 1.84e+06 |      1.22 |        72.64\n",
      "Taylor       | 4.92e+06 |      3.80 |        75.40\n",
      "Hessian      | 6.06e+06 |      4.68 |        75.93\n",
      "lamp         | 1.84e+06 |      1.22 |        72.43\n",
      "Workflow completed successfully!\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad46ea6-97a2-4d9a-9465-f8076bb0ef3f",
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load the saved Onnx model and convert to Pytorch model",
   "id": "238badca29395cae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T12:24:13.022499Z",
     "start_time": "2025-04-10T12:24:12.993796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from onnx2torch import convert\n",
    "\n",
    "# Step 1: Load the ONNX model\n",
    "onnx_model_path = './output/strategies/mobilenetv2_bn_scale_final.onnx'\n",
    "onnx_model = onnx.load(onnx_model_path)\n",
    "onnx.checker.check_model(onnx_model)  # Verify the ONNX model\n",
    "print(\"✅ ONNX model loaded and verified.\")\n",
    "\n",
    "# Step 2: Convert ONNX to PyTorch\n",
    "torch_model = convert(onnx_model)\n",
    "print(\"✅ ONNX model converted to PyTorch.\")\n",
    "tp.utils.print_tool.before_pruning(torch_model)\n"
   ],
   "id": "229d26f48f444268",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ONNX model loaded and verified.\n",
      "✅ ONNX model converted to PyTorch.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T12:24:21.518145Z",
     "start_time": "2025-04-10T12:24:21.512261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchinfo import summary\n",
    "print(summary(torch_model))"
   ],
   "id": "38ba67685c8f9c69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "GraphModule                                             --\n",
      "├─Conv2d: 1-1                                           448\n",
      "├─OnnxConstant: 1-2                                     --\n",
      "├─OnnxConstant: 1-3                                     --\n",
      "├─ReLU6: 1-4                                            --\n",
      "├─Conv2d: 1-5                                           1,632\n",
      "├─OnnxConstant: 1-6                                     --\n",
      "├─OnnxConstant: 1-7                                     --\n",
      "├─ReLU6: 1-8                                            --\n",
      "├─Conv2d: 1-9                                           960\n",
      "├─OnnxConstant: 1-10                                    --\n",
      "├─OnnxConstant: 1-11                                    --\n",
      "├─ReLU6: 1-12                                           --\n",
      "├─Conv2d: 1-13                                          776\n",
      "├─Conv2d: 1-14                                          432\n",
      "├─OnnxConstant: 1-15                                    --\n",
      "├─OnnxConstant: 1-16                                    --\n",
      "├─ReLU6: 1-17                                           --\n",
      "├─Conv2d: 1-18                                          480\n",
      "├─OnnxConstant: 1-19                                    --\n",
      "├─OnnxConstant: 1-20                                    --\n",
      "├─ReLU6: 1-21                                           --\n",
      "├─Conv2d: 1-22                                          588\n",
      "├─Conv2d: 1-23                                          936\n",
      "├─OnnxConstant: 1-24                                    --\n",
      "├─OnnxConstant: 1-25                                    --\n",
      "├─ReLU6: 1-26                                           --\n",
      "├─Conv2d: 1-27                                          720\n",
      "├─OnnxConstant: 1-28                                    --\n",
      "├─OnnxConstant: 1-29                                    --\n",
      "├─ReLU6: 1-30                                           --\n",
      "├─Conv2d: 1-31                                          1,168\n",
      "├─Conv2d: 1-32                                          1,632\n",
      "├─OnnxConstant: 1-33                                    --\n",
      "├─OnnxConstant: 1-34                                    --\n",
      "├─ReLU6: 1-35                                           --\n",
      "├─Conv2d: 1-36                                          960\n",
      "├─OnnxConstant: 1-37                                    --\n",
      "├─OnnxConstant: 1-38                                    --\n",
      "├─ReLU6: 1-39                                           --\n",
      "├─Conv2d: 1-40                                          3,104\n",
      "├─Conv2d: 1-41                                          6,336\n",
      "├─OnnxConstant: 1-42                                    --\n",
      "├─OnnxConstant: 1-43                                    --\n",
      "├─ReLU6: 1-44                                           --\n",
      "├─Conv2d: 1-45                                          1,920\n",
      "├─OnnxConstant: 1-46                                    --\n",
      "├─OnnxConstant: 1-47                                    --\n",
      "├─ReLU6: 1-48                                           --\n",
      "├─Conv2d: 1-49                                          9,264\n",
      "├─Conv2d: 1-50                                          14,112\n",
      "├─OnnxConstant: 1-51                                    --\n",
      "├─OnnxConstant: 1-52                                    --\n",
      "├─ReLU6: 1-53                                           --\n",
      "├─Conv2d: 1-54                                          2,880\n",
      "├─OnnxConstant: 1-55                                    --\n",
      "├─OnnxConstant: 1-56                                    --\n",
      "├─ReLU6: 1-57                                           --\n",
      "├─Conv2d: 1-58                                          23,120\n",
      "├─Conv2d: 1-59                                          38,880\n",
      "├─OnnxConstant: 1-60                                    --\n",
      "├─OnnxConstant: 1-61                                    --\n",
      "├─ReLU6: 1-62                                           --\n",
      "├─Conv2d: 1-63                                          4,800\n",
      "├─OnnxConstant: 1-64                                    --\n",
      "├─OnnxConstant: 1-65                                    --\n",
      "├─ReLU6: 1-66                                           --\n",
      "├─Conv2d: 1-67                                          76,960\n",
      "├─Conv2d: 1-68                                          103,040\n",
      "├─OnnxConstant: 1-69                                    --\n",
      "├─OnnxConstant: 1-70                                    --\n",
      "├─ReLU6: 1-71                                           --\n",
      "├─OnnxGlobalAveragePoolWithKnownInputShape: 1-72        --\n",
      "├─Flatten: 1-73                                         --\n",
      "├─Linear: 1-74                                          6,410\n",
      "================================================================================\n",
      "Total params: 301,558\n",
      "Trainable params: 301,558\n",
      "Non-trainable params: 0\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T10:39:54.201742Z",
     "start_time": "2025-04-10T10:39:54.150874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from torchinfo import summary\n",
    "print(summary(torch_model))\n",
    "#tp.utils.print_tool.after_pruning(torch_model)\n"
   ],
   "id": "4d1dd20bc238d90a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "GraphModule                                             --\n",
      "├─Conv2d: 1-1                                           896\n",
      "├─OnnxConstant: 1-2                                     --\n",
      "├─OnnxConstant: 1-3                                     --\n",
      "├─ReLU6: 1-4                                            --\n",
      "├─Conv2d: 1-5                                           6,336\n",
      "├─OnnxConstant: 1-6                                     --\n",
      "├─OnnxConstant: 1-7                                     --\n",
      "├─ReLU6: 1-8                                            --\n",
      "├─Conv2d: 1-9                                           1,920\n",
      "├─OnnxConstant: 1-10                                    --\n",
      "├─OnnxConstant: 1-11                                    --\n",
      "├─ReLU6: 1-12                                           --\n",
      "├─Conv2d: 1-13                                          3,088\n",
      "├─Conv2d: 1-14                                          1,632\n",
      "├─OnnxConstant: 1-15                                    --\n",
      "├─OnnxConstant: 1-16                                    --\n",
      "├─ReLU6: 1-17                                           --\n",
      "├─Conv2d: 1-18                                          960\n",
      "├─OnnxConstant: 1-19                                    --\n",
      "├─OnnxConstant: 1-20                                    --\n",
      "├─ReLU6: 1-21                                           --\n",
      "├─Conv2d: 1-22                                          2,328\n",
      "├─Conv2d: 1-23                                          3,600\n",
      "├─OnnxConstant: 1-24                                    --\n",
      "├─OnnxConstant: 1-25                                    --\n",
      "├─ReLU6: 1-26                                           --\n",
      "├─Conv2d: 1-27                                          1,440\n",
      "├─OnnxConstant: 1-28                                    --\n",
      "├─OnnxConstant: 1-29                                    --\n",
      "├─ReLU6: 1-30                                           --\n",
      "├─Conv2d: 1-31                                          4,640\n",
      "├─Conv2d: 1-32                                          6,336\n",
      "├─OnnxConstant: 1-33                                    --\n",
      "├─OnnxConstant: 1-34                                    --\n",
      "├─ReLU6: 1-35                                           --\n",
      "├─Conv2d: 1-36                                          1,920\n",
      "├─OnnxConstant: 1-37                                    --\n",
      "├─OnnxConstant: 1-38                                    --\n",
      "├─ReLU6: 1-39                                           --\n",
      "├─Conv2d: 1-40                                          12,352\n",
      "├─Conv2d: 1-41                                          24,960\n",
      "├─OnnxConstant: 1-42                                    --\n",
      "├─OnnxConstant: 1-43                                    --\n",
      "├─ReLU6: 1-44                                           --\n",
      "├─Conv2d: 1-45                                          3,840\n",
      "├─OnnxConstant: 1-46                                    --\n",
      "├─OnnxConstant: 1-47                                    --\n",
      "├─ReLU6: 1-48                                           --\n",
      "├─Conv2d: 1-49                                          36,960\n",
      "├─Conv2d: 1-50                                          55,872\n",
      "├─OnnxConstant: 1-51                                    --\n",
      "├─OnnxConstant: 1-52                                    --\n",
      "├─ReLU6: 1-53                                           --\n",
      "├─Conv2d: 1-54                                          5,760\n",
      "├─OnnxConstant: 1-55                                    --\n",
      "├─OnnxConstant: 1-56                                    --\n",
      "├─ReLU6: 1-57                                           --\n",
      "├─Conv2d: 1-58                                          92,320\n",
      "├─Conv2d: 1-59                                          154,560\n",
      "├─OnnxConstant: 1-60                                    --\n",
      "├─OnnxConstant: 1-61                                    --\n",
      "├─ReLU6: 1-62                                           --\n",
      "├─Conv2d: 1-63                                          9,600\n",
      "├─OnnxConstant: 1-64                                    --\n",
      "├─OnnxConstant: 1-65                                    --\n",
      "├─ReLU6: 1-66                                           --\n",
      "├─Conv2d: 1-67                                          307,520\n",
      "├─Conv2d: 1-68                                          410,880\n",
      "├─OnnxConstant: 1-69                                    --\n",
      "├─OnnxConstant: 1-70                                    --\n",
      "├─ReLU6: 1-71                                           --\n",
      "├─OnnxGlobalAveragePoolWithKnownInputShape: 1-72        --\n",
      "├─Flatten: 1-73                                         --\n",
      "├─Linear: 1-74                                          12,810\n",
      "================================================================================\n",
      "Total params: 1,162,530\n",
      "Trainable params: 1,162,530\n",
      "Non-trainable params: 0\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load the converted Pytorch model and fine-tune",
   "id": "8de5ca7f1456a3d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:41:44.435126Z",
     "start_time": "2025-04-09T13:37:33.019618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader, test_loader = get_data_loaders('./data')\n",
    "# Example usage\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch_model = torch_model.to(device)\n",
    "\n",
    "tp.utils.print_tool.before_pruning(torch_model)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(torch_model.parameters(), lr=0.001)\n",
    "num_epochs = 50\n",
    "\n",
    "fine_tuned_model = train_model(torch_model, train_loader, criterion, optimizer, device, num_epochs)"
   ],
   "id": "e1ece7efcc1c6179",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset directory: /home/muis/thesis/github-repo/master-thesis/cnn/mobile_net_v2/data\n",
      "Epoch 1/50: Loss=0.6039, Accuracy=78.76%\n",
      "Epoch 2/50: Loss=0.6009, Accuracy=78.70%\n",
      "Epoch 3/50: Loss=0.5960, Accuracy=78.91%\n",
      "Epoch 4/50: Loss=0.5975, Accuracy=78.81%\n",
      "Epoch 5/50: Loss=0.5957, Accuracy=78.92%\n",
      "Epoch 6/50: Loss=0.5969, Accuracy=78.82%\n",
      "Epoch 7/50: Loss=0.6109, Accuracy=78.42%\n",
      "Epoch 8/50: Loss=0.6080, Accuracy=78.65%\n",
      "Epoch 9/50: Loss=0.6081, Accuracy=78.52%\n",
      "Epoch 10/50: Loss=0.6090, Accuracy=78.53%\n",
      "Epoch 11/50: Loss=0.6294, Accuracy=77.73%\n",
      "Epoch 12/50: Loss=0.6354, Accuracy=77.75%\n",
      "Epoch 13/50: Loss=0.6369, Accuracy=77.76%\n",
      "Epoch 14/50: Loss=0.6398, Accuracy=77.80%\n",
      "Epoch 15/50: Loss=0.6449, Accuracy=77.49%\n",
      "Epoch 16/50: Loss=0.6451, Accuracy=77.21%\n",
      "Epoch 17/50: Loss=0.6569, Accuracy=76.93%\n",
      "Epoch 18/50: Loss=0.6594, Accuracy=76.96%\n",
      "Epoch 19/50: Loss=0.6644, Accuracy=76.68%\n",
      "Epoch 20/50: Loss=0.6890, Accuracy=76.04%\n",
      "Epoch 21/50: Loss=0.7159, Accuracy=75.11%\n",
      "Epoch 22/50: Loss=0.7258, Accuracy=74.65%\n",
      "Epoch 23/50: Loss=0.7349, Accuracy=74.31%\n",
      "Epoch 24/50: Loss=0.7270, Accuracy=74.58%\n",
      "Epoch 25/50: Loss=0.7467, Accuracy=74.14%\n",
      "Epoch 26/50: Loss=0.7675, Accuracy=73.00%\n",
      "Epoch 27/50: Loss=0.8084, Accuracy=72.25%\n",
      "Epoch 28/50: Loss=0.7989, Accuracy=72.42%\n",
      "Epoch 29/50: Loss=0.8117, Accuracy=72.01%\n",
      "Epoch 30/50: Loss=0.8219, Accuracy=71.50%\n",
      "Epoch 31/50: Loss=0.8353, Accuracy=71.06%\n",
      "Epoch 32/50: Loss=0.8406, Accuracy=70.78%\n",
      "Epoch 33/50: Loss=0.8447, Accuracy=71.01%\n",
      "Epoch 34/50: Loss=0.8858, Accuracy=69.39%\n",
      "Epoch 35/50: Loss=0.8922, Accuracy=69.14%\n",
      "Epoch 36/50: Loss=0.8901, Accuracy=69.15%\n",
      "Epoch 37/50: Loss=0.8982, Accuracy=68.85%\n",
      "Epoch 38/50: Loss=0.9320, Accuracy=67.87%\n",
      "Epoch 39/50: Loss=0.9501, Accuracy=67.43%\n",
      "Epoch 40/50: Loss=0.9214, Accuracy=68.09%\n",
      "Epoch 41/50: Loss=0.9657, Accuracy=66.49%\n",
      "Epoch 42/50: Loss=1.0036, Accuracy=65.34%\n",
      "Epoch 43/50: Loss=1.1095, Accuracy=61.36%\n",
      "Epoch 44/50: Loss=1.0304, Accuracy=64.18%\n",
      "Epoch 45/50: Loss=1.0052, Accuracy=65.13%\n",
      "Epoch 46/50: Loss=1.0153, Accuracy=64.64%\n",
      "Epoch 47/50: Loss=1.0694, Accuracy=63.06%\n",
      "Epoch 48/50: Loss=1.0667, Accuracy=62.99%\n",
      "Epoch 49/50: Loss=1.0831, Accuracy=62.41%\n",
      "Epoch 50/50: Loss=1.1073, Accuracy=61.28%\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
