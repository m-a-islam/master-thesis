{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "377de838",
   "metadata": {},
   "source": [
    "## import necessary libraries for pruning"
   ]
  },
  {
   "cell_type": "code",
   "id": "7b6381473b81b890",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T15:55:40.306170Z",
     "start_time": "2025-05-22T15:55:38.784806Z"
    }
   },
   "source": [
    "import torch, copy\n",
    "import torch.nn as nn\n",
    "import torch_pruning as tp\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "from torch_pruning.pruner.algorithms.scheduler import linear_scheduler\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "#from cnn.resNet.resnet_example import get_data_loaders\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T15:55:40.329047Z",
     "start_time": "2025-05-22T15:55:40.321690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_data_loaders(data_dir, batch_size=64, val_split=0.1, augment_train=True, seed=42):\n",
    "    \"\"\"\n",
    "    Loads CIFAR-10 data. Assumes data is pre-downloaded in data_dir.\n",
    "    Creates train, validation, and test loaders.\n",
    "    Applies augmentation to the training set if augment_train is True.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): Path to the directory containing CIFAR-10 data\n",
    "                        (e.g., './data' which might contain 'cifar-10-batches-py').\n",
    "        batch_size (int): Batch size for DataLoaders.\n",
    "        val_split (float): Proportion of training data to use for validation.\n",
    "        augment_train (bool): Whether to apply data augmentation to the training set.\n",
    "        seed (int): Random seed for reproducible train/validation split.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_loader, val_loader, test_loader)\n",
    "    \"\"\"\n",
    "    abs_data_dir = os.path.abspath(data_dir)\n",
    "    print(f\"Attempting to load CIFAR-10 from directory: {abs_data_dir}\")\n",
    "\n",
    "    cifar_mean = (0.4914, 0.4822, 0.4465)\n",
    "    cifar_std = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "    if augment_train:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(cifar_mean, cifar_std)\n",
    "        ])\n",
    "    else:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(cifar_mean, cifar_std)\n",
    "        ])\n",
    "\n",
    "    val_test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(cifar_mean, cifar_std)\n",
    "    ])\n",
    "\n",
    "    # Load the full training dataset initially with the basic validation transform\n",
    "    # This is just to get the indices for splitting.\n",
    "    try:\n",
    "        # Attempt to load using the data_dir as the root.\n",
    "        # torchvision will look for 'cifar-10-batches-py' within this root.\n",
    "        full_train_dataset_for_indices = torchvision.datasets.CIFAR10(\n",
    "            root=abs_data_dir,\n",
    "            train=True,\n",
    "            download=False, # IMPORTANT: Set to False as data is pre-downloaded\n",
    "            transform=val_test_transform # Basic transform for consistent indexing\n",
    "        )\n",
    "        print(f\"Successfully indexed {len(full_train_dataset_for_indices)} training images for splitting from {abs_data_dir}.\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error loading CIFAR10 training data from {abs_data_dir}: {e}\")\n",
    "        print(\"Please ensure the CIFAR-10 Python version ('cifar-10-batches-py' folder with batch files) is correctly placed in the specified data_dir.\")\n",
    "        print(\"If './data' IS the 'cifar-10-batches-py' folder, you might need to set root='.' relative to the script, or ensure data_dir correctly points to its parent.\")\n",
    "        raise # Re-raise the error to stop execution if data isn't found\n",
    "\n",
    "    val_size = int(len(full_train_dataset_for_indices) * val_split)\n",
    "    train_size = len(full_train_dataset_for_indices) - val_size\n",
    "\n",
    "    generator = torch.Generator().manual_seed(seed)\n",
    "    train_indices, val_indices = torch.utils.data.random_split(\n",
    "        range(len(full_train_dataset_for_indices)), [train_size, val_size], generator=generator\n",
    "    ) # Get indices\n",
    "\n",
    "    # Now, create the actual datasets with appropriate transforms using these indices\n",
    "    # Training dataset with training transforms\n",
    "    train_dataset_with_transforms = torchvision.datasets.CIFAR10(\n",
    "        root=abs_data_dir, train=True, download=False, transform=train_transform\n",
    "    )\n",
    "    train_dataset = Subset(train_dataset_with_transforms, train_indices.indices)\n",
    "\n",
    "    # Validation dataset with validation transforms\n",
    "    val_dataset_with_transforms = torchvision.datasets.CIFAR10(\n",
    "        root=abs_data_dir, train=True, download=False, transform=val_test_transform # Note: still train=True to access same base data\n",
    "    )\n",
    "    val_dataset = Subset(val_dataset_with_transforms, val_indices.indices)\n",
    "\n",
    "    # Test dataset\n",
    "    try:\n",
    "        test_dataset = torchvision.datasets.CIFAR10(\n",
    "            root=abs_data_dir,\n",
    "            train=False,\n",
    "            download=False, # IMPORTANT\n",
    "            transform=val_test_transform\n",
    "        )\n",
    "        print(f\"Successfully loaded {len(test_dataset)} test images from {abs_data_dir}.\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error loading CIFAR10 test data from {abs_data_dir}: {e}\")\n",
    "        raise\n",
    "\n",
    "    # DataLoader parameters\n",
    "    current_device_type = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\").type\n",
    "    pin_memory_flag = True if current_device_type == 'cuda' else False\n",
    "    num_avail_cpus = len(os.sched_getaffinity(0)) if hasattr(os, 'sched_getaffinity') else os.cpu_count()\n",
    "    num_workers_val = min(num_avail_cpus, 4) if num_avail_cpus is not None and num_avail_cpus > 0 else 0 # num_workers=0 means main process\n",
    "    if num_workers_val > 0:\n",
    "        print(f\"Using {num_workers_val} workers for DataLoaders.\")\n",
    "    else:\n",
    "        print(f\"Using main process (0 workers) for DataLoaders (num_avail_cpus: {num_avail_cpus}).\")\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers_val, pin_memory=pin_memory_flag)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers_val, pin_memory=pin_memory_flag)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers_val, pin_memory=pin_memory_flag)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ],
   "id": "4880f51785d855db",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "631981174f5d8d8a",
   "metadata": {},
   "source": [
    "### Seed Network"
   ]
  },
  {
   "cell_type": "code",
   "id": "248e7c99c6815764",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T15:55:45.168761Z",
     "start_time": "2025-05-22T15:55:45.161661Z"
    }
   },
   "source": [
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, expansion=6):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.use_res_connect = self.stride == 1 and in_channels == out_channels\n",
    "\n",
    "        # Standard PyTorch layers (NO torch_pruning wrappers needed)\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels * expansion, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels * expansion)\n",
    "        self.relu = nn.ReLU6(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels * expansion, in_channels * expansion, kernel_size=3,\n",
    "            stride=stride, padding=1, groups=in_channels * expansion, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels * expansion)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels * expansion, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x if self.use_res_connect else None\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.use_res_connect:\n",
    "            return identity + out\n",
    "        else:\n",
    "            return out"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "6431a8ad17e1d446",
   "metadata": {},
   "source": [
    "### Mask Network"
   ]
  },
  {
   "cell_type": "code",
   "id": "4da304cf4cf9f871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T15:55:51.014688Z",
     "start_time": "2025-05-22T15:55:51.007396Z"
    }
   },
   "source": [
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        # --- Remove mask-related parameters ---\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU6(inplace=True)\n",
    "\n",
    "        # Define blocks (no mask_index or mask)\n",
    "        self.block1 = InvertedResidual(32, 16, stride=1)\n",
    "        self.block2 = InvertedResidual(16, 24, stride=2)\n",
    "        self.block3 = InvertedResidual(24, 32, stride=2)\n",
    "        self.block4 = InvertedResidual(32, 64, stride=2)\n",
    "        self.block5 = InvertedResidual(64, 96, stride=1)\n",
    "        self.block6 = InvertedResidual(96, 160, stride=2)\n",
    "        self.block7 = InvertedResidual(160, 320, stride=1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(1280)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(1280, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # --- Remove mask-based block skipping ---\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "        x = self.block7(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "4ad82bf3520f8612",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T17:44:04.386526Z",
     "start_time": "2025-05-20T17:44:04.340131Z"
    }
   },
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "7ebb1e087d2f0cd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T15:55:53.611136Z",
     "start_time": "2025-05-22T15:55:53.605988Z"
    }
   },
   "source": [
    "def save_model_as_onnx(model, example_input, output_path):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    # Export to ONNX\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        example_input,\n",
    "        output_path,\n",
    "        export_params=True,\n",
    "        opset_version=13,\n",
    "        input_names=['input'],\n",
    "        output_names=['output'],\n",
    "        dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    "    )\n",
    "    print(f\"✅ Model saved as ONNX to {output_path}\")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "3e9a817a37b770da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T15:55:56.001237Z",
     "start_time": "2025-05-22T15:55:55.997310Z"
    }
   },
   "source": [
    "def calculate_macs(model, example_input):\n",
    "    macs, params = tp.utils.count_ops_and_params(model, example_input)\n",
    "    return macs, params"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "5b29391c83349f69",
   "metadata": {},
   "source": [
    "### compare results of different pruning strategies"
   ]
  },
  {
   "cell_type": "code",
   "id": "becad7e59744f0dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T15:55:57.422310Z",
     "start_time": "2025-05-22T15:55:57.417723Z"
    }
   },
   "source": [
    "def compare_results(results):\n",
    "    print(\"\\n=== Pruning Strategy Comparison ===\")\n",
    "    print(f\"{'Strategy':<12} | {'MACs':<12} | {'Size (MB)':<10} | {'Accuracy (%)':<12}\")\n",
    "    print(\"-\" * 55)\n",
    "    for strategy, metrics in results.items():\n",
    "        print(f\"{strategy:<12} | {metrics['macs']:.2e} | {metrics['size_mb']:>9.2f} | {metrics['accuracy']:>12.2f}\")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "df0e1911de55ade6",
   "metadata": {},
   "source": [
    "### compare and plot results"
   ]
  },
  {
   "cell_type": "code",
   "id": "5feb4387794b8311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T15:55:59.324343Z",
     "start_time": "2025-05-22T15:55:59.313624Z"
    }
   },
   "source": [
    "def compare_results_and_plot(results_dict, strategies_config, output_dir='output'):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    metrics_data = results_dict\n",
    "\n",
    "    print(\"\\n=== Pruning Strategy Comparison ===\")\n",
    "    header = f\"{'Strategy':<35} | {'MACs':<12} | {'Params':<12} | {'Size (MiB)':<10} | {'Accuracy (%)':<12}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "\n",
    "    if 'initial' in metrics_data:\n",
    "        strat_name = 'initial'\n",
    "        metrics = metrics_data[strat_name]\n",
    "        print(f\"{strat_name:<35} | {metrics['macs']:.2e} | {metrics['params']:.2e} | {metrics['size_mib']:>9.2f} | {metrics['accuracy']:>12.2f}\")\n",
    "\n",
    "    sorted_strategy_keys = sorted(strategies_config.keys())\n",
    "\n",
    "    for strategy_key_orig in sorted_strategy_keys:\n",
    "        strat_name_pruned = f\"{strategy_key_orig}_pruned_not_finetuned\"\n",
    "        if strat_name_pruned in metrics_data:\n",
    "            metrics = metrics_data[strat_name_pruned]\n",
    "            print(f\"{strat_name_pruned:<35} | {metrics['macs']:.2e} | {metrics['params']:.2e} | {metrics['size_mib']:>9.2f} | {metrics['accuracy']:>12.2f}\")\n",
    "\n",
    "        strat_name_final = strategy_key_orig\n",
    "        if strat_name_final in metrics_data:\n",
    "            metrics = metrics_data[strat_name_final]\n",
    "            print(f\"{strat_name_final:<35} | {metrics['macs']:.2e} | {metrics['params']:.2e} | {metrics['size_mib']:>9.2f} | {metrics['accuracy']:>12.2f}\")\n",
    "\n",
    "    plot_strategies_final_names = ['initial'] + sorted_strategy_keys\n",
    "\n",
    "    metric_keys_to_plot = ['macs', 'params', 'size_mib', 'accuracy']\n",
    "    titles = {\n",
    "        'macs': 'MACs Comparison (Final Models)',\n",
    "        'params': 'Parameters Comparison (Final Models)',\n",
    "        'size_mib': 'Model Size (MiB) Comparison (Final Models)',\n",
    "        'accuracy': 'Accuracy (%) Comparison (Final Models)'\n",
    "    }\n",
    "    y_labels = {\n",
    "        'macs': 'MACs',\n",
    "        'params': 'Parameters',\n",
    "        'size_mib': 'Size (MiB)',\n",
    "        'accuracy': 'Accuracy (%)'\n",
    "    }\n",
    "\n",
    "    num_strategies_for_plot = len(plot_strategies_final_names)\n",
    "\n",
    "    # Fix for MatplotlibDeprecationWarning and color generation\n",
    "    colors_cmap = plt.colormaps.get_cmap('tab10') # Get the colormap object\n",
    "\n",
    "    for metric_key in metric_keys_to_plot:\n",
    "        values = []\n",
    "        valid_strategies_for_plot = []\n",
    "        for strategy_name_for_plot in plot_strategies_final_names:\n",
    "            if strategy_name_for_plot in metrics_data:\n",
    "                actual_key_in_results = strategy_name_for_plot\n",
    "                if actual_key_in_results in metrics_data and metric_key in metrics_data[actual_key_in_results]:\n",
    "                    values.append(metrics_data[actual_key_in_results][metric_key])\n",
    "                    valid_strategies_for_plot.append(strategy_name_for_plot)\n",
    "\n",
    "        if not values:\n",
    "            print(f\"Skipping plot for {metric_key} as no data was found.\")\n",
    "            continue\n",
    "\n",
    "        plt.figure(figsize=(max(12, int(1.5 * len(valid_strategies_for_plot))), 7)) # Dynamic width, ensure int\n",
    "\n",
    "        # Generate colors for the valid strategies being plotted\n",
    "        bar_colors = [colors_cmap(i % colors_cmap.N) for i in range(len(valid_strategies_for_plot))]\n",
    "        bars = plt.bar(valid_strategies_for_plot, values, color=bar_colors)\n",
    "\n",
    "        plt.xlabel('Strategy')\n",
    "        plt.ylabel(y_labels[metric_key])\n",
    "        plt.title(titles[metric_key])\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "        for bar in bars:\n",
    "            yval = bar.get_height()\n",
    "            if metric_key in ['macs', 'params']:\n",
    "                 plt.text(bar.get_x() + bar.get_width()/2., yval, f'{yval:.2e}', ha='center', va='bottom')\n",
    "            else:\n",
    "                 plt.text(bar.get_x() + bar.get_width()/2., yval, f'{yval:.2f}', ha='center', va='bottom')\n",
    "\n",
    "        if 'initial' in metrics_data and metric_key in metrics_data['initial']:\n",
    "            initial_value = metrics_data['initial'][metric_key]\n",
    "            # Fix for ValueError: Invalid format specifier\n",
    "            if metric_key in [\"macs\", \"params\"]:\n",
    "                label_text = f'Initial ({initial_value:.2e})'\n",
    "            else:\n",
    "                label_text = f'Initial ({initial_value:.2f})'\n",
    "            plt.axhline(y=initial_value, color='r', linestyle='--', label=label_text)\n",
    "\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f'{metric_key}_comparison_final.png'))\n",
    "        plt.close()\n",
    "    print(f\"✅ Comparison plots saved to {output_dir}\")"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T15:56:14.919520Z",
     "start_time": "2025-05-22T15:56:14.907523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def plot_initial_model_training_summary(training_history, model_name_for_plot, output_dir_plots):\n",
    "    \"\"\"\n",
    "    Plots training/validation loss vs. epochs, and loss vs. accuracy curves\n",
    "    for the initial model's training phase.\n",
    "\n",
    "    Args:\n",
    "        training_history (dict): The history object returned by train_model.\n",
    "                                 Expected keys: 'train_loss', 'train_acc',\n",
    "                                                'val_loss', 'val_acc'.\n",
    "        model_name_for_plot (str): A name for the model to include in plot titles.\n",
    "        output_dir_plots (str): Directory to save the plots.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir_plots, exist_ok=True)\n",
    "\n",
    "    epochs_ran = len(training_history['train_loss'])\n",
    "    if epochs_ran == 0:\n",
    "        print(f\"No training history found for {model_name_for_plot}. Skipping summary plots.\")\n",
    "        return\n",
    "\n",
    "    epochs_axis = range(1, epochs_ran + 1)\n",
    "\n",
    "    # Plot 1: Loss vs. Epochs\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs_axis, training_history['train_loss'], 'bo-', label='Training Loss')\n",
    "    if training_history.get('val_loss') and any(v is not None for v in training_history['val_loss']):\n",
    "        # Ensure val_loss has same length due to how history is populated if no val_loader sometimes\n",
    "        valid_val_loss_epochs = [epoch for epoch, loss in zip(epochs_axis, training_history['val_loss']) if loss is not None]\n",
    "        valid_val_loss_values = [loss for loss in training_history['val_loss'] if loss is not None]\n",
    "        if valid_val_loss_values:\n",
    "            plt.plot(valid_val_loss_epochs, valid_val_loss_values, 'ro-', label='Validation Loss')\n",
    "\n",
    "    plt.title(f'{model_name_for_plot}: Training & Validation Loss vs. Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(output_dir_plots, f'{model_name_for_plot}_loss_vs_epochs.png'))\n",
    "    plt.close()\n",
    "    print(f\"✅ {model_name_for_plot} Loss vs. Epochs plot saved to {output_dir_plots}\")\n",
    "\n",
    "    # Plot 2: Loss vs. Accuracy\n",
    "    # We'll plot Training Loss vs. Training Accuracy on one subplot\n",
    "    # And Validation Loss vs. Validation Accuracy on another, if validation data exists\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2 if (training_history.get('val_loss') and any(v is not None for v in training_history['val_loss'])) else 1, figsize=(12, 5), squeeze=False)\n",
    "\n",
    "    # Training Loss vs. Training Accuracy\n",
    "    ax1 = axs[0, 0]\n",
    "    ax1.plot(training_history['train_acc'], training_history['train_loss'], 'bo-', label='Train Loss vs. Train Acc')\n",
    "    # Annotate start and end points for clarity\n",
    "    if epochs_ran > 0:\n",
    "        ax1.scatter(training_history['train_acc'][0], training_history['train_loss'][0], color='green', s=50, zorder=5, label='Start Train')\n",
    "        ax1.scatter(training_history['train_acc'][-1], training_history['train_loss'][-1], color='red', s=50, zorder=5, label='End Train')\n",
    "        # Add arrows to show direction if more than 1 point\n",
    "        if epochs_ran > 1:\n",
    "            for i in range(epochs_ran - 1):\n",
    "                ax1.annotate(\"\", xy=(training_history['train_acc'][i+1], training_history['train_loss'][i+1]),\n",
    "                             xytext=(training_history['train_acc'][i], training_history['train_loss'][i]),\n",
    "                             arrowprops=dict(arrowstyle=\"->\", color=\"blue\", alpha=0.5))\n",
    "    ax1.set_title(f'{model_name_for_plot}: Training Loss vs. Accuracy')\n",
    "    ax1.set_xlabel('Training Accuracy (%)')\n",
    "    ax1.set_ylabel('Training Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Validation Loss vs. Validation Accuracy (if validation data is available)\n",
    "    if training_history.get('val_loss') and any(v is not None for v in training_history['val_loss']) and axs.shape[1] > 1:\n",
    "        ax2 = axs[0, 1]\n",
    "        # Filter out None values from val_loss and corresponding val_acc\n",
    "        valid_val_epochs_indices = [i for i, (loss, acc) in enumerate(zip(training_history['val_loss'], training_history['val_acc'])) if loss is not None and acc is not None]\n",
    "\n",
    "        if valid_val_epochs_indices:\n",
    "            val_acc_plot = [training_history['val_acc'][i] for i in valid_val_epochs_indices]\n",
    "            val_loss_plot = [training_history['val_loss'][i] for i in valid_val_epochs_indices]\n",
    "\n",
    "            ax2.plot(val_acc_plot, val_loss_plot, 'ro-', label='Val Loss vs. Val Acc')\n",
    "            if len(val_acc_plot) > 0:\n",
    "                ax2.scatter(val_acc_plot[0], val_loss_plot[0], color='lime', s=50, zorder=5, label='Start Val')\n",
    "                ax2.scatter(val_acc_plot[-1], val_loss_plot[-1], color='darkred', s=50, zorder=5, label='End Val')\n",
    "                if len(val_acc_plot) > 1:\n",
    "                    for i in range(len(val_acc_plot) - 1):\n",
    "                         ax2.annotate(\"\", xy=(val_acc_plot[i+1], val_loss_plot[i+1]),\n",
    "                                      xytext=(val_acc_plot[i], val_loss_plot[i]),\n",
    "                                      arrowprops=dict(arrowstyle=\"->\", color=\"red\", alpha=0.5))\n",
    "            ax2.set_title(f'{model_name_for_plot}: Validation Loss vs. Accuracy')\n",
    "            ax2.set_xlabel('Validation Accuracy (%)')\n",
    "            ax2.set_ylabel('Validation Loss')\n",
    "            ax2.legend()\n",
    "            ax2.grid(True)\n",
    "        else: # If somehow val_loss had entries but all were None for val_acc or vice-versa\n",
    "            ax2.set_title(f'{model_name_for_plot}: No complete validation data')\n",
    "            ax2.text(0.5, 0.5, 'No valid data for validation plot', ha='center', va='center')\n",
    "\n",
    "\n",
    "    fig.suptitle(f'{model_name_for_plot}: Loss vs. Accuracy Dynamics', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust for suptitle\n",
    "    plt.savefig(os.path.join(output_dir_plots, f'{model_name_for_plot}_loss_vs_accuracy.png'))\n",
    "    plt.close()\n",
    "    print(f\"✅ {model_name_for_plot} Loss vs. Accuracy plot saved to {output_dir_plots}\")"
   ],
   "id": "4b52ac74f62c1ee4",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "23869493d2f36a72",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "615130e04992f7ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T15:56:21.875829Z",
     "start_time": "2025-05-22T15:56:21.871908Z"
    }
   },
   "source": [
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "bbd2e296738ea559",
   "metadata": {},
   "source": [
    "### Utility function to save the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "b7f8aa766a2fa06a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T15:56:23.908543Z",
     "start_time": "2025-05-22T15:56:23.904105Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "def save_model(model, path, example_input=None):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    torch.save(model.state_dict(), path)\n",
    "    if example_input is not None:\n",
    "        onnx_path = path.replace('.pth', '.onnx')\n",
    "        save_model_as_onnx(model, example_input, onnx_path)\n",
    "\n",
    "def load_model_state(model_class, path, device, *args, **kwargs):\n",
    "    # *args, **kwargs are for model_class constructor (e.g. num_classes)\n",
    "    model = model_class(*args, **kwargs)\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    model.to(device)\n",
    "    print(f\"✅ Model loaded from {path} to {device}\")\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "89740bc4e512ecde",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "5484dc87c1b63c28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T15:56:25.920627Z",
     "start_time": "2025-05-22T15:56:25.915082Z"
    }
   },
   "source": [
    "def evaluate_model(model, test_loader, example_input_device, criterion_eval, device_eval):\n",
    "    model.eval()\n",
    "    model.to(device_eval)\n",
    "    macs, num_params = calculate_macs(model, example_input_device)\n",
    "    size_mib = num_params * 4 / (1024 * 1024)\n",
    "    correct = 0; total = 0; running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = [d.to(device_eval) for d in data]\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion_eval(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    avg_loss = running_loss / total if total > 0 else float('nan')\n",
    "    accuracy = 100 * correct / total if total > 0 else 0\n",
    "    return {'macs': macs, 'params': num_params, 'size_mib': size_mib, 'accuracy': accuracy, 'loss': avg_loss}\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "78f7147c66b6d346",
   "metadata": {},
   "source": [
    "### Prune the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "6532a7494fc3fcbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T15:56:27.838566Z",
     "start_time": "2025-05-22T15:56:27.832617Z"
    }
   },
   "source": [
    "def prune_model(model, example_input, target_macs, strategy, iterative_steps=5):\n",
    "    #, iterative_pruning_ratio_scheduler=linear_scheduler()):\n",
    "    if isinstance(strategy['importance'], tp.importance.TaylorImportance):\n",
    "        pruning_ratio = 0.1\n",
    "    else:\n",
    "        pruning_ratio = 0.5\n",
    "\n",
    "    pruner = strategy['pruner'](\n",
    "        model,\n",
    "        example_input,\n",
    "        importance=strategy['importance'],\n",
    "        iterative_steps=iterative_steps,\n",
    "        ch_sparsity=pruning_ratio,  # Initial sparsity\n",
    "        #iterative_pruning_ratio_scheduler=iterative_pruning_ratio_scheduler,\n",
    "        root_module_types=[nn.Conv2d],\n",
    "        ignored_layers=[model.fc],\n",
    "    )\n",
    "\n",
    "    current_macs, base_nparams = calculate_macs(model, example_input)\n",
    "    # while current_macs > target_macs:\n",
    "    #     pruner.step()\n",
    "    #     current_macs = calculate_macs(model, example_input)\n",
    "\n",
    "\n",
    "    for i in range(iterative_steps):\n",
    "            if isinstance(strategy['importance'], tp.importance.TaylorImportance):\n",
    "                loss = model(example_input).sum() # a dummy loss for TaylorImportance\n",
    "                loss.backward()\n",
    "            for g in pruner.step(interactive=True):\n",
    "                g.prune()\n",
    "            macs, nparams = tp.utils.count_ops_and_params(model, example_input)\n",
    "            #print(model(example_input).shape)\n",
    "            print(\n",
    "                \"  Iter %d/%d, Params: %.2f M => %.2f M\"\n",
    "                % (i + 1, iterative_steps, base_nparams / 1e6, nparams / 1e6)\n",
    "            )\n",
    "            print(\n",
    "                \"  Iter %d/%d, MACs: %.2f G => %.2f G\"\n",
    "                % (i + 1, iterative_steps, current_macs / 1e9, macs / 1e9)\n",
    "            )\n",
    "\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "6adb22651c74e5f0",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "a6e1edc8a36e5260",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T15:56:30.326210Z",
     "start_time": "2025-05-22T15:56:30.311992Z"
    }
   },
   "source": [
    "def train_model(model, train_loader, criterion,optimizer, device, num_epochs,\n",
    "                val_loader=None, strategy_name=\"\",\n",
    "                early_stopping_patience=None,\n",
    "                early_stopping_metric='val_loss',\n",
    "                load_best_model_on_stop=True\n",
    "                ):\n",
    "\n",
    "    model.to(device)\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "    # Early stopping specific variables\n",
    "    best_metric_score = float('inf') if early_stopping_metric == 'val_loss' else float('-inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state_dict = None # To store the state_dict of the best model\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs, labels = [d.to(device) for d in data]\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader) if len(train_loader) > 0 else 0\n",
    "        epoch_acc = 100 * correct_train / total_train if total_train > 0 else 0\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['train_acc'].append(epoch_acc)\n",
    "\n",
    "        log_msg = f\"Strategy: {strategy_name} - Epoch {epoch+1}/{num_epochs}: Train Loss={epoch_loss:.4f}, Train Acc={epoch_acc:.2f}%\"\n",
    "\n",
    "        current_val_metric = None # To store the metric value for the current epoch\n",
    "        if val_loader:\n",
    "            model.eval()\n",
    "            running_val_loss = 0.0\n",
    "            correct_val = 0\n",
    "            total_val = 0\n",
    "            with torch.no_grad():\n",
    "                for data_val in val_loader:\n",
    "                    inputs_val, labels_val = [d.to(device) for d in data_val]\n",
    "                    outputs_val = model(inputs_val)\n",
    "                    val_loss_item = criterion(outputs_val, labels_val)\n",
    "                    running_val_loss += val_loss_item.item()\n",
    "                    _, predicted_val = torch.max(outputs_val.data, 1)\n",
    "                    total_val += labels_val.size(0)\n",
    "                    correct_val += (predicted_val == labels_val).sum().item()\n",
    "\n",
    "            epoch_val_loss = running_val_loss / len(val_loader) if len(val_loader) > 0 else 0\n",
    "            epoch_val_acc = 100 * correct_val / total_val if total_val > 0 else 0\n",
    "            history['val_loss'].append(epoch_val_loss)\n",
    "            history['val_acc'].append(epoch_val_acc)\n",
    "            log_msg += f\", Val Loss={epoch_val_loss:.4f}, Val Acc={epoch_val_acc:.2f}%\"\n",
    "\n",
    "            # Early stopping logic\n",
    "            if early_stopping_patience is not None:\n",
    "                if early_stopping_metric == 'val_loss':\n",
    "                    current_val_metric = epoch_val_loss\n",
    "                    if current_val_metric < best_metric_score:\n",
    "                        best_metric_score = current_val_metric\n",
    "                        epochs_no_improve = 0\n",
    "                        if load_best_model_on_stop:\n",
    "                            best_model_state_dict = copy.deepcopy(model.state_dict())\n",
    "                        log_msg += \" (New best val_loss)\"\n",
    "                    else:\n",
    "                        epochs_no_improve += 1\n",
    "                elif early_stopping_metric == 'val_acc':\n",
    "                    current_val_metric = epoch_val_acc\n",
    "                    if current_val_metric > best_metric_score:\n",
    "                        best_metric_score = current_val_metric\n",
    "                        epochs_no_improve = 0\n",
    "                        if load_best_model_on_stop:\n",
    "                            best_model_state_dict = copy.deepcopy(model.state_dict())\n",
    "                        log_msg += \" (New best val_acc)\"\n",
    "                    else:\n",
    "                        epochs_no_improve += 1\n",
    "                else:\n",
    "                    # This case should ideally not be hit if parameters are validated upstream\n",
    "                    # or have defaults, but good for robustness.\n",
    "                    print(f\"Warning: Unsupported early_stopping_metric: {early_stopping_metric}. Defaulting to 'val_loss'.\")\n",
    "                    early_stopping_metric = 'val_loss' # Fallback\n",
    "                    # Re-evaluate for the current epoch with the fallback metric (could be complex, simpler to just warn and continue)\n",
    "\n",
    "        else: # No validation loader\n",
    "            history['val_loss'].append(None)\n",
    "            history['val_acc'].append(None)\n",
    "            if early_stopping_patience is not None: # Only warn if ES was intended\n",
    "                print(f\"Warning: Early stopping for '{strategy_name}' configured (patience: {early_stopping_patience}), but no validation loader provided. Early stopping will be inactive.\")\n",
    "\n",
    "        print(log_msg)\n",
    "\n",
    "        # Check for early stopping condition\n",
    "        if early_stopping_patience is not None and val_loader and epochs_no_improve >= early_stopping_patience:\n",
    "            print(f\"Early stopping triggered for '{strategy_name}' after {epoch+1} epochs. No improvement in '{early_stopping_metric}' for {early_stopping_patience} epochs.\")\n",
    "            if load_best_model_on_stop and best_model_state_dict is not None:\n",
    "                print(f\"Loading best model weights from epoch {epoch + 1 - epochs_no_improve} with {early_stopping_metric}: {best_metric_score:.4f}\")\n",
    "                model.load_state_dict(best_model_state_dict)\n",
    "            break # Stop training loop\n",
    "\n",
    "    # After the loop, if training completed fully (not early stopped) OR early stopped but we want the best model\n",
    "    if load_best_model_on_stop and best_model_state_dict is not None:\n",
    "        # This check ensures we load the best model if the last epoch wasn't the best one,\n",
    "        # even if early stopping didn't trigger (e.g., training ran for all num_epochs)\n",
    "        # Or if it did trigger, this ensures the best model is loaded.\n",
    "        # Need to get the last recorded validation metric if val_loader was present\n",
    "        last_recorded_val_metric = None\n",
    "        if val_loader and history[early_stopping_metric]: # Check if history has entries for the metric\n",
    "             # Get the last non-None value for the metric\n",
    "            valid_metrics = [m for m in history[early_stopping_metric] if m is not None]\n",
    "            if valid_metrics:\n",
    "                last_recorded_val_metric = valid_metrics[-1]\n",
    "\n",
    "        should_load_best = True # Default to loading if we have a best_model_state_dict\n",
    "        if last_recorded_val_metric is not None: # If we have a final metric to compare\n",
    "            if early_stopping_metric == 'val_loss':\n",
    "                if last_recorded_val_metric <= best_metric_score: # Current/last model is as good or better\n",
    "                    should_load_best = False\n",
    "            elif early_stopping_metric == 'val_acc':\n",
    "                if last_recorded_val_metric >= best_metric_score: # Current/last model is as good or better\n",
    "                    should_load_best = False\n",
    "\n",
    "        if should_load_best:\n",
    "            print(f\"Training for '{strategy_name}' finished. Loading best recorded model state with {early_stopping_metric}: {best_metric_score:.4f}\")\n",
    "            model.load_state_dict(best_model_state_dict)\n",
    "\n",
    "    return model, history"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Plotting fine-tuning curves",
   "id": "336281ff4136c31"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T15:56:35.668285Z",
     "start_time": "2025-05-22T15:56:35.652246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "def plot_finetuning_curves(history, plot_title_suffix, output_dir_plots, model_macs_val):\n",
    "    os.makedirs(output_dir_plots, exist_ok=True)\n",
    "    actual_epochs = len(history['train_loss'])\n",
    "    epochs_range = range(1, actual_epochs + 1)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1); plt.plot(epochs_range, history['train_loss'][:actual_epochs], 'bo-', label='Train Loss')\n",
    "    if history.get('val_loss') and any(v is not None for v in history['val_loss']):\n",
    "        plt.plot(epochs_range, history['val_loss'][:actual_epochs], 'ro-', label='Val Loss')\n",
    "    plt.title(f'Loss ({plot_title_suffix})\\nMACs: {model_macs_val:.2e}'); plt.xlabel('Epochs'); plt.ylabel('Loss'); plt.legend(); plt.grid(True)\n",
    "    plt.subplot(1, 2, 2); plt.plot(epochs_range, history['train_acc'][:actual_epochs], 'bo-', label='Train Acc')\n",
    "    if history.get('val_acc') and any(v is not None for v in history['val_acc']):\n",
    "        plt.plot(epochs_range, history['val_acc'][:actual_epochs], 'ro-', label='Val Acc')\n",
    "    plt.title(f'Accuracy ({plot_title_suffix})\\nMACs: {model_macs_val:.2e}'); plt.xlabel('Epochs'); plt.ylabel('Acc %'); plt.legend(); plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    safe_suffix = plot_title_suffix.replace(' ', '_').replace('/', '_').replace(':', '_')\n",
    "    plt.savefig(os.path.join(output_dir_plots, f'finetune_curves_{safe_suffix}.png')); plt.close()\n",
    "    print(f\"✅ Fine-tuning curves for {plot_title_suffix} saved.\")\n",
    "\n",
    "\n",
    "def plot_metrics_vs_ratio_all_strategies(results_data_plot, ratios_tested_plot, output_dir_main_plots):\n",
    "    os.makedirs(output_dir_main_plots, exist_ok=True)\n",
    "\n",
    "    strategies_plot = list(results_data_plot.keys())\n",
    "    if not strategies_plot:\n",
    "        print(\"No strategies found in results_data for plotting ratio effects.\")\n",
    "        return\n",
    "\n",
    "    ratios_str_plot = [f\"{r:.1f}\" for r in ratios_tested_plot] # X-axis labels (e.g., \"0.0\", \"0.2\")\n",
    "    num_ratios_plot = len(ratios_tested_plot)\n",
    "    num_strategies_plot = len(strategies_plot)\n",
    "\n",
    "    # Determine bar width and indices for grouped bars\n",
    "    # Total width for a group of bars at one ratio tick will be slightly less than 1 (e.g., 0.8)\n",
    "    # Individual bar width = total_group_width / num_strategies\n",
    "    total_group_width = 0.8\n",
    "    bar_width_plot = total_group_width / num_strategies_plot\n",
    "    index_plot = np.arange(num_ratios_plot) # The x locations for the groups of bars\n",
    "\n",
    "    colors_map_plot = plt.colormaps.get_cmap('tab10') # Or any other colormap like 'viridis', 'plasma'\n",
    "\n",
    "    # --- Plot 1: MACs vs. Pruning Ratio (Grouped by Strategy) ---\n",
    "    plt.figure(figsize=(max(12, int(1.8 * num_ratios_plot)), 7)) # Dynamic width\n",
    "    for i, s_name in enumerate(strategies_plot):\n",
    "        macs_vals = [results_data_plot[s_name].get(r_val, {}).get('macs', np.nan) for r_val in ratios_tested_plot]\n",
    "        # Calculate position for each bar in the group\n",
    "        bar_positions = index_plot - (total_group_width / 2) + (i * bar_width_plot) + (bar_width_plot / 2)\n",
    "        plt.bar(bar_positions, macs_vals, bar_width_plot, label=s_name, color=colors_map_plot(i % colors_map_plot.N))\n",
    "\n",
    "    plt.xlabel('Pruning Ratio (ch_sparsity)')\n",
    "    plt.ylabel('MACs (Log Scale)')\n",
    "    plt.title('MACs vs. Pruning Ratio (Fine-tuned Models)')\n",
    "    plt.xticks(index_plot, ratios_str_plot) # Center ticks for each group\n",
    "    plt.yscale('log')\n",
    "    plt.legend(title=\"Strategy\", bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "    plt.grid(True, which=\"both\", ls=\"-\", alpha=0.3)\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1]) # Adjust layout to make space for legend\n",
    "    plt.savefig(os.path.join(output_dir_main_plots, 'MACs_vs_Ratio_by_Strategy.png'))\n",
    "    plt.close()\n",
    "    print(f\"✅ MACs vs. Ratio by Strategy plot saved to {output_dir_main_plots}\")\n",
    "\n",
    "\n",
    "    # --- Plot 2: Loss vs. Pruning Ratio (Grouped by Strategy) ---\n",
    "    plt.figure(figsize=(max(12, int(1.8 * num_ratios_plot)), 7))\n",
    "    for i, s_name in enumerate(strategies_plot):\n",
    "        loss_vals = [results_data_plot[s_name].get(r_val, {}).get('loss', np.nan) for r_val in ratios_tested_plot]\n",
    "        bar_positions = index_plot - (total_group_width / 2) + (i * bar_width_plot) + (bar_width_plot / 2)\n",
    "        plt.bar(bar_positions, loss_vals, bar_width_plot, label=s_name, color=colors_map_plot(i % colors_map_plot.N))\n",
    "\n",
    "    plt.xlabel('Pruning Ratio (ch_sparsity)')\n",
    "    plt.ylabel('Average Test Loss')\n",
    "    plt.title('Avg. Test Loss vs. Pruning Ratio (Fine-tuned Models)')\n",
    "    plt.xticks(index_plot, ratios_str_plot)\n",
    "    plt.legend(title=\"Strategy\", bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "    plt.savefig(os.path.join(output_dir_main_plots, 'Loss_vs_Ratio_by_Strategy.png'))\n",
    "    plt.close()\n",
    "    print(f\"✅ Loss vs. Ratio by Strategy plot saved to {output_dir_main_plots}\")\n",
    "\n",
    "    # --- Plot 3: Accuracy vs. Pruning Ratio (Grouped by Strategy) --- <<<< NEW PLOT\n",
    "    plt.figure(figsize=(max(12, int(1.8 * num_ratios_plot)), 7))\n",
    "    for i, s_name in enumerate(strategies_plot):\n",
    "        accuracy_vals = [results_data_plot[s_name].get(r_val, {}).get('accuracy', np.nan) for r_val in ratios_tested_plot]\n",
    "        bar_positions = index_plot - (total_group_width / 2) + (i * bar_width_plot) + (bar_width_plot / 2)\n",
    "        plt.bar(bar_positions, accuracy_vals, bar_width_plot, label=s_name, color=colors_map_plot(i % colors_map_plot.N))\n",
    "\n",
    "    plt.xlabel('Pruning Ratio (ch_sparsity)')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Accuracy vs. Pruning Ratio (Fine-tuned Models)')\n",
    "    plt.xticks(index_plot, ratios_str_plot)\n",
    "    plt.ylim(0, 100) # Accuracy is typically between 0 and 100\n",
    "    plt.legend(title=\"Strategy\", bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "    plt.savefig(os.path.join(output_dir_main_plots, 'Accuracy_vs_Ratio_by_Strategy.png'))\n",
    "    plt.close()\n",
    "    print(f\"✅ Accuracy vs. Ratio by Strategy plot saved to {output_dir_main_plots}\")"
   ],
   "id": "b4a43f15e22c98b2",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "b26416e6ff76416a",
   "metadata": {},
   "source": [
    "### Main workflow"
   ]
  },
  {
   "cell_type": "code",
   "id": "bdf93b3196076098",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T16:20:04.499028Z",
     "start_time": "2025-05-22T16:20:04.485771Z"
    }
   },
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Configuration\n",
    "    cfg = {\n",
    "        'strategies': {\n",
    "            'magnitude': {\n",
    "                'pruner': tp.pruner.MagnitudePruner,\n",
    "                'importance': tp.importance.MagnitudeImportance(p=2),\n",
    "            },\n",
    "            'bn_scale': {\n",
    "                'pruner': tp.pruner.BNScalePruner,\n",
    "                'importance': tp.importance.BNScaleImportance(),\n",
    "            },\n",
    "            # 'group_norm': {\n",
    "            #     'pruner': tp.pruner.GroupNormPruner,\n",
    "            #     'importance': tp.importance.GroupMagnitudeImportance(p=1),\n",
    "            # },\n",
    "            'random': {\n",
    "                'pruner': tp.pruner.MagnitudePruner,\n",
    "                'importance': tp.importance.RandomImportance(),\n",
    "            },\n",
    "            # 'Taylor': {\n",
    "            #     'pruner': tp.pruner.MagnitudePruner,\n",
    "            #     'importance': tp.importance.TaylorImportance()\n",
    "            # },\n",
    "            # 'Hessian': {\n",
    "            #     'pruner': tp.pruner.MagnitudePruner,\n",
    "            #     'importance': tp.importance.GroupHessianImportance()\n",
    "            # },\n",
    "            # 'lamp': {\n",
    "            #     'pruner': tp.pruner.MagnitudePruner,\n",
    "            #     'importance': tp.importance.LAMPImportance(p=2)\n",
    "            # },\n",
    "            # 'geometry': {\n",
    "            #     'pruner': tp.pruner.MagnitudePruner,\n",
    "            #     'importance': tp.importance.FPGMImportance()\n",
    "            # },\n",
    "            #todo: implement growing reg pruning\n",
    "        },\n",
    "        #todo: different types of schedulers can be added\n",
    "        'pruning_ratios_to_test': [0.0, 0.2, 0.5, 0.7, 0.9], # 0.0 for baseline\n",
    "        'iterative_steps_pruner_general': 5, # For non-Taylor pruners inside gr_prune_model_by_ratio\n",
    "        'iterative_steps_taylor_pruning': 5, # Number of backward passes for Taylor method in gr_prune_model_by_ratio\n",
    "        'val_split_for_loader': 0.1, # Corresponds to your get_data_loaders val_split\n",
    "        #'iterative_pruning_ratio_scheduler': linear_scheduler(),\n",
    "        'initial_train_epochs': 1000,\n",
    "        'fine_tune_epochs': 1000,\n",
    "        'early_stopping_patience': 20,\n",
    "        'early_stopping_metric': 'val_loss', # 'val_loss' or 'val_acc'\n",
    "        'load_best_model_on_early_stop': True,\n",
    "\n",
    "        'augment_training_data': True, # To enable training augmentations\n",
    "        'seed_for_datasplit': 42,\n",
    "        'data_dir': './data',\n",
    "        'output_dir_base': './output_final_ratio_experiment',\n",
    "        'num_classes': 10, 'batch_size': 128,\n",
    "        'learning_rate_initial': 0.001, 'learning_rate_finetune': 0.0001,\n",
    "    }\n",
    "\n",
    "    initial_model_plots_dir = os.path.join(cfg['output_dir_base'], \"initial_model_training_plots\")\n",
    "    os.makedirs(initial_model_plots_dir, exist_ok=True)\n",
    "    #os.makedirs(cfg['output_dir_base'], exist_ok=True)\n",
    "\n",
    "    # --- Updated Data Loader Call ---\n",
    "    print(\"Initializing DataLoaders...\")\n",
    "    # Now get_data_loaders returns train, val, test\n",
    "    train_loader, val_loader, test_loader = get_data_loaders(\n",
    "        data_dir=cfg['data_dir'],\n",
    "        batch_size=cfg['batch_size'],\n",
    "        val_split=cfg['val_split_for_loader'], # Pass the val_split\n",
    "        augment_train=cfg['augment_training_data'], # Pass the new arg\n",
    "        seed=cfg['seed_for_datasplit']\n",
    "    )\n",
    "    print(f\"Train loader: {len(train_loader.dataset)} samples, Val loader: {len(val_loader.dataset)} samples, Test loader: {len(test_loader.dataset)} samples\")\n",
    "    # --- End of Updated Data Loader Call ---\n",
    "\n",
    "    example_input_cpu_onnx = torch.randn(1, 3, 32, 32)\n",
    "    example_input_dev = example_input_cpu_onnx.to(device)\n",
    "\n",
    "    model_base_name = \"MobileNetV2_CIFAR10\"\n",
    "    initial_model_filename_base = f\"{model_base_name}_initial_dense_trained\"\n",
    "    initial_model_trained_path = os.path.join(cfg['output_dir_base'], \"mobilenetv2_initial_dense_trained.pth\")\n",
    "    criterion_train_eval = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    initial_model_training_history = None\n",
    "\n",
    "    if not os.path.exists(initial_model_trained_path):\n",
    "        print(\"--- Training Initial Dense MobileNetV2 ---\")\n",
    "        dense_model_instance = MobileNetV2(num_classes=cfg['num_classes']).to(device)\n",
    "        trained_dense_model, initial_model_training_history = train_model(\n",
    "            model=dense_model_instance,\n",
    "            train_loader=train_loader,\n",
    "            criterion=criterion_train_eval,\n",
    "            optimizer=optim.Adam(dense_model_instance.parameters(), lr=cfg['learning_rate_initial'], weight_decay=1e-4),\n",
    "            device=device,\n",
    "            num_epochs=cfg['initial_train_epochs'],\n",
    "            val_loader=val_loader,\n",
    "            strategy_name=\"InitialDenseModel\",\n",
    "            early_stopping_patience=cfg['early_stopping_patience'],\n",
    "            early_stopping_metric=cfg['early_stopping_metric'],\n",
    "            load_best_model_on_stop=cfg['load_best_model_on_early_stop']\n",
    "        )\n",
    "        save_model(trained_dense_model, initial_model_trained_path, example_input=example_input_cpu_onnx.to(device))\n",
    "        # <<<< PLOT INITIAL MODEL TRAINING SUMMARY IF IT WAS JUST TRAINED >>>>\n",
    "        if initial_model_training_history:\n",
    "            plot_initial_model_training_summary(\n",
    "                initial_model_training_history,\n",
    "                model_name_for_plot=f\"{model_base_name}_InitialDense\",\n",
    "                output_dir_plots=initial_model_plots_dir # Save in its dedicated folder\n",
    "            )\n",
    "    else:\n",
    "        print(f\"--- Using Pre-trained Dense Model from {initial_model_trained_path} ---\")\n",
    "\n",
    "    results_all_ratios_strategies = {s_name: {} for s_name in cfg['strategies'].keys()}\n",
    "\n",
    "    print(\"\\n--- Evaluating Baseline Model (Ratio 0.0) on TEST SET---\")\n",
    "    baseline_model_eval = load_model_state(MobileNetV2, initial_model_trained_path, device, num_classes=cfg['num_classes'])\n",
    "    # Final evaluation of baseline model on the TEST set\n",
    "    baseline_metrics_eval = evaluate_model(baseline_model_eval, test_loader, example_input_dev, criterion_train_eval, device)\n",
    "    print(f\"Baseline Metrics (Ratio 0.0, Evaluated on Test Set): {baseline_metrics_eval}\")\n",
    "    for s_name_key in cfg['strategies'].keys():\n",
    "        results_all_ratios_strategies[s_name_key][0.0] = baseline_metrics_eval # Store test set metrics\n",
    "\n",
    "    for strategy_name_key, strategy_details_dict in cfg['strategies'].items():\n",
    "        strategy_specific_output_dir = os.path.join(cfg['output_dir_base'], strategy_name_key)\n",
    "        os.makedirs(strategy_specific_output_dir, exist_ok=True)\n",
    "\n",
    "        for current_ratio in cfg['pruning_ratios_to_test']:\n",
    "            if current_ratio == 0.0: continue\n",
    "\n",
    "            print(f\"\\n\\n--- Processing: Strategy '{strategy_name_key}', Ratio: {current_ratio:.2f} ---\")\n",
    "            model_for_pruning_current = load_model_state(MobileNetV2, initial_model_trained_path, device, num_classes=cfg['num_classes'])\n",
    "\n",
    "            print(f\"--- Pruning model with {strategy_name_key} to ratio {current_ratio:.2f} ---\")\n",
    "            pruned_model_current = gr_prune_model_by_ratio( # Your adapted pruning function\n",
    "                model_for_pruning_current, example_input_dev, strategy_details_dict, current_ratio,\n",
    "                iterative_steps_config=cfg['iterative_steps_pruner_general'],\n",
    "                iterative_steps_taylor=cfg['iterative_steps_taylor_pruning']\n",
    "            )\n",
    "\n",
    "            # Optional: Evaluate on test set *before* fine-tuning\n",
    "            metrics_pruned_bf_ft_current = evaluate_model(pruned_model_current, test_loader, example_input_dev, criterion_train_eval, device)\n",
    "            print(f\"Metrics for '{strategy_name_key}' @ Ratio {current_ratio:.2f} (Pruned, Before FT, on Test Set): {metrics_pruned_bf_ft_current}\")\n",
    "\n",
    "            print(f\"--- Fine-tuning pruned model ({strategy_name_key} @ Ratio {current_ratio:.2f}) ---\")\n",
    "            fine_tuned_model_current, ft_history_current = train_model(\n",
    "                model=pruned_model_current,\n",
    "                train_loader=train_loader,\n",
    "                criterion=criterion_train_eval,\n",
    "                optimizer=optim.Adam(pruned_model_current.parameters(), lr=cfg['learning_rate_finetune'], weight_decay=1e-4),\n",
    "                device=device,\n",
    "                num_epochs=cfg['fine_tune_epochs'],\n",
    "                val_loader=val_loader,\n",
    "                strategy_name=f\"{strategy_name_key}_R{current_ratio:.1f}\",\n",
    "                early_stopping_patience=cfg['early_stopping_patience'],\n",
    "                early_stopping_metric=cfg['early_stopping_metric'],\n",
    "                load_best_model_on_stop=cfg['load_best_model_on_early_stop']\n",
    "            )\n",
    "\n",
    "            macs_ft_current, _ = calculate_macs(fine_tuned_model_current, example_input_dev)\n",
    "            plot_finetuning_curves(ft_history_current, f\"{strategy_name_key}_R{current_ratio:.1f}\",\n",
    "                                   strategy_specific_output_dir, macs_ft_current)\n",
    "\n",
    "            # Final evaluation of fine-tuned model on the TEST set\n",
    "            print(f\"--- Evaluating Fine-tuned Model ({strategy_name_key} @ Ratio {current_ratio:.2f}) on TEST SET ---\")\n",
    "            final_metrics_current = evaluate_model(fine_tuned_model_current, test_loader, example_input_dev, criterion_train_eval, device)\n",
    "            results_all_ratios_strategies[strategy_name_key][current_ratio] = final_metrics_current\n",
    "            print(f\"Metrics for '{strategy_name_key}' @ Ratio {current_ratio:.2f} (Fine-tuned, on Test Set): {final_metrics_current}\")\n",
    "            save_model(fine_tuned_model_current,\n",
    "                       os.path.join(strategy_specific_output_dir, f\"model_R{current_ratio:.1f}_final.pth\"),\n",
    "                       example_input=example_input_cpu_onnx.to(device))\n",
    "\n",
    "    plot_metrics_vs_ratio_all_strategies(results_all_ratios_strategies, cfg['pruning_ratios_to_test'], cfg['output_dir_base'])\n",
    "    print(\"\\nAll ratio-based pruning experiments completed successfully!\")"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "6d51f760-3726-4028-98a7-02e0105ebd82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T16:43:17.372203Z",
     "start_time": "2025-05-22T16:20:17.852947Z"
    }
   },
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DataLoaders...\n",
      "Attempting to load CIFAR-10 from directory: /home/muis/thesis/github-repo/master-thesis/cnn/mobile_net_v2/data\n",
      "Successfully indexed 50000 training images for splitting from /home/muis/thesis/github-repo/master-thesis/cnn/mobile_net_v2/data.\n",
      "Successfully loaded 10000 test images from /home/muis/thesis/github-repo/master-thesis/cnn/mobile_net_v2/data.\n",
      "Using 4 workers for DataLoaders.\n",
      "Train loader: 45000 samples, Val loader: 5000 samples, Test loader: 10000 samples\n",
      "--- Training Initial Dense MobileNetV2 ---\n",
      "Strategy: InitialDenseModel - Epoch 1/1000: Train Loss=1.7938, Train Acc=33.03%, Val Loss=1.5669, Val Acc=42.60% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 2/1000: Train Loss=1.4680, Train Acc=46.08%, Val Loss=1.3369, Val Acc=50.82% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 3/1000: Train Loss=1.3200, Train Acc=52.24%, Val Loss=1.2073, Val Acc=56.46% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 4/1000: Train Loss=1.2103, Train Acc=56.44%, Val Loss=1.0876, Val Acc=60.14% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 5/1000: Train Loss=1.1174, Train Acc=60.17%, Val Loss=1.0478, Val Acc=62.90% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 6/1000: Train Loss=1.0528, Train Acc=62.33%, Val Loss=0.9231, Val Acc=66.48% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 7/1000: Train Loss=0.9885, Train Acc=65.00%, Val Loss=0.8698, Val Acc=68.20% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 8/1000: Train Loss=0.9482, Train Acc=66.50%, Val Loss=0.8562, Val Acc=69.54% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 9/1000: Train Loss=0.8960, Train Acc=68.46%, Val Loss=0.8087, Val Acc=69.96% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 10/1000: Train Loss=0.8637, Train Acc=69.39%, Val Loss=0.7802, Val Acc=72.04% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 11/1000: Train Loss=0.8329, Train Acc=70.73%, Val Loss=0.7445, Val Acc=73.02% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 12/1000: Train Loss=0.8002, Train Acc=72.04%, Val Loss=0.7505, Val Acc=73.06%\n",
      "Strategy: InitialDenseModel - Epoch 13/1000: Train Loss=0.7803, Train Acc=72.56%, Val Loss=0.7556, Val Acc=73.40%\n",
      "Strategy: InitialDenseModel - Epoch 14/1000: Train Loss=0.7574, Train Acc=73.47%, Val Loss=0.6989, Val Acc=75.04% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 15/1000: Train Loss=0.7398, Train Acc=73.99%, Val Loss=0.6758, Val Acc=75.74% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 16/1000: Train Loss=0.7220, Train Acc=74.66%, Val Loss=0.6934, Val Acc=74.92%\n",
      "Strategy: InitialDenseModel - Epoch 17/1000: Train Loss=0.7089, Train Acc=75.30%, Val Loss=0.6525, Val Acc=76.54% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 18/1000: Train Loss=0.6941, Train Acc=75.70%, Val Loss=0.6456, Val Acc=76.60% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 19/1000: Train Loss=0.6789, Train Acc=76.27%, Val Loss=0.6274, Val Acc=77.18% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 20/1000: Train Loss=0.6605, Train Acc=76.92%, Val Loss=0.6280, Val Acc=77.60%\n",
      "Strategy: InitialDenseModel - Epoch 21/1000: Train Loss=0.6501, Train Acc=77.29%, Val Loss=0.6702, Val Acc=76.76%\n",
      "Strategy: InitialDenseModel - Epoch 22/1000: Train Loss=0.6383, Train Acc=77.77%, Val Loss=0.6730, Val Acc=76.70%\n",
      "Strategy: InitialDenseModel - Epoch 23/1000: Train Loss=0.6301, Train Acc=78.08%, Val Loss=0.6154, Val Acc=78.28% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 24/1000: Train Loss=0.6225, Train Acc=78.33%, Val Loss=0.6044, Val Acc=78.84% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 25/1000: Train Loss=0.6074, Train Acc=78.86%, Val Loss=0.6022, Val Acc=78.82% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 26/1000: Train Loss=0.6039, Train Acc=79.05%, Val Loss=0.5636, Val Acc=80.18% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 27/1000: Train Loss=0.5901, Train Acc=79.51%, Val Loss=0.5689, Val Acc=78.78%\n",
      "Strategy: InitialDenseModel - Epoch 28/1000: Train Loss=0.5840, Train Acc=79.70%, Val Loss=0.5880, Val Acc=79.68%\n",
      "Strategy: InitialDenseModel - Epoch 29/1000: Train Loss=0.5725, Train Acc=79.81%, Val Loss=0.5859, Val Acc=79.16%\n",
      "Strategy: InitialDenseModel - Epoch 30/1000: Train Loss=0.5673, Train Acc=80.06%, Val Loss=0.5516, Val Acc=80.14% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 31/1000: Train Loss=0.5619, Train Acc=80.40%, Val Loss=0.5667, Val Acc=79.34%\n",
      "Strategy: InitialDenseModel - Epoch 32/1000: Train Loss=0.5534, Train Acc=80.64%, Val Loss=0.5606, Val Acc=80.58%\n",
      "Strategy: InitialDenseModel - Epoch 33/1000: Train Loss=0.5521, Train Acc=80.86%, Val Loss=0.5413, Val Acc=81.08% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 34/1000: Train Loss=0.5366, Train Acc=81.36%, Val Loss=0.5269, Val Acc=80.98% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 35/1000: Train Loss=0.5365, Train Acc=81.17%, Val Loss=0.5540, Val Acc=80.78%\n",
      "Strategy: InitialDenseModel - Epoch 36/1000: Train Loss=0.5227, Train Acc=81.76%, Val Loss=0.5349, Val Acc=81.00%\n",
      "Strategy: InitialDenseModel - Epoch 37/1000: Train Loss=0.5248, Train Acc=81.62%, Val Loss=0.5288, Val Acc=81.36%\n",
      "Strategy: InitialDenseModel - Epoch 38/1000: Train Loss=0.5107, Train Acc=82.24%, Val Loss=0.5346, Val Acc=80.68%\n",
      "Strategy: InitialDenseModel - Epoch 39/1000: Train Loss=0.5086, Train Acc=82.39%, Val Loss=0.5271, Val Acc=81.24%\n",
      "Strategy: InitialDenseModel - Epoch 40/1000: Train Loss=0.5037, Train Acc=82.55%, Val Loss=0.5188, Val Acc=81.28% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 41/1000: Train Loss=0.5008, Train Acc=82.67%, Val Loss=0.5003, Val Acc=82.14% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 42/1000: Train Loss=0.4923, Train Acc=82.77%, Val Loss=0.5156, Val Acc=82.02%\n",
      "Strategy: InitialDenseModel - Epoch 43/1000: Train Loss=0.4884, Train Acc=83.00%, Val Loss=0.4889, Val Acc=82.62% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 44/1000: Train Loss=0.4889, Train Acc=82.99%, Val Loss=0.4956, Val Acc=82.68%\n",
      "Strategy: InitialDenseModel - Epoch 45/1000: Train Loss=0.4790, Train Acc=83.30%, Val Loss=0.5016, Val Acc=82.40%\n",
      "Strategy: InitialDenseModel - Epoch 46/1000: Train Loss=0.4774, Train Acc=83.29%, Val Loss=0.5074, Val Acc=82.18%\n",
      "Strategy: InitialDenseModel - Epoch 47/1000: Train Loss=0.4731, Train Acc=83.64%, Val Loss=0.5143, Val Acc=82.34%\n",
      "Strategy: InitialDenseModel - Epoch 48/1000: Train Loss=0.4712, Train Acc=83.63%, Val Loss=0.4897, Val Acc=82.70%\n",
      "Strategy: InitialDenseModel - Epoch 49/1000: Train Loss=0.4670, Train Acc=83.41%, Val Loss=0.4814, Val Acc=83.42% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 50/1000: Train Loss=0.4579, Train Acc=84.12%, Val Loss=0.4862, Val Acc=82.98%\n",
      "Strategy: InitialDenseModel - Epoch 51/1000: Train Loss=0.4603, Train Acc=83.98%, Val Loss=0.4841, Val Acc=83.36%\n",
      "Strategy: InitialDenseModel - Epoch 52/1000: Train Loss=0.4591, Train Acc=84.03%, Val Loss=0.4860, Val Acc=83.10%\n",
      "Strategy: InitialDenseModel - Epoch 53/1000: Train Loss=0.4551, Train Acc=84.16%, Val Loss=0.4795, Val Acc=83.48% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 54/1000: Train Loss=0.4496, Train Acc=84.25%, Val Loss=0.5023, Val Acc=82.84%\n",
      "Strategy: InitialDenseModel - Epoch 55/1000: Train Loss=0.4444, Train Acc=84.57%, Val Loss=0.4777, Val Acc=83.32% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 56/1000: Train Loss=0.4407, Train Acc=84.47%, Val Loss=0.4771, Val Acc=83.24% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 57/1000: Train Loss=0.4390, Train Acc=84.76%, Val Loss=0.4906, Val Acc=83.22%\n",
      "Strategy: InitialDenseModel - Epoch 58/1000: Train Loss=0.4327, Train Acc=84.93%, Val Loss=0.4771, Val Acc=83.54%\n",
      "Strategy: InitialDenseModel - Epoch 59/1000: Train Loss=0.4350, Train Acc=84.84%, Val Loss=0.4842, Val Acc=83.50%\n",
      "Strategy: InitialDenseModel - Epoch 60/1000: Train Loss=0.4272, Train Acc=85.19%, Val Loss=0.4762, Val Acc=83.20% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 61/1000: Train Loss=0.4283, Train Acc=84.92%, Val Loss=0.4668, Val Acc=83.66% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 62/1000: Train Loss=0.4231, Train Acc=85.28%, Val Loss=0.4745, Val Acc=83.74%\n",
      "Strategy: InitialDenseModel - Epoch 63/1000: Train Loss=0.4208, Train Acc=85.27%, Val Loss=0.4718, Val Acc=83.80%\n",
      "Strategy: InitialDenseModel - Epoch 64/1000: Train Loss=0.4174, Train Acc=85.59%, Val Loss=0.4781, Val Acc=83.88%\n",
      "Strategy: InitialDenseModel - Epoch 65/1000: Train Loss=0.4192, Train Acc=85.36%, Val Loss=0.4793, Val Acc=83.54%\n",
      "Strategy: InitialDenseModel - Epoch 66/1000: Train Loss=0.4112, Train Acc=85.53%, Val Loss=0.4788, Val Acc=83.44%\n",
      "Strategy: InitialDenseModel - Epoch 67/1000: Train Loss=0.4115, Train Acc=85.59%, Val Loss=0.4652, Val Acc=83.76% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 68/1000: Train Loss=0.4090, Train Acc=85.71%, Val Loss=0.4632, Val Acc=83.84% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 69/1000: Train Loss=0.4016, Train Acc=85.88%, Val Loss=0.4810, Val Acc=83.68%\n",
      "Strategy: InitialDenseModel - Epoch 70/1000: Train Loss=0.4068, Train Acc=85.90%, Val Loss=0.4782, Val Acc=83.30%\n",
      "Strategy: InitialDenseModel - Epoch 71/1000: Train Loss=0.4018, Train Acc=85.82%, Val Loss=0.4548, Val Acc=83.70% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 72/1000: Train Loss=0.4000, Train Acc=85.98%, Val Loss=0.4648, Val Acc=83.06%\n",
      "Strategy: InitialDenseModel - Epoch 73/1000: Train Loss=0.3972, Train Acc=86.08%, Val Loss=0.4597, Val Acc=83.82%\n",
      "Strategy: InitialDenseModel - Epoch 74/1000: Train Loss=0.3937, Train Acc=86.25%, Val Loss=0.4503, Val Acc=84.22% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 75/1000: Train Loss=0.3940, Train Acc=86.33%, Val Loss=0.4493, Val Acc=84.58% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 76/1000: Train Loss=0.3865, Train Acc=86.30%, Val Loss=0.4729, Val Acc=83.62%\n",
      "Strategy: InitialDenseModel - Epoch 77/1000: Train Loss=0.3892, Train Acc=86.26%, Val Loss=0.4594, Val Acc=84.26%\n",
      "Strategy: InitialDenseModel - Epoch 78/1000: Train Loss=0.3855, Train Acc=86.41%, Val Loss=0.4522, Val Acc=84.28%\n",
      "Strategy: InitialDenseModel - Epoch 79/1000: Train Loss=0.3806, Train Acc=86.58%, Val Loss=0.4558, Val Acc=84.20%\n",
      "Strategy: InitialDenseModel - Epoch 80/1000: Train Loss=0.3814, Train Acc=86.74%, Val Loss=0.4575, Val Acc=84.00%\n",
      "Strategy: InitialDenseModel - Epoch 81/1000: Train Loss=0.3782, Train Acc=86.67%, Val Loss=0.4593, Val Acc=84.54%\n",
      "Strategy: InitialDenseModel - Epoch 82/1000: Train Loss=0.3811, Train Acc=86.56%, Val Loss=0.4593, Val Acc=84.00%\n",
      "Strategy: InitialDenseModel - Epoch 83/1000: Train Loss=0.3723, Train Acc=86.91%, Val Loss=0.4547, Val Acc=84.24%\n",
      "Strategy: InitialDenseModel - Epoch 84/1000: Train Loss=0.3769, Train Acc=86.77%, Val Loss=0.4632, Val Acc=84.02%\n",
      "Strategy: InitialDenseModel - Epoch 85/1000: Train Loss=0.3762, Train Acc=86.94%, Val Loss=0.4429, Val Acc=84.36% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 86/1000: Train Loss=0.3718, Train Acc=86.92%, Val Loss=0.4438, Val Acc=84.44%\n",
      "Strategy: InitialDenseModel - Epoch 87/1000: Train Loss=0.3725, Train Acc=86.84%, Val Loss=0.4661, Val Acc=83.82%\n",
      "Strategy: InitialDenseModel - Epoch 88/1000: Train Loss=0.3640, Train Acc=87.16%, Val Loss=0.4358, Val Acc=85.06% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 89/1000: Train Loss=0.3645, Train Acc=87.30%, Val Loss=0.4719, Val Acc=84.14%\n",
      "Strategy: InitialDenseModel - Epoch 90/1000: Train Loss=0.3710, Train Acc=86.99%, Val Loss=0.4388, Val Acc=84.90%\n",
      "Strategy: InitialDenseModel - Epoch 91/1000: Train Loss=0.3606, Train Acc=87.32%, Val Loss=0.4514, Val Acc=84.62%\n",
      "Strategy: InitialDenseModel - Epoch 92/1000: Train Loss=0.3623, Train Acc=87.16%, Val Loss=0.4447, Val Acc=84.86%\n",
      "Strategy: InitialDenseModel - Epoch 93/1000: Train Loss=0.3583, Train Acc=87.39%, Val Loss=0.4492, Val Acc=83.84%\n",
      "Strategy: InitialDenseModel - Epoch 94/1000: Train Loss=0.3639, Train Acc=87.19%, Val Loss=0.4309, Val Acc=84.68% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 95/1000: Train Loss=0.3555, Train Acc=87.60%, Val Loss=0.4544, Val Acc=84.72%\n",
      "Strategy: InitialDenseModel - Epoch 96/1000: Train Loss=0.3586, Train Acc=87.35%, Val Loss=0.4453, Val Acc=84.54%\n",
      "Strategy: InitialDenseModel - Epoch 97/1000: Train Loss=0.3576, Train Acc=87.21%, Val Loss=0.4675, Val Acc=84.22%\n",
      "Strategy: InitialDenseModel - Epoch 98/1000: Train Loss=0.3530, Train Acc=87.50%, Val Loss=0.4517, Val Acc=84.20%\n",
      "Strategy: InitialDenseModel - Epoch 99/1000: Train Loss=0.3541, Train Acc=87.48%, Val Loss=0.4286, Val Acc=85.12% (New best val_loss)\n",
      "Strategy: InitialDenseModel - Epoch 100/1000: Train Loss=0.3473, Train Acc=87.79%, Val Loss=0.4517, Val Acc=83.96%\n",
      "Strategy: InitialDenseModel - Epoch 101/1000: Train Loss=0.3494, Train Acc=87.73%, Val Loss=0.4539, Val Acc=84.26%\n",
      "Strategy: InitialDenseModel - Epoch 102/1000: Train Loss=0.3472, Train Acc=87.73%, Val Loss=0.4574, Val Acc=84.42%\n",
      "Strategy: InitialDenseModel - Epoch 103/1000: Train Loss=0.3450, Train Acc=87.72%, Val Loss=0.4508, Val Acc=84.70%\n",
      "Strategy: InitialDenseModel - Epoch 104/1000: Train Loss=0.3410, Train Acc=88.16%, Val Loss=0.4619, Val Acc=83.80%\n",
      "Strategy: InitialDenseModel - Epoch 105/1000: Train Loss=0.3444, Train Acc=87.93%, Val Loss=0.4308, Val Acc=84.72%\n",
      "Strategy: InitialDenseModel - Epoch 106/1000: Train Loss=0.3452, Train Acc=87.78%, Val Loss=0.4307, Val Acc=85.26%\n",
      "Strategy: InitialDenseModel - Epoch 107/1000: Train Loss=0.3367, Train Acc=87.93%, Val Loss=0.4455, Val Acc=84.86%\n",
      "Strategy: InitialDenseModel - Epoch 108/1000: Train Loss=0.3373, Train Acc=88.02%, Val Loss=0.4415, Val Acc=84.78%\n",
      "Strategy: InitialDenseModel - Epoch 109/1000: Train Loss=0.3346, Train Acc=88.13%, Val Loss=0.4506, Val Acc=84.58%\n",
      "Strategy: InitialDenseModel - Epoch 110/1000: Train Loss=0.3371, Train Acc=88.13%, Val Loss=0.4758, Val Acc=83.66%\n",
      "Strategy: InitialDenseModel - Epoch 111/1000: Train Loss=0.3331, Train Acc=88.24%, Val Loss=0.4289, Val Acc=85.48%\n",
      "Strategy: InitialDenseModel - Epoch 112/1000: Train Loss=0.3290, Train Acc=88.46%, Val Loss=0.4498, Val Acc=84.72%\n",
      "Strategy: InitialDenseModel - Epoch 113/1000: Train Loss=0.3334, Train Acc=88.19%, Val Loss=0.4392, Val Acc=85.26%\n",
      "Strategy: InitialDenseModel - Epoch 114/1000: Train Loss=0.3318, Train Acc=88.18%, Val Loss=0.4537, Val Acc=84.94%\n",
      "Strategy: InitialDenseModel - Epoch 115/1000: Train Loss=0.3312, Train Acc=88.35%, Val Loss=0.4556, Val Acc=84.26%\n",
      "Strategy: InitialDenseModel - Epoch 116/1000: Train Loss=0.3251, Train Acc=88.59%, Val Loss=0.4453, Val Acc=84.98%\n",
      "Strategy: InitialDenseModel - Epoch 117/1000: Train Loss=0.3280, Train Acc=88.49%, Val Loss=0.4487, Val Acc=84.72%\n",
      "Strategy: InitialDenseModel - Epoch 118/1000: Train Loss=0.3227, Train Acc=88.70%, Val Loss=0.4457, Val Acc=84.56%\n",
      "Strategy: InitialDenseModel - Epoch 119/1000: Train Loss=0.3214, Train Acc=88.60%, Val Loss=0.4381, Val Acc=85.26%\n",
      "Early stopping triggered for 'InitialDenseModel' after 119 epochs. No improvement in 'val_loss' for 20 epochs.\n",
      "Loading best model weights from epoch 99 with val_loss: 0.4286\n",
      "Training for 'InitialDenseModel' finished. Loading best recorded model state with val_loss: 0.4286\n",
      "✅ Model saved as ONNX to ./output_final_ratio_experiment/mobilenetv2_initial_dense_trained.onnx\n",
      "✅ MobileNetV2_CIFAR10_InitialDense Loss vs. Epochs plot saved to ./output_final_ratio_experiment/initial_model_training_plots\n",
      "✅ MobileNetV2_CIFAR10_InitialDense Loss vs. Accuracy plot saved to ./output_final_ratio_experiment/initial_model_training_plots\n",
      "\n",
      "--- Evaluating Baseline Model (Ratio 0.0) on TEST SET---\n",
      "✅ Model loaded from ./output_final_ratio_experiment/mobilenetv2_initial_dense_trained.pth to cuda\n",
      "Baseline Metrics (Ratio 0.0, Evaluated on Test Set): {'macs': 6059786.0, 'params': 1169642, 'size_mib': 4.461830139160156, 'accuracy': 85.09, 'loss': 0.44558160047531126}\n",
      "\n",
      "\n",
      "--- Processing: Strategy 'magnitude', Ratio: 0.20 ---\n",
      "✅ Model loaded from ./output_final_ratio_experiment/mobilenetv2_initial_dense_trained.pth to cuda\n",
      "--- Pruning model with magnitude to ratio 0.20 ---\n",
      "Initial MACs before pruning for ratio 0.20: 0.006 G\n",
      "Applying MagnitudeImportance with target ratio: 0.20 using pruner's 5 iterative_steps.\n",
      "After pruning for ratio 0.20: MACs 0.006 G (Reduction: 8.36%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muis/.virtualenvs/master-thesis/lib/python3.12/site-packages/torch_pruning/pruner/algorithms/base_pruner.py:87: UserWarning: ch_sparsity is deprecated in v1.3.0. Please use pruning_ratio.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for 'magnitude' @ Ratio 0.20 (Pruned, Before FT, on Test Set): {'macs': 5553441.0, 'params': 1076719, 'size_mib': 4.107357025146484, 'accuracy': 82.79, 'loss': 0.513667586517334}\n",
      "--- Fine-tuning pruned model (magnitude @ Ratio 0.20) ---\n",
      "Strategy: magnitude_R0.2 - Epoch 1/1000: Train Loss=0.3230, Train Acc=88.54%, Val Loss=0.4168, Val Acc=85.28% (New best val_loss)\n",
      "Strategy: magnitude_R0.2 - Epoch 2/1000: Train Loss=0.2935, Train Acc=89.54%, Val Loss=0.4094, Val Acc=85.78% (New best val_loss)\n",
      "Strategy: magnitude_R0.2 - Epoch 3/1000: Train Loss=0.2829, Train Acc=89.97%, Val Loss=0.4128, Val Acc=85.90%\n",
      "Strategy: magnitude_R0.2 - Epoch 4/1000: Train Loss=0.2772, Train Acc=90.09%, Val Loss=0.4114, Val Acc=86.08%\n",
      "Strategy: magnitude_R0.2 - Epoch 5/1000: Train Loss=0.2662, Train Acc=90.52%, Val Loss=0.4112, Val Acc=86.02%\n",
      "Strategy: magnitude_R0.2 - Epoch 6/1000: Train Loss=0.2633, Train Acc=90.62%, Val Loss=0.4085, Val Acc=86.36% (New best val_loss)\n",
      "Strategy: magnitude_R0.2 - Epoch 7/1000: Train Loss=0.2596, Train Acc=90.76%, Val Loss=0.4029, Val Acc=86.28% (New best val_loss)\n",
      "Strategy: magnitude_R0.2 - Epoch 8/1000: Train Loss=0.2538, Train Acc=90.97%, Val Loss=0.4097, Val Acc=86.52%\n",
      "Strategy: magnitude_R0.2 - Epoch 9/1000: Train Loss=0.2516, Train Acc=91.07%, Val Loss=0.4081, Val Acc=86.62%\n",
      "Strategy: magnitude_R0.2 - Epoch 10/1000: Train Loss=0.2495, Train Acc=91.19%, Val Loss=0.4118, Val Acc=86.10%\n",
      "Strategy: magnitude_R0.2 - Epoch 11/1000: Train Loss=0.2411, Train Acc=91.53%, Val Loss=0.4150, Val Acc=86.16%\n",
      "Strategy: magnitude_R0.2 - Epoch 12/1000: Train Loss=0.2410, Train Acc=91.40%, Val Loss=0.4115, Val Acc=86.52%\n",
      "Strategy: magnitude_R0.2 - Epoch 13/1000: Train Loss=0.2384, Train Acc=91.50%, Val Loss=0.4129, Val Acc=86.52%\n",
      "Strategy: magnitude_R0.2 - Epoch 14/1000: Train Loss=0.2398, Train Acc=91.47%, Val Loss=0.4122, Val Acc=86.62%\n",
      "Strategy: magnitude_R0.2 - Epoch 15/1000: Train Loss=0.2315, Train Acc=91.66%, Val Loss=0.4130, Val Acc=86.44%\n",
      "Strategy: magnitude_R0.2 - Epoch 16/1000: Train Loss=0.2312, Train Acc=91.72%, Val Loss=0.4128, Val Acc=86.30%\n",
      "Strategy: magnitude_R0.2 - Epoch 17/1000: Train Loss=0.2311, Train Acc=91.71%, Val Loss=0.4164, Val Acc=86.32%\n",
      "Strategy: magnitude_R0.2 - Epoch 18/1000: Train Loss=0.2295, Train Acc=91.80%, Val Loss=0.4161, Val Acc=86.16%\n",
      "Strategy: magnitude_R0.2 - Epoch 19/1000: Train Loss=0.2294, Train Acc=91.93%, Val Loss=0.4202, Val Acc=86.30%\n",
      "Strategy: magnitude_R0.2 - Epoch 20/1000: Train Loss=0.2271, Train Acc=91.96%, Val Loss=0.4234, Val Acc=86.36%\n",
      "Strategy: magnitude_R0.2 - Epoch 21/1000: Train Loss=0.2286, Train Acc=91.94%, Val Loss=0.4237, Val Acc=86.32%\n",
      "Strategy: magnitude_R0.2 - Epoch 22/1000: Train Loss=0.2244, Train Acc=92.03%, Val Loss=0.4222, Val Acc=86.34%\n",
      "Strategy: magnitude_R0.2 - Epoch 23/1000: Train Loss=0.2155, Train Acc=92.30%, Val Loss=0.4166, Val Acc=86.54%\n",
      "Strategy: magnitude_R0.2 - Epoch 24/1000: Train Loss=0.2172, Train Acc=92.26%, Val Loss=0.4225, Val Acc=86.20%\n",
      "Strategy: magnitude_R0.2 - Epoch 25/1000: Train Loss=0.2187, Train Acc=92.25%, Val Loss=0.4243, Val Acc=86.12%\n",
      "Strategy: magnitude_R0.2 - Epoch 26/1000: Train Loss=0.2203, Train Acc=92.10%, Val Loss=0.4275, Val Acc=86.16%\n",
      "Strategy: magnitude_R0.2 - Epoch 27/1000: Train Loss=0.2208, Train Acc=92.07%, Val Loss=0.4273, Val Acc=86.14%\n",
      "Early stopping triggered for 'magnitude_R0.2' after 27 epochs. No improvement in 'val_loss' for 20 epochs.\n",
      "Loading best model weights from epoch 7 with val_loss: 0.4029\n",
      "Training for 'magnitude_R0.2' finished. Loading best recorded model state with val_loss: 0.4029\n",
      "✅ Fine-tuning curves for magnitude_R0.2 saved.\n",
      "--- Evaluating Fine-tuned Model (magnitude @ Ratio 0.20) on TEST SET ---\n",
      "Metrics for 'magnitude' @ Ratio 0.20 (Fine-tuned, on Test Set): {'macs': 5553441.0, 'params': 1076719, 'size_mib': 4.107357025146484, 'accuracy': 86.23, 'loss': 0.4284124759674072}\n",
      "✅ Model saved as ONNX to ./output_final_ratio_experiment/magnitude/model_R0.2_final.onnx\n",
      "\n",
      "\n",
      "--- Processing: Strategy 'magnitude', Ratio: 0.50 ---\n",
      "✅ Model loaded from ./output_final_ratio_experiment/mobilenetv2_initial_dense_trained.pth to cuda\n",
      "--- Pruning model with magnitude to ratio 0.50 ---\n",
      "Initial MACs before pruning for ratio 0.50: 0.006 G\n",
      "Applying MagnitudeImportance with target ratio: 0.50 using pruner's 5 iterative_steps.\n",
      "After pruning for ratio 0.50: MACs 0.005 G (Reduction: 18.74%)\n",
      "Metrics for 'magnitude' @ Ratio 0.50 (Pruned, Before FT, on Test Set): {'macs': 4924394.0, 'params': 950314, 'size_mib': 3.6251602172851562, 'accuracy': 72.24, 'loss': 0.8764889598846436}\n",
      "--- Fine-tuning pruned model (magnitude @ Ratio 0.50) ---\n",
      "Strategy: magnitude_R0.5 - Epoch 1/1000: Train Loss=0.3999, Train Acc=85.92%, Val Loss=0.4612, Val Acc=83.80% (New best val_loss)\n",
      "Strategy: magnitude_R0.5 - Epoch 2/1000: Train Loss=0.3474, Train Acc=87.78%, Val Loss=0.4454, Val Acc=84.18% (New best val_loss)\n",
      "Strategy: magnitude_R0.5 - Epoch 3/1000: Train Loss=0.3345, Train Acc=88.20%, Val Loss=0.4429, Val Acc=84.58% (New best val_loss)\n",
      "Strategy: magnitude_R0.5 - Epoch 4/1000: Train Loss=0.3224, Train Acc=88.74%, Val Loss=0.4380, Val Acc=84.62% (New best val_loss)\n",
      "Strategy: magnitude_R0.5 - Epoch 5/1000: Train Loss=0.3092, Train Acc=89.03%, Val Loss=0.4373, Val Acc=84.78% (New best val_loss)\n",
      "Strategy: magnitude_R0.5 - Epoch 6/1000: Train Loss=0.3108, Train Acc=88.93%, Val Loss=0.4338, Val Acc=85.06% (New best val_loss)\n",
      "Strategy: magnitude_R0.5 - Epoch 7/1000: Train Loss=0.2982, Train Acc=89.36%, Val Loss=0.4350, Val Acc=85.10%\n",
      "Strategy: magnitude_R0.5 - Epoch 8/1000: Train Loss=0.2942, Train Acc=89.47%, Val Loss=0.4314, Val Acc=85.36% (New best val_loss)\n",
      "Strategy: magnitude_R0.5 - Epoch 9/1000: Train Loss=0.2907, Train Acc=89.70%, Val Loss=0.4315, Val Acc=85.06%\n",
      "Strategy: magnitude_R0.5 - Epoch 10/1000: Train Loss=0.2814, Train Acc=90.08%, Val Loss=0.4306, Val Acc=85.40% (New best val_loss)\n",
      "Strategy: magnitude_R0.5 - Epoch 11/1000: Train Loss=0.2767, Train Acc=90.12%, Val Loss=0.4310, Val Acc=85.42%\n",
      "Strategy: magnitude_R0.5 - Epoch 12/1000: Train Loss=0.2733, Train Acc=90.16%, Val Loss=0.4259, Val Acc=85.54% (New best val_loss)\n",
      "Strategy: magnitude_R0.5 - Epoch 13/1000: Train Loss=0.2727, Train Acc=90.28%, Val Loss=0.4244, Val Acc=85.48% (New best val_loss)\n",
      "Strategy: magnitude_R0.5 - Epoch 14/1000: Train Loss=0.2692, Train Acc=90.39%, Val Loss=0.4275, Val Acc=85.42%\n",
      "Strategy: magnitude_R0.5 - Epoch 15/1000: Train Loss=0.2680, Train Acc=90.32%, Val Loss=0.4257, Val Acc=85.38%\n",
      "Strategy: magnitude_R0.5 - Epoch 16/1000: Train Loss=0.2615, Train Acc=90.63%, Val Loss=0.4240, Val Acc=85.64% (New best val_loss)\n",
      "Strategy: magnitude_R0.5 - Epoch 17/1000: Train Loss=0.2608, Train Acc=90.70%, Val Loss=0.4204, Val Acc=85.52% (New best val_loss)\n",
      "Strategy: magnitude_R0.5 - Epoch 18/1000: Train Loss=0.2542, Train Acc=90.87%, Val Loss=0.4258, Val Acc=85.76%\n",
      "Strategy: magnitude_R0.5 - Epoch 19/1000: Train Loss=0.2502, Train Acc=91.00%, Val Loss=0.4230, Val Acc=85.58%\n",
      "Strategy: magnitude_R0.5 - Epoch 20/1000: Train Loss=0.2548, Train Acc=90.99%, Val Loss=0.4264, Val Acc=85.70%\n",
      "Strategy: magnitude_R0.5 - Epoch 21/1000: Train Loss=0.2526, Train Acc=90.89%, Val Loss=0.4235, Val Acc=85.92%\n",
      "Strategy: magnitude_R0.5 - Epoch 22/1000: Train Loss=0.2478, Train Acc=91.15%, Val Loss=0.4308, Val Acc=85.56%\n",
      "Strategy: magnitude_R0.5 - Epoch 23/1000: Train Loss=0.2478, Train Acc=91.18%, Val Loss=0.4269, Val Acc=85.86%\n",
      "Strategy: magnitude_R0.5 - Epoch 24/1000: Train Loss=0.2465, Train Acc=91.14%, Val Loss=0.4273, Val Acc=86.02%\n",
      "Strategy: magnitude_R0.5 - Epoch 25/1000: Train Loss=0.2471, Train Acc=91.24%, Val Loss=0.4266, Val Acc=85.98%\n",
      "Strategy: magnitude_R0.5 - Epoch 26/1000: Train Loss=0.2414, Train Acc=91.37%, Val Loss=0.4304, Val Acc=85.76%\n",
      "Strategy: magnitude_R0.5 - Epoch 27/1000: Train Loss=0.2466, Train Acc=91.24%, Val Loss=0.4211, Val Acc=86.02%\n",
      "Strategy: magnitude_R0.5 - Epoch 28/1000: Train Loss=0.2423, Train Acc=91.35%, Val Loss=0.4289, Val Acc=85.84%\n",
      "Strategy: magnitude_R0.5 - Epoch 29/1000: Train Loss=0.2349, Train Acc=91.71%, Val Loss=0.4318, Val Acc=86.10%\n",
      "Strategy: magnitude_R0.5 - Epoch 30/1000: Train Loss=0.2329, Train Acc=91.63%, Val Loss=0.4284, Val Acc=85.68%\n",
      "Strategy: magnitude_R0.5 - Epoch 31/1000: Train Loss=0.2369, Train Acc=91.53%, Val Loss=0.4394, Val Acc=85.94%\n",
      "Strategy: magnitude_R0.5 - Epoch 32/1000: Train Loss=0.2318, Train Acc=91.58%, Val Loss=0.4353, Val Acc=85.88%\n",
      "Strategy: magnitude_R0.5 - Epoch 33/1000: Train Loss=0.2377, Train Acc=91.52%, Val Loss=0.4317, Val Acc=86.02%\n",
      "Strategy: magnitude_R0.5 - Epoch 34/1000: Train Loss=0.2348, Train Acc=91.65%, Val Loss=0.4343, Val Acc=85.64%\n",
      "Strategy: magnitude_R0.5 - Epoch 35/1000: Train Loss=0.2337, Train Acc=91.57%, Val Loss=0.4371, Val Acc=85.80%\n",
      "Strategy: magnitude_R0.5 - Epoch 36/1000: Train Loss=0.2298, Train Acc=91.78%, Val Loss=0.4356, Val Acc=85.72%\n",
      "Strategy: magnitude_R0.5 - Epoch 37/1000: Train Loss=0.2276, Train Acc=91.98%, Val Loss=0.4374, Val Acc=85.88%\n",
      "Early stopping triggered for 'magnitude_R0.5' after 37 epochs. No improvement in 'val_loss' for 20 epochs.\n",
      "Loading best model weights from epoch 17 with val_loss: 0.4204\n",
      "Training for 'magnitude_R0.5' finished. Loading best recorded model state with val_loss: 0.4204\n",
      "✅ Fine-tuning curves for magnitude_R0.5 saved.\n",
      "--- Evaluating Fine-tuned Model (magnitude @ Ratio 0.50) on TEST SET ---\n",
      "Metrics for 'magnitude' @ Ratio 0.50 (Fine-tuned, on Test Set): {'macs': 4924394.0, 'params': 950314, 'size_mib': 3.6251602172851562, 'accuracy': 85.82, 'loss': 0.4411367650985718}\n",
      "✅ Model saved as ONNX to ./output_final_ratio_experiment/magnitude/model_R0.5_final.onnx\n",
      "\n",
      "\n",
      "--- Processing: Strategy 'magnitude', Ratio: 0.70 ---\n",
      "✅ Model loaded from ./output_final_ratio_experiment/mobilenetv2_initial_dense_trained.pth to cuda\n",
      "--- Pruning model with magnitude to ratio 0.70 ---\n",
      "Initial MACs before pruning for ratio 0.70: 0.006 G\n",
      "Applying MagnitudeImportance with target ratio: 0.70 using pruner's 5 iterative_steps.\n",
      "After pruning for ratio 0.70: MACs 0.005 G (Reduction: 25.07%)\n",
      "Metrics for 'magnitude' @ Ratio 0.70 (Pruned, Before FT, on Test Set): {'macs': 4540476.0, 'params': 868248, 'size_mib': 3.312103271484375, 'accuracy': 64.9, 'loss': 1.0485723651885985}\n",
      "--- Fine-tuning pruned model (magnitude @ Ratio 0.70) ---\n",
      "Strategy: magnitude_R0.7 - Epoch 1/1000: Train Loss=0.4790, Train Acc=83.42%, Val Loss=0.4810, Val Acc=82.92% (New best val_loss)\n",
      "Strategy: magnitude_R0.7 - Epoch 2/1000: Train Loss=0.4049, Train Acc=85.68%, Val Loss=0.4598, Val Acc=83.58% (New best val_loss)\n",
      "Strategy: magnitude_R0.7 - Epoch 3/1000: Train Loss=0.3761, Train Acc=86.62%, Val Loss=0.4498, Val Acc=83.82% (New best val_loss)\n",
      "Strategy: magnitude_R0.7 - Epoch 4/1000: Train Loss=0.3612, Train Acc=87.21%, Val Loss=0.4435, Val Acc=84.04% (New best val_loss)\n",
      "Strategy: magnitude_R0.7 - Epoch 5/1000: Train Loss=0.3516, Train Acc=87.47%, Val Loss=0.4389, Val Acc=84.32% (New best val_loss)\n",
      "Strategy: magnitude_R0.7 - Epoch 6/1000: Train Loss=0.3368, Train Acc=88.16%, Val Loss=0.4401, Val Acc=84.56%\n",
      "Strategy: magnitude_R0.7 - Epoch 7/1000: Train Loss=0.3324, Train Acc=88.21%, Val Loss=0.4437, Val Acc=84.64%\n",
      "Strategy: magnitude_R0.7 - Epoch 8/1000: Train Loss=0.3244, Train Acc=88.54%, Val Loss=0.4386, Val Acc=84.54% (New best val_loss)\n",
      "Strategy: magnitude_R0.7 - Epoch 9/1000: Train Loss=0.3155, Train Acc=88.73%, Val Loss=0.4357, Val Acc=84.58% (New best val_loss)\n",
      "Strategy: magnitude_R0.7 - Epoch 10/1000: Train Loss=0.3152, Train Acc=88.76%, Val Loss=0.4385, Val Acc=84.88%\n",
      "Strategy: magnitude_R0.7 - Epoch 11/1000: Train Loss=0.3068, Train Acc=89.18%, Val Loss=0.4352, Val Acc=84.86% (New best val_loss)\n",
      "Strategy: magnitude_R0.7 - Epoch 12/1000: Train Loss=0.3029, Train Acc=89.24%, Val Loss=0.4341, Val Acc=85.16% (New best val_loss)\n",
      "Strategy: magnitude_R0.7 - Epoch 13/1000: Train Loss=0.3000, Train Acc=89.38%, Val Loss=0.4389, Val Acc=84.76%\n",
      "Strategy: magnitude_R0.7 - Epoch 14/1000: Train Loss=0.2991, Train Acc=89.32%, Val Loss=0.4361, Val Acc=84.80%\n",
      "Strategy: magnitude_R0.7 - Epoch 15/1000: Train Loss=0.2910, Train Acc=89.60%, Val Loss=0.4350, Val Acc=85.26%\n",
      "Strategy: magnitude_R0.7 - Epoch 16/1000: Train Loss=0.2924, Train Acc=89.53%, Val Loss=0.4316, Val Acc=85.14% (New best val_loss)\n",
      "Strategy: magnitude_R0.7 - Epoch 17/1000: Train Loss=0.2852, Train Acc=89.89%, Val Loss=0.4313, Val Acc=85.06% (New best val_loss)\n",
      "Strategy: magnitude_R0.7 - Epoch 18/1000: Train Loss=0.2854, Train Acc=89.89%, Val Loss=0.4301, Val Acc=85.06% (New best val_loss)\n",
      "Strategy: magnitude_R0.7 - Epoch 19/1000: Train Loss=0.2812, Train Acc=89.97%, Val Loss=0.4275, Val Acc=85.34% (New best val_loss)\n",
      "Strategy: magnitude_R0.7 - Epoch 20/1000: Train Loss=0.2818, Train Acc=90.01%, Val Loss=0.4388, Val Acc=85.38%\n",
      "Strategy: magnitude_R0.7 - Epoch 21/1000: Train Loss=0.2752, Train Acc=90.01%, Val Loss=0.4332, Val Acc=85.24%\n",
      "Strategy: magnitude_R0.7 - Epoch 22/1000: Train Loss=0.2696, Train Acc=90.42%, Val Loss=0.4339, Val Acc=85.52%\n",
      "Strategy: magnitude_R0.7 - Epoch 23/1000: Train Loss=0.2736, Train Acc=90.19%, Val Loss=0.4369, Val Acc=85.48%\n",
      "Strategy: magnitude_R0.7 - Epoch 24/1000: Train Loss=0.2656, Train Acc=90.56%, Val Loss=0.4309, Val Acc=85.34%\n",
      "Strategy: magnitude_R0.7 - Epoch 25/1000: Train Loss=0.2712, Train Acc=90.32%, Val Loss=0.4376, Val Acc=85.62%\n",
      "Strategy: magnitude_R0.7 - Epoch 26/1000: Train Loss=0.2707, Train Acc=90.40%, Val Loss=0.4339, Val Acc=85.42%\n",
      "Strategy: magnitude_R0.7 - Epoch 27/1000: Train Loss=0.2646, Train Acc=90.52%, Val Loss=0.4350, Val Acc=85.42%\n",
      "Strategy: magnitude_R0.7 - Epoch 28/1000: Train Loss=0.2583, Train Acc=90.72%, Val Loss=0.4329, Val Acc=85.50%\n",
      "Strategy: magnitude_R0.7 - Epoch 29/1000: Train Loss=0.2629, Train Acc=90.81%, Val Loss=0.4308, Val Acc=85.50%\n",
      "Strategy: magnitude_R0.7 - Epoch 30/1000: Train Loss=0.2583, Train Acc=90.83%, Val Loss=0.4349, Val Acc=85.42%\n",
      "Strategy: magnitude_R0.7 - Epoch 31/1000: Train Loss=0.2551, Train Acc=90.78%, Val Loss=0.4284, Val Acc=85.64%\n",
      "Strategy: magnitude_R0.7 - Epoch 32/1000: Train Loss=0.2531, Train Acc=91.06%, Val Loss=0.4356, Val Acc=85.52%\n",
      "Strategy: magnitude_R0.7 - Epoch 33/1000: Train Loss=0.2561, Train Acc=90.81%, Val Loss=0.4301, Val Acc=85.68%\n",
      "Strategy: magnitude_R0.7 - Epoch 34/1000: Train Loss=0.2547, Train Acc=90.97%, Val Loss=0.4387, Val Acc=85.40%\n",
      "Strategy: magnitude_R0.7 - Epoch 35/1000: Train Loss=0.2517, Train Acc=91.06%, Val Loss=0.4369, Val Acc=85.34%\n",
      "Strategy: magnitude_R0.7 - Epoch 36/1000: Train Loss=0.2496, Train Acc=90.94%, Val Loss=0.4410, Val Acc=85.46%\n",
      "Strategy: magnitude_R0.7 - Epoch 37/1000: Train Loss=0.2466, Train Acc=91.28%, Val Loss=0.4365, Val Acc=85.62%\n",
      "Strategy: magnitude_R0.7 - Epoch 38/1000: Train Loss=0.2455, Train Acc=91.22%, Val Loss=0.4350, Val Acc=85.50%\n",
      "Strategy: magnitude_R0.7 - Epoch 39/1000: Train Loss=0.2481, Train Acc=91.08%, Val Loss=0.4338, Val Acc=85.70%\n",
      "Early stopping triggered for 'magnitude_R0.7' after 39 epochs. No improvement in 'val_loss' for 20 epochs.\n",
      "Loading best model weights from epoch 19 with val_loss: 0.4275\n",
      "Training for 'magnitude_R0.7' finished. Loading best recorded model state with val_loss: 0.4275\n",
      "✅ Fine-tuning curves for magnitude_R0.7 saved.\n",
      "--- Evaluating Fine-tuned Model (magnitude @ Ratio 0.70) on TEST SET ---\n",
      "Metrics for 'magnitude' @ Ratio 0.70 (Fine-tuned, on Test Set): {'macs': 4540476.0, 'params': 868248, 'size_mib': 3.312103271484375, 'accuracy': 85.28, 'loss': 0.44854226808547976}\n",
      "✅ Model saved as ONNX to ./output_final_ratio_experiment/magnitude/model_R0.7_final.onnx\n",
      "\n",
      "\n",
      "--- Processing: Strategy 'magnitude', Ratio: 0.90 ---\n",
      "✅ Model loaded from ./output_final_ratio_experiment/mobilenetv2_initial_dense_trained.pth to cuda\n",
      "--- Pruning model with magnitude to ratio 0.90 ---\n",
      "Initial MACs before pruning for ratio 0.90: 0.006 G\n",
      "Applying MagnitudeImportance with target ratio: 0.90 using pruner's 5 iterative_steps.\n",
      "After pruning for ratio 0.90: MACs 0.004 G (Reduction: 30.36%)\n",
      "Metrics for 'magnitude' @ Ratio 0.90 (Pruned, Before FT, on Test Set): {'macs': 4220136.0, 'params': 791365, 'size_mib': 3.018817901611328, 'accuracy': 53.77, 'loss': 1.4468067863464356}\n",
      "--- Fine-tuning pruned model (magnitude @ Ratio 0.90) ---\n",
      "Strategy: magnitude_R0.9 - Epoch 1/1000: Train Loss=0.5519, Train Acc=81.02%, Val Loss=0.5110, Val Acc=81.68% (New best val_loss)\n",
      "Strategy: magnitude_R0.9 - Epoch 2/1000: Train Loss=0.4492, Train Acc=83.93%, Val Loss=0.4838, Val Acc=82.60% (New best val_loss)\n",
      "Strategy: magnitude_R0.9 - Epoch 3/1000: Train Loss=0.4177, Train Acc=85.02%, Val Loss=0.4646, Val Acc=83.34% (New best val_loss)\n",
      "Strategy: magnitude_R0.9 - Epoch 4/1000: Train Loss=0.3931, Train Acc=85.94%, Val Loss=0.4588, Val Acc=84.14% (New best val_loss)\n",
      "Strategy: magnitude_R0.9 - Epoch 5/1000: Train Loss=0.3796, Train Acc=86.52%, Val Loss=0.4508, Val Acc=84.32% (New best val_loss)\n",
      "Strategy: magnitude_R0.9 - Epoch 6/1000: Train Loss=0.3662, Train Acc=86.89%, Val Loss=0.4470, Val Acc=84.18% (New best val_loss)\n",
      "Strategy: magnitude_R0.9 - Epoch 7/1000: Train Loss=0.3577, Train Acc=87.23%, Val Loss=0.4438, Val Acc=84.42% (New best val_loss)\n",
      "Strategy: magnitude_R0.9 - Epoch 8/1000: Train Loss=0.3498, Train Acc=87.60%, Val Loss=0.4451, Val Acc=84.42%\n",
      "Strategy: magnitude_R0.9 - Epoch 9/1000: Train Loss=0.3444, Train Acc=87.83%, Val Loss=0.4421, Val Acc=84.26% (New best val_loss)\n",
      "Strategy: magnitude_R0.9 - Epoch 10/1000: Train Loss=0.3327, Train Acc=88.12%, Val Loss=0.4420, Val Acc=84.94% (New best val_loss)\n",
      "Strategy: magnitude_R0.9 - Epoch 11/1000: Train Loss=0.3260, Train Acc=88.50%, Val Loss=0.4397, Val Acc=84.84% (New best val_loss)\n",
      "Strategy: magnitude_R0.9 - Epoch 12/1000: Train Loss=0.3277, Train Acc=88.40%, Val Loss=0.4387, Val Acc=84.84% (New best val_loss)\n",
      "Strategy: magnitude_R0.9 - Epoch 13/1000: Train Loss=0.3207, Train Acc=88.55%, Val Loss=0.4382, Val Acc=84.58% (New best val_loss)\n",
      "Strategy: magnitude_R0.9 - Epoch 14/1000: Train Loss=0.3156, Train Acc=88.79%, Val Loss=0.4386, Val Acc=84.98%\n",
      "Strategy: magnitude_R0.9 - Epoch 15/1000: Train Loss=0.3135, Train Acc=88.93%, Val Loss=0.4316, Val Acc=85.14% (New best val_loss)\n",
      "Strategy: magnitude_R0.9 - Epoch 16/1000: Train Loss=0.3125, Train Acc=88.99%, Val Loss=0.4355, Val Acc=85.38%\n",
      "Strategy: magnitude_R0.9 - Epoch 17/1000: Train Loss=0.3072, Train Acc=89.12%, Val Loss=0.4326, Val Acc=85.30%\n",
      "Strategy: magnitude_R0.9 - Epoch 18/1000: Train Loss=0.3042, Train Acc=89.17%, Val Loss=0.4324, Val Acc=84.86%\n",
      "Strategy: magnitude_R0.9 - Epoch 19/1000: Train Loss=0.3052, Train Acc=89.18%, Val Loss=0.4314, Val Acc=85.24% (New best val_loss)\n",
      "Strategy: magnitude_R0.9 - Epoch 20/1000: Train Loss=0.3009, Train Acc=89.41%, Val Loss=0.4284, Val Acc=85.08% (New best val_loss)\n",
      "Strategy: magnitude_R0.9 - Epoch 21/1000: Train Loss=0.2946, Train Acc=89.34%, Val Loss=0.4303, Val Acc=85.34%\n",
      "Strategy: magnitude_R0.9 - Epoch 22/1000: Train Loss=0.2930, Train Acc=89.63%, Val Loss=0.4291, Val Acc=85.00%\n",
      "Strategy: magnitude_R0.9 - Epoch 23/1000: Train Loss=0.2891, Train Acc=89.75%, Val Loss=0.4219, Val Acc=85.34% (New best val_loss)\n",
      "Strategy: magnitude_R0.9 - Epoch 24/1000: Train Loss=0.2911, Train Acc=89.70%, Val Loss=0.4268, Val Acc=85.32%\n",
      "Strategy: magnitude_R0.9 - Epoch 25/1000: Train Loss=0.2859, Train Acc=89.85%, Val Loss=0.4256, Val Acc=85.32%\n",
      "Strategy: magnitude_R0.9 - Epoch 26/1000: Train Loss=0.2872, Train Acc=89.77%, Val Loss=0.4249, Val Acc=85.42%\n",
      "Strategy: magnitude_R0.9 - Epoch 27/1000: Train Loss=0.2825, Train Acc=89.94%, Val Loss=0.4268, Val Acc=85.44%\n",
      "Strategy: magnitude_R0.9 - Epoch 28/1000: Train Loss=0.2805, Train Acc=90.10%, Val Loss=0.4252, Val Acc=85.76%\n",
      "Strategy: magnitude_R0.9 - Epoch 29/1000: Train Loss=0.2779, Train Acc=90.17%, Val Loss=0.4256, Val Acc=85.70%\n",
      "Strategy: magnitude_R0.9 - Epoch 30/1000: Train Loss=0.2787, Train Acc=90.04%, Val Loss=0.4267, Val Acc=85.48%\n",
      "Strategy: magnitude_R0.9 - Epoch 31/1000: Train Loss=0.2752, Train Acc=90.22%, Val Loss=0.4281, Val Acc=85.42%\n",
      "Strategy: magnitude_R0.9 - Epoch 32/1000: Train Loss=0.2702, Train Acc=90.26%, Val Loss=0.4310, Val Acc=85.24%\n",
      "Strategy: magnitude_R0.9 - Epoch 33/1000: Train Loss=0.2712, Train Acc=90.32%, Val Loss=0.4320, Val Acc=85.42%\n",
      "Strategy: magnitude_R0.9 - Epoch 34/1000: Train Loss=0.2706, Train Acc=90.18%, Val Loss=0.4297, Val Acc=85.76%\n",
      "Strategy: magnitude_R0.9 - Epoch 35/1000: Train Loss=0.2645, Train Acc=90.51%, Val Loss=0.4355, Val Acc=85.24%\n",
      "Strategy: magnitude_R0.9 - Epoch 36/1000: Train Loss=0.2664, Train Acc=90.50%, Val Loss=0.4297, Val Acc=85.44%\n",
      "Strategy: magnitude_R0.9 - Epoch 37/1000: Train Loss=0.2606, Train Acc=90.77%, Val Loss=0.4344, Val Acc=85.22%\n",
      "Strategy: magnitude_R0.9 - Epoch 38/1000: Train Loss=0.2603, Train Acc=90.74%, Val Loss=0.4325, Val Acc=85.54%\n",
      "Strategy: magnitude_R0.9 - Epoch 39/1000: Train Loss=0.2612, Train Acc=90.67%, Val Loss=0.4318, Val Acc=85.80%\n",
      "Strategy: magnitude_R0.9 - Epoch 40/1000: Train Loss=0.2611, Train Acc=90.66%, Val Loss=0.4249, Val Acc=86.18%\n",
      "Strategy: magnitude_R0.9 - Epoch 41/1000: Train Loss=0.2583, Train Acc=90.79%, Val Loss=0.4348, Val Acc=85.82%\n",
      "Strategy: magnitude_R0.9 - Epoch 42/1000: Train Loss=0.2593, Train Acc=90.64%, Val Loss=0.4327, Val Acc=85.62%\n",
      "Strategy: magnitude_R0.9 - Epoch 43/1000: Train Loss=0.2596, Train Acc=90.57%, Val Loss=0.4323, Val Acc=86.02%\n",
      "Early stopping triggered for 'magnitude_R0.9' after 43 epochs. No improvement in 'val_loss' for 20 epochs.\n",
      "Loading best model weights from epoch 23 with val_loss: 0.4219\n",
      "Training for 'magnitude_R0.9' finished. Loading best recorded model state with val_loss: 0.4219\n",
      "✅ Fine-tuning curves for magnitude_R0.9 saved.\n",
      "--- Evaluating Fine-tuned Model (magnitude @ Ratio 0.90) on TEST SET ---\n",
      "Metrics for 'magnitude' @ Ratio 0.90 (Fine-tuned, on Test Set): {'macs': 4220136.0, 'params': 791365, 'size_mib': 3.018817901611328, 'accuracy': 85.15, 'loss': 0.4596526607990265}\n",
      "✅ Model saved as ONNX to ./output_final_ratio_experiment/magnitude/model_R0.9_final.onnx\n",
      "\n",
      "\n",
      "--- Processing: Strategy 'bn_scale', Ratio: 0.20 ---\n",
      "✅ Model loaded from ./output_final_ratio_experiment/mobilenetv2_initial_dense_trained.pth to cuda\n",
      "--- Pruning model with bn_scale to ratio 0.20 ---\n",
      "Initial MACs before pruning for ratio 0.20: 0.006 G\n",
      "Applying BNScaleImportance with target ratio: 0.20 using pruner's 5 iterative_steps.\n",
      "After pruning for ratio 0.20: MACs 0.006 G (Reduction: 8.36%)\n",
      "Metrics for 'bn_scale' @ Ratio 0.20 (Pruned, Before FT, on Test Set): {'macs': 5553441.0, 'params': 1076719, 'size_mib': 4.107357025146484, 'accuracy': 80.55, 'loss': 0.5774513246536255}\n",
      "--- Fine-tuning pruned model (bn_scale @ Ratio 0.20) ---\n",
      "Strategy: bn_scale_R0.2 - Epoch 1/1000: Train Loss=0.3349, Train Acc=88.18%, Val Loss=0.4285, Val Acc=84.96% (New best val_loss)\n",
      "Strategy: bn_scale_R0.2 - Epoch 2/1000: Train Loss=0.3063, Train Acc=89.29%, Val Loss=0.4174, Val Acc=85.46% (New best val_loss)\n",
      "Strategy: bn_scale_R0.2 - Epoch 3/1000: Train Loss=0.2916, Train Acc=89.58%, Val Loss=0.4193, Val Acc=85.38%\n",
      "Strategy: bn_scale_R0.2 - Epoch 4/1000: Train Loss=0.2807, Train Acc=90.12%, Val Loss=0.4164, Val Acc=85.72% (New best val_loss)\n",
      "Strategy: bn_scale_R0.2 - Epoch 5/1000: Train Loss=0.2725, Train Acc=90.32%, Val Loss=0.4127, Val Acc=85.92% (New best val_loss)\n",
      "Strategy: bn_scale_R0.2 - Epoch 6/1000: Train Loss=0.2649, Train Acc=90.56%, Val Loss=0.4207, Val Acc=86.04%\n",
      "Strategy: bn_scale_R0.2 - Epoch 7/1000: Train Loss=0.2645, Train Acc=90.65%, Val Loss=0.4123, Val Acc=86.14% (New best val_loss)\n",
      "Strategy: bn_scale_R0.2 - Epoch 8/1000: Train Loss=0.2658, Train Acc=90.56%, Val Loss=0.4125, Val Acc=85.88%\n",
      "Strategy: bn_scale_R0.2 - Epoch 9/1000: Train Loss=0.2587, Train Acc=90.75%, Val Loss=0.4140, Val Acc=86.00%\n",
      "Strategy: bn_scale_R0.2 - Epoch 10/1000: Train Loss=0.2515, Train Acc=90.97%, Val Loss=0.4114, Val Acc=86.00% (New best val_loss)\n",
      "Strategy: bn_scale_R0.2 - Epoch 11/1000: Train Loss=0.2518, Train Acc=91.14%, Val Loss=0.4161, Val Acc=85.78%\n",
      "Strategy: bn_scale_R0.2 - Epoch 12/1000: Train Loss=0.2491, Train Acc=91.09%, Val Loss=0.4110, Val Acc=86.02% (New best val_loss)\n",
      "Strategy: bn_scale_R0.2 - Epoch 13/1000: Train Loss=0.2481, Train Acc=91.16%, Val Loss=0.4140, Val Acc=86.08%\n",
      "Strategy: bn_scale_R0.2 - Epoch 14/1000: Train Loss=0.2383, Train Acc=91.61%, Val Loss=0.4194, Val Acc=86.12%\n",
      "Strategy: bn_scale_R0.2 - Epoch 15/1000: Train Loss=0.2416, Train Acc=91.50%, Val Loss=0.4182, Val Acc=86.30%\n",
      "Strategy: bn_scale_R0.2 - Epoch 16/1000: Train Loss=0.2389, Train Acc=91.54%, Val Loss=0.4053, Val Acc=86.32% (New best val_loss)\n",
      "Strategy: bn_scale_R0.2 - Epoch 17/1000: Train Loss=0.2353, Train Acc=91.43%, Val Loss=0.4116, Val Acc=86.24%\n",
      "Strategy: bn_scale_R0.2 - Epoch 18/1000: Train Loss=0.2339, Train Acc=91.74%, Val Loss=0.4089, Val Acc=86.52%\n",
      "Strategy: bn_scale_R0.2 - Epoch 19/1000: Train Loss=0.2320, Train Acc=91.80%, Val Loss=0.4166, Val Acc=86.02%\n",
      "Strategy: bn_scale_R0.2 - Epoch 20/1000: Train Loss=0.2305, Train Acc=91.79%, Val Loss=0.4108, Val Acc=86.62%\n",
      "Strategy: bn_scale_R0.2 - Epoch 21/1000: Train Loss=0.2285, Train Acc=91.75%, Val Loss=0.4147, Val Acc=86.32%\n",
      "Strategy: bn_scale_R0.2 - Epoch 22/1000: Train Loss=0.2275, Train Acc=91.84%, Val Loss=0.4182, Val Acc=86.06%\n",
      "Strategy: bn_scale_R0.2 - Epoch 23/1000: Train Loss=0.2243, Train Acc=91.87%, Val Loss=0.4207, Val Acc=86.42%\n",
      "Strategy: bn_scale_R0.2 - Epoch 24/1000: Train Loss=0.2260, Train Acc=91.98%, Val Loss=0.4252, Val Acc=86.06%\n",
      "Strategy: bn_scale_R0.2 - Epoch 25/1000: Train Loss=0.2235, Train Acc=91.98%, Val Loss=0.4196, Val Acc=86.10%\n",
      "Strategy: bn_scale_R0.2 - Epoch 26/1000: Train Loss=0.2212, Train Acc=92.18%, Val Loss=0.4176, Val Acc=86.26%\n",
      "Strategy: bn_scale_R0.2 - Epoch 27/1000: Train Loss=0.2227, Train Acc=92.10%, Val Loss=0.4229, Val Acc=86.16%\n",
      "Strategy: bn_scale_R0.2 - Epoch 28/1000: Train Loss=0.2178, Train Acc=92.13%, Val Loss=0.4195, Val Acc=86.20%\n",
      "Strategy: bn_scale_R0.2 - Epoch 29/1000: Train Loss=0.2171, Train Acc=92.17%, Val Loss=0.4173, Val Acc=86.06%\n",
      "Strategy: bn_scale_R0.2 - Epoch 30/1000: Train Loss=0.2150, Train Acc=92.33%, Val Loss=0.4211, Val Acc=86.16%\n",
      "Strategy: bn_scale_R0.2 - Epoch 31/1000: Train Loss=0.2174, Train Acc=92.32%, Val Loss=0.4230, Val Acc=86.18%\n",
      "Strategy: bn_scale_R0.2 - Epoch 32/1000: Train Loss=0.2148, Train Acc=92.33%, Val Loss=0.4235, Val Acc=86.26%\n",
      "Strategy: bn_scale_R0.2 - Epoch 33/1000: Train Loss=0.2164, Train Acc=92.29%, Val Loss=0.4201, Val Acc=86.30%\n",
      "Strategy: bn_scale_R0.2 - Epoch 34/1000: Train Loss=0.2096, Train Acc=92.57%, Val Loss=0.4312, Val Acc=86.14%\n",
      "Strategy: bn_scale_R0.2 - Epoch 35/1000: Train Loss=0.2131, Train Acc=92.38%, Val Loss=0.4253, Val Acc=86.36%\n",
      "Strategy: bn_scale_R0.2 - Epoch 36/1000: Train Loss=0.2106, Train Acc=92.40%, Val Loss=0.4281, Val Acc=86.24%\n",
      "Early stopping triggered for 'bn_scale_R0.2' after 36 epochs. No improvement in 'val_loss' for 20 epochs.\n",
      "Loading best model weights from epoch 16 with val_loss: 0.4053\n",
      "Training for 'bn_scale_R0.2' finished. Loading best recorded model state with val_loss: 0.4053\n",
      "✅ Fine-tuning curves for bn_scale_R0.2 saved.\n",
      "--- Evaluating Fine-tuned Model (bn_scale @ Ratio 0.20) on TEST SET ---\n",
      "Metrics for 'bn_scale' @ Ratio 0.20 (Fine-tuned, on Test Set): {'macs': 5553441.0, 'params': 1076719, 'size_mib': 4.107357025146484, 'accuracy': 86.7, 'loss': 0.434171857881546}\n",
      "✅ Model saved as ONNX to ./output_final_ratio_experiment/bn_scale/model_R0.2_final.onnx\n",
      "\n",
      "\n",
      "--- Processing: Strategy 'bn_scale', Ratio: 0.50 ---\n",
      "✅ Model loaded from ./output_final_ratio_experiment/mobilenetv2_initial_dense_trained.pth to cuda\n",
      "--- Pruning model with bn_scale to ratio 0.50 ---\n",
      "Initial MACs before pruning for ratio 0.50: 0.006 G\n",
      "Applying BNScaleImportance with target ratio: 0.50 using pruner's 5 iterative_steps.\n",
      "After pruning for ratio 0.50: MACs 0.005 G (Reduction: 18.74%)\n",
      "Metrics for 'bn_scale' @ Ratio 0.50 (Pruned, Before FT, on Test Set): {'macs': 4924394.0, 'params': 950314, 'size_mib': 3.6251602172851562, 'accuracy': 69.51, 'loss': 0.9363366092681885}\n",
      "--- Fine-tuning pruned model (bn_scale @ Ratio 0.50) ---\n",
      "Strategy: bn_scale_R0.5 - Epoch 1/1000: Train Loss=0.4238, Train Acc=85.05%, Val Loss=0.4619, Val Acc=83.68% (New best val_loss)\n",
      "Strategy: bn_scale_R0.5 - Epoch 2/1000: Train Loss=0.3690, Train Acc=86.99%, Val Loss=0.4456, Val Acc=84.26% (New best val_loss)\n",
      "Strategy: bn_scale_R0.5 - Epoch 3/1000: Train Loss=0.3485, Train Acc=87.61%, Val Loss=0.4410, Val Acc=84.18% (New best val_loss)\n",
      "Strategy: bn_scale_R0.5 - Epoch 4/1000: Train Loss=0.3311, Train Acc=88.25%, Val Loss=0.4382, Val Acc=84.78% (New best val_loss)\n",
      "Strategy: bn_scale_R0.5 - Epoch 5/1000: Train Loss=0.3217, Train Acc=88.68%, Val Loss=0.4369, Val Acc=84.64% (New best val_loss)\n",
      "Strategy: bn_scale_R0.5 - Epoch 6/1000: Train Loss=0.3141, Train Acc=88.86%, Val Loss=0.4370, Val Acc=84.90%\n",
      "Strategy: bn_scale_R0.5 - Epoch 7/1000: Train Loss=0.3036, Train Acc=89.34%, Val Loss=0.4286, Val Acc=85.00% (New best val_loss)\n",
      "Strategy: bn_scale_R0.5 - Epoch 8/1000: Train Loss=0.3002, Train Acc=89.33%, Val Loss=0.4359, Val Acc=85.36%\n",
      "Strategy: bn_scale_R0.5 - Epoch 9/1000: Train Loss=0.2990, Train Acc=89.35%, Val Loss=0.4361, Val Acc=84.68%\n",
      "Strategy: bn_scale_R0.5 - Epoch 10/1000: Train Loss=0.2892, Train Acc=89.62%, Val Loss=0.4284, Val Acc=84.96% (New best val_loss)\n",
      "Strategy: bn_scale_R0.5 - Epoch 11/1000: Train Loss=0.2892, Train Acc=89.72%, Val Loss=0.4364, Val Acc=85.06%\n",
      "Strategy: bn_scale_R0.5 - Epoch 12/1000: Train Loss=0.2813, Train Acc=90.02%, Val Loss=0.4355, Val Acc=85.22%\n",
      "Strategy: bn_scale_R0.5 - Epoch 13/1000: Train Loss=0.2784, Train Acc=90.13%, Val Loss=0.4405, Val Acc=84.88%\n",
      "Strategy: bn_scale_R0.5 - Epoch 14/1000: Train Loss=0.2738, Train Acc=90.26%, Val Loss=0.4383, Val Acc=85.36%\n",
      "Strategy: bn_scale_R0.5 - Epoch 15/1000: Train Loss=0.2724, Train Acc=90.26%, Val Loss=0.4394, Val Acc=85.06%\n",
      "Strategy: bn_scale_R0.5 - Epoch 16/1000: Train Loss=0.2692, Train Acc=90.42%, Val Loss=0.4479, Val Acc=85.10%\n",
      "Strategy: bn_scale_R0.5 - Epoch 17/1000: Train Loss=0.2721, Train Acc=90.26%, Val Loss=0.4371, Val Acc=85.36%\n",
      "Strategy: bn_scale_R0.5 - Epoch 18/1000: Train Loss=0.2649, Train Acc=90.58%, Val Loss=0.4362, Val Acc=85.26%\n",
      "Strategy: bn_scale_R0.5 - Epoch 19/1000: Train Loss=0.2598, Train Acc=90.70%, Val Loss=0.4344, Val Acc=85.62%\n",
      "Strategy: bn_scale_R0.5 - Epoch 20/1000: Train Loss=0.2570, Train Acc=90.86%, Val Loss=0.4431, Val Acc=85.18%\n",
      "Strategy: bn_scale_R0.5 - Epoch 21/1000: Train Loss=0.2572, Train Acc=90.85%, Val Loss=0.4423, Val Acc=85.24%\n",
      "Strategy: bn_scale_R0.5 - Epoch 22/1000: Train Loss=0.2610, Train Acc=90.64%, Val Loss=0.4366, Val Acc=85.38%\n",
      "Strategy: bn_scale_R0.5 - Epoch 23/1000: Train Loss=0.2579, Train Acc=90.74%, Val Loss=0.4402, Val Acc=85.62%\n",
      "Strategy: bn_scale_R0.5 - Epoch 24/1000: Train Loss=0.2531, Train Acc=90.91%, Val Loss=0.4444, Val Acc=85.38%\n",
      "Strategy: bn_scale_R0.5 - Epoch 25/1000: Train Loss=0.2499, Train Acc=91.03%, Val Loss=0.4445, Val Acc=85.28%\n",
      "Strategy: bn_scale_R0.5 - Epoch 26/1000: Train Loss=0.2465, Train Acc=91.33%, Val Loss=0.4430, Val Acc=85.54%\n",
      "Strategy: bn_scale_R0.5 - Epoch 27/1000: Train Loss=0.2491, Train Acc=91.06%, Val Loss=0.4434, Val Acc=85.40%\n",
      "Strategy: bn_scale_R0.5 - Epoch 28/1000: Train Loss=0.2449, Train Acc=91.34%, Val Loss=0.4392, Val Acc=85.90%\n",
      "Strategy: bn_scale_R0.5 - Epoch 29/1000: Train Loss=0.2438, Train Acc=91.29%, Val Loss=0.4442, Val Acc=85.66%\n",
      "Strategy: bn_scale_R0.5 - Epoch 30/1000: Train Loss=0.2438, Train Acc=91.20%, Val Loss=0.4417, Val Acc=85.32%\n",
      "Early stopping triggered for 'bn_scale_R0.5' after 30 epochs. No improvement in 'val_loss' for 20 epochs.\n",
      "Loading best model weights from epoch 10 with val_loss: 0.4284\n",
      "Training for 'bn_scale_R0.5' finished. Loading best recorded model state with val_loss: 0.4284\n",
      "✅ Fine-tuning curves for bn_scale_R0.5 saved.\n",
      "--- Evaluating Fine-tuned Model (bn_scale @ Ratio 0.50) on TEST SET ---\n",
      "Metrics for 'bn_scale' @ Ratio 0.50 (Fine-tuned, on Test Set): {'macs': 4924394.0, 'params': 950314, 'size_mib': 3.6251602172851562, 'accuracy': 85.59, 'loss': 0.4489218177318573}\n",
      "✅ Model saved as ONNX to ./output_final_ratio_experiment/bn_scale/model_R0.5_final.onnx\n",
      "\n",
      "\n",
      "--- Processing: Strategy 'bn_scale', Ratio: 0.70 ---\n",
      "✅ Model loaded from ./output_final_ratio_experiment/mobilenetv2_initial_dense_trained.pth to cuda\n",
      "--- Pruning model with bn_scale to ratio 0.70 ---\n",
      "Initial MACs before pruning for ratio 0.70: 0.006 G\n",
      "Applying BNScaleImportance with target ratio: 0.70 using pruner's 5 iterative_steps.\n",
      "After pruning for ratio 0.70: MACs 0.005 G (Reduction: 25.07%)\n",
      "Metrics for 'bn_scale' @ Ratio 0.70 (Pruned, Before FT, on Test Set): {'macs': 4540476.0, 'params': 868248, 'size_mib': 3.312103271484375, 'accuracy': 50.96, 'loss': 1.6079097476959228}\n",
      "--- Fine-tuning pruned model (bn_scale @ Ratio 0.70) ---\n",
      "Strategy: bn_scale_R0.7 - Epoch 1/1000: Train Loss=0.5017, Train Acc=82.54%, Val Loss=0.4840, Val Acc=82.88% (New best val_loss)\n",
      "Strategy: bn_scale_R0.7 - Epoch 2/1000: Train Loss=0.4175, Train Acc=85.21%, Val Loss=0.4587, Val Acc=83.64% (New best val_loss)\n",
      "Strategy: bn_scale_R0.7 - Epoch 3/1000: Train Loss=0.3896, Train Acc=86.19%, Val Loss=0.4513, Val Acc=84.40% (New best val_loss)\n",
      "Strategy: bn_scale_R0.7 - Epoch 4/1000: Train Loss=0.3727, Train Acc=86.81%, Val Loss=0.4442, Val Acc=84.20% (New best val_loss)\n",
      "Strategy: bn_scale_R0.7 - Epoch 5/1000: Train Loss=0.3576, Train Acc=87.33%, Val Loss=0.4375, Val Acc=84.56% (New best val_loss)\n",
      "Strategy: bn_scale_R0.7 - Epoch 6/1000: Train Loss=0.3524, Train Acc=87.52%, Val Loss=0.4338, Val Acc=84.70% (New best val_loss)\n",
      "Strategy: bn_scale_R0.7 - Epoch 7/1000: Train Loss=0.3395, Train Acc=88.00%, Val Loss=0.4338, Val Acc=84.78%\n",
      "Strategy: bn_scale_R0.7 - Epoch 8/1000: Train Loss=0.3332, Train Acc=88.10%, Val Loss=0.4281, Val Acc=84.82% (New best val_loss)\n",
      "Strategy: bn_scale_R0.7 - Epoch 9/1000: Train Loss=0.3233, Train Acc=88.70%, Val Loss=0.4353, Val Acc=84.74%\n",
      "Strategy: bn_scale_R0.7 - Epoch 10/1000: Train Loss=0.3203, Train Acc=88.58%, Val Loss=0.4355, Val Acc=84.38%\n",
      "Strategy: bn_scale_R0.7 - Epoch 11/1000: Train Loss=0.3156, Train Acc=88.75%, Val Loss=0.4326, Val Acc=84.60%\n",
      "Strategy: bn_scale_R0.7 - Epoch 12/1000: Train Loss=0.3127, Train Acc=88.90%, Val Loss=0.4306, Val Acc=85.00%\n",
      "Strategy: bn_scale_R0.7 - Epoch 13/1000: Train Loss=0.3069, Train Acc=89.02%, Val Loss=0.4325, Val Acc=85.06%\n",
      "Strategy: bn_scale_R0.7 - Epoch 14/1000: Train Loss=0.3020, Train Acc=89.26%, Val Loss=0.4268, Val Acc=85.06% (New best val_loss)\n",
      "Strategy: bn_scale_R0.7 - Epoch 15/1000: Train Loss=0.2993, Train Acc=89.40%, Val Loss=0.4324, Val Acc=85.10%\n",
      "Strategy: bn_scale_R0.7 - Epoch 16/1000: Train Loss=0.2944, Train Acc=89.56%, Val Loss=0.4387, Val Acc=85.14%\n",
      "Strategy: bn_scale_R0.7 - Epoch 17/1000: Train Loss=0.2938, Train Acc=89.39%, Val Loss=0.4321, Val Acc=85.18%\n",
      "Strategy: bn_scale_R0.7 - Epoch 18/1000: Train Loss=0.2931, Train Acc=89.63%, Val Loss=0.4255, Val Acc=85.28% (New best val_loss)\n",
      "Strategy: bn_scale_R0.7 - Epoch 19/1000: Train Loss=0.2887, Train Acc=89.76%, Val Loss=0.4247, Val Acc=85.30% (New best val_loss)\n",
      "Strategy: bn_scale_R0.7 - Epoch 20/1000: Train Loss=0.2862, Train Acc=89.82%, Val Loss=0.4258, Val Acc=85.50%\n",
      "Strategy: bn_scale_R0.7 - Epoch 21/1000: Train Loss=0.2793, Train Acc=90.02%, Val Loss=0.4303, Val Acc=85.76%\n",
      "Strategy: bn_scale_R0.7 - Epoch 22/1000: Train Loss=0.2834, Train Acc=89.74%, Val Loss=0.4270, Val Acc=85.72%\n",
      "Strategy: bn_scale_R0.7 - Epoch 23/1000: Train Loss=0.2825, Train Acc=89.83%, Val Loss=0.4275, Val Acc=85.42%\n",
      "Strategy: bn_scale_R0.7 - Epoch 24/1000: Train Loss=0.2763, Train Acc=90.22%, Val Loss=0.4264, Val Acc=85.92%\n",
      "Strategy: bn_scale_R0.7 - Epoch 25/1000: Train Loss=0.2789, Train Acc=90.18%, Val Loss=0.4280, Val Acc=85.94%\n",
      "Strategy: bn_scale_R0.7 - Epoch 26/1000: Train Loss=0.2708, Train Acc=90.47%, Val Loss=0.4280, Val Acc=85.52%\n",
      "Strategy: bn_scale_R0.7 - Epoch 27/1000: Train Loss=0.2655, Train Acc=90.57%, Val Loss=0.4349, Val Acc=85.48%\n",
      "Strategy: bn_scale_R0.7 - Epoch 28/1000: Train Loss=0.2679, Train Acc=90.48%, Val Loss=0.4263, Val Acc=86.00%\n",
      "Strategy: bn_scale_R0.7 - Epoch 29/1000: Train Loss=0.2661, Train Acc=90.40%, Val Loss=0.4294, Val Acc=85.68%\n",
      "Strategy: bn_scale_R0.7 - Epoch 30/1000: Train Loss=0.2670, Train Acc=90.62%, Val Loss=0.4287, Val Acc=85.82%\n",
      "Strategy: bn_scale_R0.7 - Epoch 31/1000: Train Loss=0.2650, Train Acc=90.47%, Val Loss=0.4416, Val Acc=85.68%\n",
      "Strategy: bn_scale_R0.7 - Epoch 32/1000: Train Loss=0.2608, Train Acc=90.67%, Val Loss=0.4331, Val Acc=85.58%\n",
      "Strategy: bn_scale_R0.7 - Epoch 33/1000: Train Loss=0.2609, Train Acc=90.66%, Val Loss=0.4327, Val Acc=85.70%\n",
      "Strategy: bn_scale_R0.7 - Epoch 34/1000: Train Loss=0.2539, Train Acc=90.89%, Val Loss=0.4348, Val Acc=85.64%\n",
      "Strategy: bn_scale_R0.7 - Epoch 35/1000: Train Loss=0.2579, Train Acc=90.72%, Val Loss=0.4400, Val Acc=85.50%\n",
      "Strategy: bn_scale_R0.7 - Epoch 36/1000: Train Loss=0.2550, Train Acc=90.85%, Val Loss=0.4335, Val Acc=85.84%\n",
      "Strategy: bn_scale_R0.7 - Epoch 37/1000: Train Loss=0.2472, Train Acc=91.14%, Val Loss=0.4311, Val Acc=85.70%\n",
      "Strategy: bn_scale_R0.7 - Epoch 38/1000: Train Loss=0.2550, Train Acc=90.90%, Val Loss=0.4297, Val Acc=85.50%\n",
      "Strategy: bn_scale_R0.7 - Epoch 39/1000: Train Loss=0.2528, Train Acc=90.89%, Val Loss=0.4273, Val Acc=85.32%\n",
      "Early stopping triggered for 'bn_scale_R0.7' after 39 epochs. No improvement in 'val_loss' for 20 epochs.\n",
      "Loading best model weights from epoch 19 with val_loss: 0.4247\n",
      "Training for 'bn_scale_R0.7' finished. Loading best recorded model state with val_loss: 0.4247\n",
      "✅ Fine-tuning curves for bn_scale_R0.7 saved.\n",
      "--- Evaluating Fine-tuned Model (bn_scale @ Ratio 0.70) on TEST SET ---\n",
      "Metrics for 'bn_scale' @ Ratio 0.70 (Fine-tuned, on Test Set): {'macs': 4540476.0, 'params': 868248, 'size_mib': 3.312103271484375, 'accuracy': 85.04, 'loss': 0.4576197726249695}\n",
      "✅ Model saved as ONNX to ./output_final_ratio_experiment/bn_scale/model_R0.7_final.onnx\n",
      "\n",
      "\n",
      "--- Processing: Strategy 'bn_scale', Ratio: 0.90 ---\n",
      "✅ Model loaded from ./output_final_ratio_experiment/mobilenetv2_initial_dense_trained.pth to cuda\n",
      "--- Pruning model with bn_scale to ratio 0.90 ---\n",
      "Initial MACs before pruning for ratio 0.90: 0.006 G\n",
      "Applying BNScaleImportance with target ratio: 0.90 using pruner's 5 iterative_steps.\n",
      "After pruning for ratio 0.90: MACs 0.004 G (Reduction: 30.36%)\n",
      "Metrics for 'bn_scale' @ Ratio 0.90 (Pruned, Before FT, on Test Set): {'macs': 4220136.0, 'params': 791365, 'size_mib': 3.018817901611328, 'accuracy': 48.02, 'loss': 1.6747969533920288}\n",
      "--- Fine-tuning pruned model (bn_scale @ Ratio 0.90) ---\n",
      "Strategy: bn_scale_R0.9 - Epoch 1/1000: Train Loss=0.5796, Train Acc=80.11%, Val Loss=0.5287, Val Acc=81.22% (New best val_loss)\n",
      "Strategy: bn_scale_R0.9 - Epoch 2/1000: Train Loss=0.4721, Train Acc=83.38%, Val Loss=0.4909, Val Acc=82.58% (New best val_loss)\n",
      "Strategy: bn_scale_R0.9 - Epoch 3/1000: Train Loss=0.4303, Train Acc=84.83%, Val Loss=0.4696, Val Acc=82.90% (New best val_loss)\n",
      "Strategy: bn_scale_R0.9 - Epoch 4/1000: Train Loss=0.4083, Train Acc=85.54%, Val Loss=0.4625, Val Acc=83.48% (New best val_loss)\n",
      "Strategy: bn_scale_R0.9 - Epoch 5/1000: Train Loss=0.3877, Train Acc=86.38%, Val Loss=0.4570, Val Acc=83.50% (New best val_loss)\n",
      "Strategy: bn_scale_R0.9 - Epoch 6/1000: Train Loss=0.3823, Train Acc=86.55%, Val Loss=0.4520, Val Acc=83.98% (New best val_loss)\n",
      "Strategy: bn_scale_R0.9 - Epoch 7/1000: Train Loss=0.3687, Train Acc=87.01%, Val Loss=0.4478, Val Acc=84.04% (New best val_loss)\n",
      "Strategy: bn_scale_R0.9 - Epoch 8/1000: Train Loss=0.3587, Train Acc=87.37%, Val Loss=0.4470, Val Acc=83.72% (New best val_loss)\n",
      "Strategy: bn_scale_R0.9 - Epoch 9/1000: Train Loss=0.3514, Train Acc=87.38%, Val Loss=0.4466, Val Acc=84.02% (New best val_loss)\n",
      "Strategy: bn_scale_R0.9 - Epoch 10/1000: Train Loss=0.3495, Train Acc=87.48%, Val Loss=0.4435, Val Acc=84.54% (New best val_loss)\n",
      "Strategy: bn_scale_R0.9 - Epoch 11/1000: Train Loss=0.3365, Train Acc=88.01%, Val Loss=0.4397, Val Acc=84.42% (New best val_loss)\n",
      "Strategy: bn_scale_R0.9 - Epoch 12/1000: Train Loss=0.3351, Train Acc=88.00%, Val Loss=0.4384, Val Acc=84.80% (New best val_loss)\n",
      "Strategy: bn_scale_R0.9 - Epoch 13/1000: Train Loss=0.3296, Train Acc=88.13%, Val Loss=0.4459, Val Acc=84.56%\n",
      "Strategy: bn_scale_R0.9 - Epoch 14/1000: Train Loss=0.3253, Train Acc=88.51%, Val Loss=0.4407, Val Acc=84.62%\n",
      "Strategy: bn_scale_R0.9 - Epoch 15/1000: Train Loss=0.3239, Train Acc=88.47%, Val Loss=0.4467, Val Acc=84.28%\n",
      "Strategy: bn_scale_R0.9 - Epoch 16/1000: Train Loss=0.3180, Train Acc=88.64%, Val Loss=0.4376, Val Acc=84.68% (New best val_loss)\n",
      "Strategy: bn_scale_R0.9 - Epoch 17/1000: Train Loss=0.3119, Train Acc=88.86%, Val Loss=0.4388, Val Acc=84.88%\n",
      "Strategy: bn_scale_R0.9 - Epoch 18/1000: Train Loss=0.3121, Train Acc=88.86%, Val Loss=0.4386, Val Acc=84.70%\n",
      "Strategy: bn_scale_R0.9 - Epoch 19/1000: Train Loss=0.3076, Train Acc=89.13%, Val Loss=0.4380, Val Acc=84.84%\n",
      "Strategy: bn_scale_R0.9 - Epoch 20/1000: Train Loss=0.3058, Train Acc=88.96%, Val Loss=0.4392, Val Acc=84.74%\n",
      "Strategy: bn_scale_R0.9 - Epoch 21/1000: Train Loss=0.3026, Train Acc=89.17%, Val Loss=0.4339, Val Acc=85.02% (New best val_loss)\n",
      "Strategy: bn_scale_R0.9 - Epoch 22/1000: Train Loss=0.2970, Train Acc=89.40%, Val Loss=0.4308, Val Acc=85.22% (New best val_loss)\n",
      "Strategy: bn_scale_R0.9 - Epoch 23/1000: Train Loss=0.2951, Train Acc=89.37%, Val Loss=0.4297, Val Acc=84.96% (New best val_loss)\n",
      "Strategy: bn_scale_R0.9 - Epoch 24/1000: Train Loss=0.2926, Train Acc=89.58%, Val Loss=0.4376, Val Acc=85.12%\n",
      "Strategy: bn_scale_R0.9 - Epoch 25/1000: Train Loss=0.2918, Train Acc=89.61%, Val Loss=0.4367, Val Acc=84.90%\n",
      "Strategy: bn_scale_R0.9 - Epoch 26/1000: Train Loss=0.2891, Train Acc=89.70%, Val Loss=0.4369, Val Acc=84.70%\n",
      "Strategy: bn_scale_R0.9 - Epoch 27/1000: Train Loss=0.2889, Train Acc=89.72%, Val Loss=0.4383, Val Acc=84.60%\n",
      "Strategy: bn_scale_R0.9 - Epoch 28/1000: Train Loss=0.2861, Train Acc=89.84%, Val Loss=0.4380, Val Acc=84.88%\n",
      "Strategy: bn_scale_R0.9 - Epoch 29/1000: Train Loss=0.2850, Train Acc=89.88%, Val Loss=0.4421, Val Acc=85.26%\n",
      "Strategy: bn_scale_R0.9 - Epoch 30/1000: Train Loss=0.2845, Train Acc=89.82%, Val Loss=0.4358, Val Acc=85.10%\n",
      "Strategy: bn_scale_R0.9 - Epoch 31/1000: Train Loss=0.2773, Train Acc=90.14%, Val Loss=0.4393, Val Acc=85.02%\n",
      "Strategy: bn_scale_R0.9 - Epoch 32/1000: Train Loss=0.2811, Train Acc=89.90%, Val Loss=0.4424, Val Acc=85.06%\n",
      "Strategy: bn_scale_R0.9 - Epoch 33/1000: Train Loss=0.2762, Train Acc=90.14%, Val Loss=0.4374, Val Acc=85.26%\n",
      "Strategy: bn_scale_R0.9 - Epoch 34/1000: Train Loss=0.2753, Train Acc=90.07%, Val Loss=0.4353, Val Acc=85.36%\n",
      "Strategy: bn_scale_R0.9 - Epoch 35/1000: Train Loss=0.2716, Train Acc=90.15%, Val Loss=0.4386, Val Acc=85.58%\n",
      "Strategy: bn_scale_R0.9 - Epoch 36/1000: Train Loss=0.2718, Train Acc=90.36%, Val Loss=0.4342, Val Acc=85.60%\n",
      "Strategy: bn_scale_R0.9 - Epoch 37/1000: Train Loss=0.2684, Train Acc=90.48%, Val Loss=0.4354, Val Acc=85.38%\n",
      "Strategy: bn_scale_R0.9 - Epoch 38/1000: Train Loss=0.2687, Train Acc=90.49%, Val Loss=0.4390, Val Acc=85.46%\n",
      "Strategy: bn_scale_R0.9 - Epoch 39/1000: Train Loss=0.2676, Train Acc=90.32%, Val Loss=0.4364, Val Acc=85.50%\n",
      "Strategy: bn_scale_R0.9 - Epoch 40/1000: Train Loss=0.2639, Train Acc=90.55%, Val Loss=0.4471, Val Acc=85.22%\n",
      "Strategy: bn_scale_R0.9 - Epoch 41/1000: Train Loss=0.2628, Train Acc=90.64%, Val Loss=0.4414, Val Acc=85.24%\n",
      "Strategy: bn_scale_R0.9 - Epoch 42/1000: Train Loss=0.2629, Train Acc=90.78%, Val Loss=0.4371, Val Acc=85.52%\n",
      "Strategy: bn_scale_R0.9 - Epoch 43/1000: Train Loss=0.2590, Train Acc=90.73%, Val Loss=0.4408, Val Acc=85.46%\n",
      "Early stopping triggered for 'bn_scale_R0.9' after 43 epochs. No improvement in 'val_loss' for 20 epochs.\n",
      "Loading best model weights from epoch 23 with val_loss: 0.4297\n",
      "Training for 'bn_scale_R0.9' finished. Loading best recorded model state with val_loss: 0.4297\n",
      "✅ Fine-tuning curves for bn_scale_R0.9 saved.\n",
      "--- Evaluating Fine-tuned Model (bn_scale @ Ratio 0.90) on TEST SET ---\n",
      "Metrics for 'bn_scale' @ Ratio 0.90 (Fine-tuned, on Test Set): {'macs': 4220136.0, 'params': 791365, 'size_mib': 3.018817901611328, 'accuracy': 85.54, 'loss': 0.45157094078063964}\n",
      "✅ Model saved as ONNX to ./output_final_ratio_experiment/bn_scale/model_R0.9_final.onnx\n",
      "\n",
      "\n",
      "--- Processing: Strategy 'random', Ratio: 0.20 ---\n",
      "✅ Model loaded from ./output_final_ratio_experiment/mobilenetv2_initial_dense_trained.pth to cuda\n",
      "--- Pruning model with random to ratio 0.20 ---\n",
      "Initial MACs before pruning for ratio 0.20: 0.006 G\n",
      "Applying RandomImportance with target ratio: 0.20 using pruner's 5 iterative_steps.\n",
      "After pruning for ratio 0.20: MACs 0.006 G (Reduction: 8.36%)\n",
      "Metrics for 'random' @ Ratio 0.20 (Pruned, Before FT, on Test Set): {'macs': 5553441.0, 'params': 1076719, 'size_mib': 4.107357025146484, 'accuracy': 69.43, 'loss': 0.9254887104034424}\n",
      "--- Fine-tuning pruned model (random @ Ratio 0.20) ---\n",
      "Strategy: random_R0.2 - Epoch 1/1000: Train Loss=0.4560, Train Acc=84.26%, Val Loss=0.4824, Val Acc=83.28% (New best val_loss)\n",
      "Strategy: random_R0.2 - Epoch 2/1000: Train Loss=0.3839, Train Acc=86.36%, Val Loss=0.4632, Val Acc=84.26% (New best val_loss)\n",
      "Strategy: random_R0.2 - Epoch 3/1000: Train Loss=0.3571, Train Acc=87.25%, Val Loss=0.4524, Val Acc=84.72% (New best val_loss)\n",
      "Strategy: random_R0.2 - Epoch 4/1000: Train Loss=0.3422, Train Acc=88.00%, Val Loss=0.4479, Val Acc=84.58% (New best val_loss)\n",
      "Strategy: random_R0.2 - Epoch 5/1000: Train Loss=0.3327, Train Acc=88.24%, Val Loss=0.4370, Val Acc=85.46% (New best val_loss)\n",
      "Strategy: random_R0.2 - Epoch 6/1000: Train Loss=0.3193, Train Acc=88.79%, Val Loss=0.4357, Val Acc=85.58% (New best val_loss)\n",
      "Strategy: random_R0.2 - Epoch 7/1000: Train Loss=0.3112, Train Acc=89.02%, Val Loss=0.4346, Val Acc=85.38% (New best val_loss)\n",
      "Strategy: random_R0.2 - Epoch 8/1000: Train Loss=0.3085, Train Acc=89.27%, Val Loss=0.4270, Val Acc=85.72% (New best val_loss)\n",
      "Strategy: random_R0.2 - Epoch 9/1000: Train Loss=0.3030, Train Acc=89.26%, Val Loss=0.4281, Val Acc=85.84%\n",
      "Strategy: random_R0.2 - Epoch 10/1000: Train Loss=0.2953, Train Acc=89.64%, Val Loss=0.4288, Val Acc=85.30%\n",
      "Strategy: random_R0.2 - Epoch 11/1000: Train Loss=0.2897, Train Acc=89.78%, Val Loss=0.4319, Val Acc=85.36%\n",
      "Strategy: random_R0.2 - Epoch 12/1000: Train Loss=0.2831, Train Acc=89.94%, Val Loss=0.4331, Val Acc=85.50%\n",
      "Strategy: random_R0.2 - Epoch 13/1000: Train Loss=0.2826, Train Acc=90.04%, Val Loss=0.4325, Val Acc=85.14%\n",
      "Strategy: random_R0.2 - Epoch 14/1000: Train Loss=0.2737, Train Acc=90.18%, Val Loss=0.4286, Val Acc=85.38%\n",
      "Strategy: random_R0.2 - Epoch 15/1000: Train Loss=0.2767, Train Acc=90.26%, Val Loss=0.4281, Val Acc=85.68%\n",
      "Strategy: random_R0.2 - Epoch 16/1000: Train Loss=0.2740, Train Acc=90.17%, Val Loss=0.4315, Val Acc=85.16%\n",
      "Strategy: random_R0.2 - Epoch 17/1000: Train Loss=0.2649, Train Acc=90.53%, Val Loss=0.4320, Val Acc=85.66%\n",
      "Strategy: random_R0.2 - Epoch 18/1000: Train Loss=0.2669, Train Acc=90.63%, Val Loss=0.4304, Val Acc=85.88%\n",
      "Strategy: random_R0.2 - Epoch 19/1000: Train Loss=0.2606, Train Acc=90.73%, Val Loss=0.4356, Val Acc=85.74%\n",
      "Strategy: random_R0.2 - Epoch 20/1000: Train Loss=0.2575, Train Acc=90.77%, Val Loss=0.4257, Val Acc=85.84% (New best val_loss)\n",
      "Strategy: random_R0.2 - Epoch 21/1000: Train Loss=0.2615, Train Acc=90.65%, Val Loss=0.4265, Val Acc=85.86%\n",
      "Strategy: random_R0.2 - Epoch 22/1000: Train Loss=0.2548, Train Acc=90.88%, Val Loss=0.4298, Val Acc=85.86%\n",
      "Strategy: random_R0.2 - Epoch 23/1000: Train Loss=0.2569, Train Acc=90.80%, Val Loss=0.4313, Val Acc=85.76%\n",
      "Strategy: random_R0.2 - Epoch 24/1000: Train Loss=0.2537, Train Acc=91.10%, Val Loss=0.4359, Val Acc=85.48%\n",
      "Strategy: random_R0.2 - Epoch 25/1000: Train Loss=0.2479, Train Acc=91.12%, Val Loss=0.4342, Val Acc=85.54%\n",
      "Strategy: random_R0.2 - Epoch 26/1000: Train Loss=0.2467, Train Acc=91.22%, Val Loss=0.4303, Val Acc=85.78%\n",
      "Strategy: random_R0.2 - Epoch 27/1000: Train Loss=0.2480, Train Acc=91.07%, Val Loss=0.4241, Val Acc=85.96% (New best val_loss)\n",
      "Strategy: random_R0.2 - Epoch 28/1000: Train Loss=0.2440, Train Acc=91.30%, Val Loss=0.4299, Val Acc=85.94%\n",
      "Strategy: random_R0.2 - Epoch 29/1000: Train Loss=0.2403, Train Acc=91.52%, Val Loss=0.4279, Val Acc=85.98%\n",
      "Strategy: random_R0.2 - Epoch 30/1000: Train Loss=0.2383, Train Acc=91.46%, Val Loss=0.4269, Val Acc=85.78%\n",
      "Strategy: random_R0.2 - Epoch 31/1000: Train Loss=0.2398, Train Acc=91.45%, Val Loss=0.4323, Val Acc=85.60%\n",
      "Strategy: random_R0.2 - Epoch 32/1000: Train Loss=0.2402, Train Acc=91.46%, Val Loss=0.4263, Val Acc=85.84%\n",
      "Strategy: random_R0.2 - Epoch 33/1000: Train Loss=0.2344, Train Acc=91.54%, Val Loss=0.4250, Val Acc=86.30%\n",
      "Strategy: random_R0.2 - Epoch 34/1000: Train Loss=0.2354, Train Acc=91.56%, Val Loss=0.4241, Val Acc=86.08%\n",
      "Strategy: random_R0.2 - Epoch 35/1000: Train Loss=0.2326, Train Acc=91.77%, Val Loss=0.4373, Val Acc=85.80%\n",
      "Strategy: random_R0.2 - Epoch 36/1000: Train Loss=0.2337, Train Acc=91.60%, Val Loss=0.4312, Val Acc=85.88%\n",
      "Strategy: random_R0.2 - Epoch 37/1000: Train Loss=0.2329, Train Acc=91.67%, Val Loss=0.4277, Val Acc=86.02%\n",
      "Strategy: random_R0.2 - Epoch 38/1000: Train Loss=0.2253, Train Acc=91.90%, Val Loss=0.4261, Val Acc=86.04%\n",
      "Strategy: random_R0.2 - Epoch 39/1000: Train Loss=0.2296, Train Acc=91.77%, Val Loss=0.4258, Val Acc=86.06%\n",
      "Strategy: random_R0.2 - Epoch 40/1000: Train Loss=0.2305, Train Acc=91.73%, Val Loss=0.4251, Val Acc=86.24%\n",
      "Strategy: random_R0.2 - Epoch 41/1000: Train Loss=0.2267, Train Acc=91.90%, Val Loss=0.4273, Val Acc=86.16%\n",
      "Strategy: random_R0.2 - Epoch 42/1000: Train Loss=0.2246, Train Acc=91.91%, Val Loss=0.4309, Val Acc=86.04%\n",
      "Strategy: random_R0.2 - Epoch 43/1000: Train Loss=0.2234, Train Acc=91.98%, Val Loss=0.4332, Val Acc=86.32%\n",
      "Strategy: random_R0.2 - Epoch 44/1000: Train Loss=0.2237, Train Acc=92.00%, Val Loss=0.4406, Val Acc=85.94%\n",
      "Strategy: random_R0.2 - Epoch 45/1000: Train Loss=0.2207, Train Acc=92.07%, Val Loss=0.4392, Val Acc=86.06%\n",
      "Strategy: random_R0.2 - Epoch 46/1000: Train Loss=0.2223, Train Acc=92.08%, Val Loss=0.4315, Val Acc=86.14%\n",
      "Strategy: random_R0.2 - Epoch 47/1000: Train Loss=0.2188, Train Acc=92.12%, Val Loss=0.4397, Val Acc=85.88%\n",
      "Early stopping triggered for 'random_R0.2' after 47 epochs. No improvement in 'val_loss' for 20 epochs.\n",
      "Loading best model weights from epoch 27 with val_loss: 0.4241\n",
      "Training for 'random_R0.2' finished. Loading best recorded model state with val_loss: 0.4241\n",
      "✅ Fine-tuning curves for random_R0.2 saved.\n",
      "--- Evaluating Fine-tuned Model (random @ Ratio 0.20) on TEST SET ---\n",
      "Metrics for 'random' @ Ratio 0.20 (Fine-tuned, on Test Set): {'macs': 5553441.0, 'params': 1076719, 'size_mib': 4.107357025146484, 'accuracy': 85.86, 'loss': 0.45066568593978884}\n",
      "✅ Model saved as ONNX to ./output_final_ratio_experiment/random/model_R0.2_final.onnx\n",
      "\n",
      "\n",
      "--- Processing: Strategy 'random', Ratio: 0.50 ---\n",
      "✅ Model loaded from ./output_final_ratio_experiment/mobilenetv2_initial_dense_trained.pth to cuda\n",
      "--- Pruning model with random to ratio 0.50 ---\n",
      "Initial MACs before pruning for ratio 0.50: 0.006 G\n",
      "Applying RandomImportance with target ratio: 0.50 using pruner's 5 iterative_steps.\n",
      "After pruning for ratio 0.50: MACs 0.005 G (Reduction: 18.74%)\n",
      "Metrics for 'random' @ Ratio 0.50 (Pruned, Before FT, on Test Set): {'macs': 4924394.0, 'params': 950314, 'size_mib': 3.6251602172851562, 'accuracy': 39.18, 'loss': 1.847980571937561}\n",
      "--- Fine-tuning pruned model (random @ Ratio 0.50) ---\n",
      "Strategy: random_R0.5 - Epoch 1/1000: Train Loss=0.7355, Train Acc=74.84%, Val Loss=0.6077, Val Acc=78.56% (New best val_loss)\n",
      "Strategy: random_R0.5 - Epoch 2/1000: Train Loss=0.5460, Train Acc=80.86%, Val Loss=0.5409, Val Acc=81.12% (New best val_loss)\n",
      "Strategy: random_R0.5 - Epoch 3/1000: Train Loss=0.4851, Train Acc=82.82%, Val Loss=0.5120, Val Acc=82.32% (New best val_loss)\n",
      "Strategy: random_R0.5 - Epoch 4/1000: Train Loss=0.4507, Train Acc=84.20%, Val Loss=0.4944, Val Acc=82.88% (New best val_loss)\n",
      "Strategy: random_R0.5 - Epoch 5/1000: Train Loss=0.4305, Train Acc=84.73%, Val Loss=0.4779, Val Acc=83.42% (New best val_loss)\n",
      "Strategy: random_R0.5 - Epoch 6/1000: Train Loss=0.4149, Train Acc=85.64%, Val Loss=0.4703, Val Acc=83.78% (New best val_loss)\n",
      "Strategy: random_R0.5 - Epoch 7/1000: Train Loss=0.3991, Train Acc=85.86%, Val Loss=0.4678, Val Acc=83.80% (New best val_loss)\n",
      "Strategy: random_R0.5 - Epoch 8/1000: Train Loss=0.3886, Train Acc=86.36%, Val Loss=0.4596, Val Acc=84.10% (New best val_loss)\n",
      "Strategy: random_R0.5 - Epoch 9/1000: Train Loss=0.3755, Train Acc=86.68%, Val Loss=0.4526, Val Acc=84.28% (New best val_loss)\n",
      "Strategy: random_R0.5 - Epoch 10/1000: Train Loss=0.3673, Train Acc=86.96%, Val Loss=0.4561, Val Acc=84.32%\n",
      "Strategy: random_R0.5 - Epoch 11/1000: Train Loss=0.3664, Train Acc=87.11%, Val Loss=0.4544, Val Acc=84.26%\n",
      "Strategy: random_R0.5 - Epoch 12/1000: Train Loss=0.3595, Train Acc=87.32%, Val Loss=0.4493, Val Acc=84.62% (New best val_loss)\n",
      "Strategy: random_R0.5 - Epoch 13/1000: Train Loss=0.3516, Train Acc=87.60%, Val Loss=0.4454, Val Acc=84.72% (New best val_loss)\n",
      "Strategy: random_R0.5 - Epoch 14/1000: Train Loss=0.3468, Train Acc=87.60%, Val Loss=0.4467, Val Acc=84.72%\n",
      "Strategy: random_R0.5 - Epoch 15/1000: Train Loss=0.3341, Train Acc=88.15%, Val Loss=0.4494, Val Acc=84.92%\n",
      "Strategy: random_R0.5 - Epoch 16/1000: Train Loss=0.3296, Train Acc=88.17%, Val Loss=0.4456, Val Acc=84.90%\n",
      "Strategy: random_R0.5 - Epoch 17/1000: Train Loss=0.3284, Train Acc=88.29%, Val Loss=0.4475, Val Acc=84.72%\n",
      "Strategy: random_R0.5 - Epoch 18/1000: Train Loss=0.3255, Train Acc=88.55%, Val Loss=0.4506, Val Acc=84.72%\n",
      "Strategy: random_R0.5 - Epoch 19/1000: Train Loss=0.3193, Train Acc=88.64%, Val Loss=0.4437, Val Acc=85.02% (New best val_loss)\n",
      "Strategy: random_R0.5 - Epoch 20/1000: Train Loss=0.3173, Train Acc=88.62%, Val Loss=0.4429, Val Acc=84.92% (New best val_loss)\n",
      "Strategy: random_R0.5 - Epoch 21/1000: Train Loss=0.3138, Train Acc=88.85%, Val Loss=0.4449, Val Acc=84.76%\n",
      "Strategy: random_R0.5 - Epoch 22/1000: Train Loss=0.3093, Train Acc=88.95%, Val Loss=0.4331, Val Acc=85.22% (New best val_loss)\n",
      "Strategy: random_R0.5 - Epoch 23/1000: Train Loss=0.3115, Train Acc=89.00%, Val Loss=0.4399, Val Acc=85.24%\n",
      "Strategy: random_R0.5 - Epoch 24/1000: Train Loss=0.3017, Train Acc=89.15%, Val Loss=0.4427, Val Acc=85.20%\n",
      "Strategy: random_R0.5 - Epoch 25/1000: Train Loss=0.2989, Train Acc=89.24%, Val Loss=0.4408, Val Acc=84.84%\n",
      "Strategy: random_R0.5 - Epoch 26/1000: Train Loss=0.2990, Train Acc=89.30%, Val Loss=0.4483, Val Acc=84.80%\n",
      "Strategy: random_R0.5 - Epoch 27/1000: Train Loss=0.2982, Train Acc=89.41%, Val Loss=0.4449, Val Acc=85.00%\n",
      "Strategy: random_R0.5 - Epoch 28/1000: Train Loss=0.2955, Train Acc=89.45%, Val Loss=0.4428, Val Acc=85.34%\n",
      "Strategy: random_R0.5 - Epoch 29/1000: Train Loss=0.2914, Train Acc=89.47%, Val Loss=0.4420, Val Acc=85.12%\n",
      "Strategy: random_R0.5 - Epoch 30/1000: Train Loss=0.2925, Train Acc=89.56%, Val Loss=0.4406, Val Acc=84.86%\n",
      "Strategy: random_R0.5 - Epoch 31/1000: Train Loss=0.2854, Train Acc=89.74%, Val Loss=0.4423, Val Acc=84.96%\n",
      "Strategy: random_R0.5 - Epoch 32/1000: Train Loss=0.2883, Train Acc=89.71%, Val Loss=0.4388, Val Acc=85.30%\n",
      "Strategy: random_R0.5 - Epoch 33/1000: Train Loss=0.2851, Train Acc=89.73%, Val Loss=0.4421, Val Acc=84.98%\n",
      "Strategy: random_R0.5 - Epoch 34/1000: Train Loss=0.2796, Train Acc=90.01%, Val Loss=0.4435, Val Acc=85.22%\n",
      "Strategy: random_R0.5 - Epoch 35/1000: Train Loss=0.2803, Train Acc=90.12%, Val Loss=0.4339, Val Acc=85.34%\n",
      "Strategy: random_R0.5 - Epoch 36/1000: Train Loss=0.2813, Train Acc=90.03%, Val Loss=0.4333, Val Acc=85.20%\n",
      "Strategy: random_R0.5 - Epoch 37/1000: Train Loss=0.2730, Train Acc=90.26%, Val Loss=0.4352, Val Acc=85.18%\n",
      "Strategy: random_R0.5 - Epoch 38/1000: Train Loss=0.2732, Train Acc=90.30%, Val Loss=0.4374, Val Acc=85.38%\n",
      "Strategy: random_R0.5 - Epoch 39/1000: Train Loss=0.2683, Train Acc=90.54%, Val Loss=0.4373, Val Acc=85.18%\n",
      "Strategy: random_R0.5 - Epoch 40/1000: Train Loss=0.2754, Train Acc=90.22%, Val Loss=0.4373, Val Acc=85.10%\n",
      "Strategy: random_R0.5 - Epoch 41/1000: Train Loss=0.2695, Train Acc=90.34%, Val Loss=0.4364, Val Acc=85.10%\n",
      "Strategy: random_R0.5 - Epoch 42/1000: Train Loss=0.2701, Train Acc=90.45%, Val Loss=0.4333, Val Acc=85.64%\n",
      "Early stopping triggered for 'random_R0.5' after 42 epochs. No improvement in 'val_loss' for 20 epochs.\n",
      "Loading best model weights from epoch 22 with val_loss: 0.4331\n",
      "Training for 'random_R0.5' finished. Loading best recorded model state with val_loss: 0.4331\n",
      "✅ Fine-tuning curves for random_R0.5 saved.\n",
      "--- Evaluating Fine-tuned Model (random @ Ratio 0.50) on TEST SET ---\n",
      "Metrics for 'random' @ Ratio 0.50 (Fine-tuned, on Test Set): {'macs': 4924394.0, 'params': 950314, 'size_mib': 3.6251602172851562, 'accuracy': 84.9, 'loss': 0.46639788103103635}\n",
      "✅ Model saved as ONNX to ./output_final_ratio_experiment/random/model_R0.5_final.onnx\n",
      "\n",
      "\n",
      "--- Processing: Strategy 'random', Ratio: 0.70 ---\n",
      "✅ Model loaded from ./output_final_ratio_experiment/mobilenetv2_initial_dense_trained.pth to cuda\n",
      "--- Pruning model with random to ratio 0.70 ---\n",
      "Initial MACs before pruning for ratio 0.70: 0.006 G\n",
      "Applying RandomImportance with target ratio: 0.70 using pruner's 5 iterative_steps.\n",
      "After pruning for ratio 0.70: MACs 0.005 G (Reduction: 25.07%)\n",
      "Metrics for 'random' @ Ratio 0.70 (Pruned, Before FT, on Test Set): {'macs': 4540476.0, 'params': 868248, 'size_mib': 3.312103271484375, 'accuracy': 10.49, 'loss': 2.8445318645477293}\n",
      "--- Fine-tuning pruned model (random @ Ratio 0.70) ---\n",
      "Strategy: random_R0.7 - Epoch 1/1000: Train Loss=0.9662, Train Acc=67.64%, Val Loss=0.7267, Val Acc=73.98% (New best val_loss)\n",
      "Strategy: random_R0.7 - Epoch 2/1000: Train Loss=0.6796, Train Acc=76.33%, Val Loss=0.6153, Val Acc=77.80% (New best val_loss)\n",
      "Strategy: random_R0.7 - Epoch 3/1000: Train Loss=0.5874, Train Acc=79.32%, Val Loss=0.5651, Val Acc=79.82% (New best val_loss)\n",
      "Strategy: random_R0.7 - Epoch 4/1000: Train Loss=0.5425, Train Acc=81.11%, Val Loss=0.5383, Val Acc=80.68% (New best val_loss)\n",
      "Strategy: random_R0.7 - Epoch 5/1000: Train Loss=0.5101, Train Acc=82.16%, Val Loss=0.5147, Val Acc=81.72% (New best val_loss)\n",
      "Strategy: random_R0.7 - Epoch 6/1000: Train Loss=0.4829, Train Acc=82.99%, Val Loss=0.5040, Val Acc=82.12% (New best val_loss)\n",
      "Strategy: random_R0.7 - Epoch 7/1000: Train Loss=0.4638, Train Acc=83.57%, Val Loss=0.4896, Val Acc=82.84% (New best val_loss)\n",
      "Strategy: random_R0.7 - Epoch 8/1000: Train Loss=0.4545, Train Acc=84.11%, Val Loss=0.4790, Val Acc=82.98% (New best val_loss)\n",
      "Strategy: random_R0.7 - Epoch 9/1000: Train Loss=0.4350, Train Acc=84.67%, Val Loss=0.4730, Val Acc=82.84% (New best val_loss)\n",
      "Strategy: random_R0.7 - Epoch 10/1000: Train Loss=0.4299, Train Acc=84.82%, Val Loss=0.4671, Val Acc=83.42% (New best val_loss)\n",
      "Strategy: random_R0.7 - Epoch 11/1000: Train Loss=0.4197, Train Acc=85.04%, Val Loss=0.4655, Val Acc=83.38% (New best val_loss)\n",
      "Strategy: random_R0.7 - Epoch 12/1000: Train Loss=0.4125, Train Acc=85.34%, Val Loss=0.4600, Val Acc=83.90% (New best val_loss)\n",
      "Strategy: random_R0.7 - Epoch 13/1000: Train Loss=0.3970, Train Acc=86.06%, Val Loss=0.4575, Val Acc=83.70% (New best val_loss)\n",
      "Strategy: random_R0.7 - Epoch 14/1000: Train Loss=0.3921, Train Acc=85.96%, Val Loss=0.4531, Val Acc=84.02% (New best val_loss)\n",
      "Strategy: random_R0.7 - Epoch 15/1000: Train Loss=0.3848, Train Acc=86.43%, Val Loss=0.4542, Val Acc=83.96%\n",
      "Strategy: random_R0.7 - Epoch 16/1000: Train Loss=0.3804, Train Acc=86.48%, Val Loss=0.4460, Val Acc=84.22% (New best val_loss)\n",
      "Strategy: random_R0.7 - Epoch 17/1000: Train Loss=0.3764, Train Acc=86.72%, Val Loss=0.4466, Val Acc=84.32%\n",
      "Strategy: random_R0.7 - Epoch 18/1000: Train Loss=0.3666, Train Acc=86.94%, Val Loss=0.4447, Val Acc=84.28% (New best val_loss)\n",
      "Strategy: random_R0.7 - Epoch 19/1000: Train Loss=0.3673, Train Acc=87.02%, Val Loss=0.4389, Val Acc=84.44% (New best val_loss)\n",
      "Strategy: random_R0.7 - Epoch 20/1000: Train Loss=0.3575, Train Acc=87.35%, Val Loss=0.4414, Val Acc=84.68%\n",
      "Strategy: random_R0.7 - Epoch 21/1000: Train Loss=0.3530, Train Acc=87.45%, Val Loss=0.4385, Val Acc=84.66% (New best val_loss)\n",
      "Strategy: random_R0.7 - Epoch 22/1000: Train Loss=0.3500, Train Acc=87.54%, Val Loss=0.4413, Val Acc=84.76%\n",
      "Strategy: random_R0.7 - Epoch 23/1000: Train Loss=0.3475, Train Acc=87.53%, Val Loss=0.4413, Val Acc=84.74%\n",
      "Strategy: random_R0.7 - Epoch 24/1000: Train Loss=0.3457, Train Acc=87.79%, Val Loss=0.4429, Val Acc=84.56%\n",
      "Strategy: random_R0.7 - Epoch 25/1000: Train Loss=0.3390, Train Acc=88.04%, Val Loss=0.4402, Val Acc=85.00%\n",
      "Strategy: random_R0.7 - Epoch 26/1000: Train Loss=0.3360, Train Acc=88.09%, Val Loss=0.4424, Val Acc=84.98%\n",
      "Strategy: random_R0.7 - Epoch 27/1000: Train Loss=0.3402, Train Acc=87.90%, Val Loss=0.4408, Val Acc=84.94%\n",
      "Strategy: random_R0.7 - Epoch 28/1000: Train Loss=0.3333, Train Acc=87.98%, Val Loss=0.4409, Val Acc=85.08%\n",
      "Strategy: random_R0.7 - Epoch 29/1000: Train Loss=0.3310, Train Acc=88.41%, Val Loss=0.4456, Val Acc=85.06%\n",
      "Strategy: random_R0.7 - Epoch 30/1000: Train Loss=0.3245, Train Acc=88.43%, Val Loss=0.4427, Val Acc=84.78%\n",
      "Strategy: random_R0.7 - Epoch 31/1000: Train Loss=0.3244, Train Acc=88.42%, Val Loss=0.4441, Val Acc=84.06%\n",
      "Strategy: random_R0.7 - Epoch 32/1000: Train Loss=0.3221, Train Acc=88.51%, Val Loss=0.4422, Val Acc=84.36%\n",
      "Strategy: random_R0.7 - Epoch 33/1000: Train Loss=0.3167, Train Acc=88.80%, Val Loss=0.4423, Val Acc=84.58%\n",
      "Strategy: random_R0.7 - Epoch 34/1000: Train Loss=0.3185, Train Acc=88.73%, Val Loss=0.4383, Val Acc=84.90% (New best val_loss)\n",
      "Strategy: random_R0.7 - Epoch 35/1000: Train Loss=0.3148, Train Acc=88.93%, Val Loss=0.4382, Val Acc=85.04% (New best val_loss)\n",
      "Strategy: random_R0.7 - Epoch 36/1000: Train Loss=0.3119, Train Acc=88.87%, Val Loss=0.4372, Val Acc=84.80% (New best val_loss)\n",
      "Strategy: random_R0.7 - Epoch 37/1000: Train Loss=0.3127, Train Acc=88.92%, Val Loss=0.4365, Val Acc=84.96% (New best val_loss)\n",
      "Strategy: random_R0.7 - Epoch 38/1000: Train Loss=0.3047, Train Acc=89.21%, Val Loss=0.4406, Val Acc=84.88%\n",
      "Strategy: random_R0.7 - Epoch 39/1000: Train Loss=0.3038, Train Acc=89.12%, Val Loss=0.4408, Val Acc=84.80%\n",
      "Strategy: random_R0.7 - Epoch 40/1000: Train Loss=0.3029, Train Acc=89.33%, Val Loss=0.4418, Val Acc=84.74%\n",
      "Strategy: random_R0.7 - Epoch 41/1000: Train Loss=0.3059, Train Acc=89.09%, Val Loss=0.4382, Val Acc=85.20%\n",
      "Strategy: random_R0.7 - Epoch 42/1000: Train Loss=0.3006, Train Acc=89.25%, Val Loss=0.4432, Val Acc=84.94%\n",
      "Strategy: random_R0.7 - Epoch 43/1000: Train Loss=0.2975, Train Acc=89.50%, Val Loss=0.4377, Val Acc=85.00%\n",
      "Strategy: random_R0.7 - Epoch 44/1000: Train Loss=0.2924, Train Acc=89.60%, Val Loss=0.4359, Val Acc=84.86% (New best val_loss)\n",
      "Strategy: random_R0.7 - Epoch 45/1000: Train Loss=0.2943, Train Acc=89.50%, Val Loss=0.4386, Val Acc=85.00%\n",
      "Strategy: random_R0.7 - Epoch 46/1000: Train Loss=0.2933, Train Acc=89.51%, Val Loss=0.4436, Val Acc=84.94%\n",
      "Strategy: random_R0.7 - Epoch 47/1000: Train Loss=0.2912, Train Acc=89.57%, Val Loss=0.4434, Val Acc=84.70%\n",
      "Strategy: random_R0.7 - Epoch 48/1000: Train Loss=0.2911, Train Acc=89.70%, Val Loss=0.4431, Val Acc=85.16%\n",
      "Strategy: random_R0.7 - Epoch 49/1000: Train Loss=0.2868, Train Acc=89.69%, Val Loss=0.4391, Val Acc=84.74%\n",
      "Strategy: random_R0.7 - Epoch 50/1000: Train Loss=0.2827, Train Acc=89.74%, Val Loss=0.4360, Val Acc=84.76%\n",
      "Strategy: random_R0.7 - Epoch 51/1000: Train Loss=0.2814, Train Acc=89.90%, Val Loss=0.4432, Val Acc=84.76%\n",
      "Strategy: random_R0.7 - Epoch 52/1000: Train Loss=0.2810, Train Acc=89.96%, Val Loss=0.4438, Val Acc=84.86%\n",
      "Strategy: random_R0.7 - Epoch 53/1000: Train Loss=0.2804, Train Acc=89.99%, Val Loss=0.4396, Val Acc=84.54%\n",
      "Strategy: random_R0.7 - Epoch 54/1000: Train Loss=0.2790, Train Acc=90.12%, Val Loss=0.4370, Val Acc=84.78%\n",
      "Strategy: random_R0.7 - Epoch 55/1000: Train Loss=0.2821, Train Acc=89.79%, Val Loss=0.4383, Val Acc=85.08%\n",
      "Strategy: random_R0.7 - Epoch 56/1000: Train Loss=0.2803, Train Acc=90.04%, Val Loss=0.4427, Val Acc=85.22%\n",
      "Strategy: random_R0.7 - Epoch 57/1000: Train Loss=0.2785, Train Acc=90.12%, Val Loss=0.4438, Val Acc=85.12%\n",
      "Strategy: random_R0.7 - Epoch 58/1000: Train Loss=0.2747, Train Acc=89.97%, Val Loss=0.4456, Val Acc=84.76%\n",
      "Strategy: random_R0.7 - Epoch 59/1000: Train Loss=0.2692, Train Acc=90.37%, Val Loss=0.4414, Val Acc=85.02%\n",
      "Strategy: random_R0.7 - Epoch 60/1000: Train Loss=0.2711, Train Acc=90.21%, Val Loss=0.4410, Val Acc=84.96%\n",
      "Strategy: random_R0.7 - Epoch 61/1000: Train Loss=0.2692, Train Acc=90.38%, Val Loss=0.4410, Val Acc=85.24%\n",
      "Strategy: random_R0.7 - Epoch 62/1000: Train Loss=0.2681, Train Acc=90.30%, Val Loss=0.4370, Val Acc=85.06%\n",
      "Strategy: random_R0.7 - Epoch 63/1000: Train Loss=0.2664, Train Acc=90.54%, Val Loss=0.4411, Val Acc=84.84%\n",
      "Strategy: random_R0.7 - Epoch 64/1000: Train Loss=0.2658, Train Acc=90.44%, Val Loss=0.4463, Val Acc=85.16%\n",
      "Early stopping triggered for 'random_R0.7' after 64 epochs. No improvement in 'val_loss' for 20 epochs.\n",
      "Loading best model weights from epoch 44 with val_loss: 0.4359\n",
      "Training for 'random_R0.7' finished. Loading best recorded model state with val_loss: 0.4359\n",
      "✅ Fine-tuning curves for random_R0.7 saved.\n",
      "--- Evaluating Fine-tuned Model (random @ Ratio 0.70) on TEST SET ---\n",
      "Metrics for 'random' @ Ratio 0.70 (Fine-tuned, on Test Set): {'macs': 4540476.0, 'params': 868248, 'size_mib': 3.312103271484375, 'accuracy': 85.17, 'loss': 0.46895592613220216}\n",
      "✅ Model saved as ONNX to ./output_final_ratio_experiment/random/model_R0.7_final.onnx\n",
      "\n",
      "\n",
      "--- Processing: Strategy 'random', Ratio: 0.90 ---\n",
      "✅ Model loaded from ./output_final_ratio_experiment/mobilenetv2_initial_dense_trained.pth to cuda\n",
      "--- Pruning model with random to ratio 0.90 ---\n",
      "Initial MACs before pruning for ratio 0.90: 0.006 G\n",
      "Applying RandomImportance with target ratio: 0.90 using pruner's 5 iterative_steps.\n",
      "After pruning for ratio 0.90: MACs 0.004 G (Reduction: 30.36%)\n",
      "Metrics for 'random' @ Ratio 0.90 (Pruned, Before FT, on Test Set): {'macs': 4220136.0, 'params': 791365, 'size_mib': 3.018817901611328, 'accuracy': 17.82, 'loss': 2.357781214904785}\n",
      "--- Fine-tuning pruned model (random @ Ratio 0.90) ---\n",
      "Strategy: random_R0.9 - Epoch 1/1000: Train Loss=1.0061, Train Acc=65.75%, Val Loss=0.7937, Val Acc=71.98% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 2/1000: Train Loss=0.7331, Train Acc=74.17%, Val Loss=0.6827, Val Acc=75.74% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 3/1000: Train Loss=0.6489, Train Acc=77.27%, Val Loss=0.6272, Val Acc=77.82% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 4/1000: Train Loss=0.6011, Train Acc=78.54%, Val Loss=0.5913, Val Acc=79.18% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 5/1000: Train Loss=0.5691, Train Acc=80.16%, Val Loss=0.5708, Val Acc=79.78% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 6/1000: Train Loss=0.5396, Train Acc=80.97%, Val Loss=0.5540, Val Acc=80.24% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 7/1000: Train Loss=0.5169, Train Acc=81.66%, Val Loss=0.5363, Val Acc=80.82% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 8/1000: Train Loss=0.5009, Train Acc=82.35%, Val Loss=0.5319, Val Acc=80.92% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 9/1000: Train Loss=0.4853, Train Acc=82.94%, Val Loss=0.5200, Val Acc=81.16% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 10/1000: Train Loss=0.4713, Train Acc=83.25%, Val Loss=0.5177, Val Acc=81.58% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 11/1000: Train Loss=0.4650, Train Acc=83.61%, Val Loss=0.5092, Val Acc=81.94% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 12/1000: Train Loss=0.4522, Train Acc=84.06%, Val Loss=0.4976, Val Acc=82.40% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 13/1000: Train Loss=0.4387, Train Acc=84.40%, Val Loss=0.5014, Val Acc=82.46%\n",
      "Strategy: random_R0.9 - Epoch 14/1000: Train Loss=0.4314, Train Acc=84.65%, Val Loss=0.4943, Val Acc=82.56% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 15/1000: Train Loss=0.4250, Train Acc=85.00%, Val Loss=0.4880, Val Acc=83.10% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 16/1000: Train Loss=0.4210, Train Acc=85.12%, Val Loss=0.4864, Val Acc=83.34% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 17/1000: Train Loss=0.4131, Train Acc=85.25%, Val Loss=0.4789, Val Acc=83.26% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 18/1000: Train Loss=0.4044, Train Acc=85.61%, Val Loss=0.4746, Val Acc=83.46% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 19/1000: Train Loss=0.4029, Train Acc=85.80%, Val Loss=0.4688, Val Acc=83.70% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 20/1000: Train Loss=0.3974, Train Acc=85.98%, Val Loss=0.4635, Val Acc=83.94% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 21/1000: Train Loss=0.3915, Train Acc=86.13%, Val Loss=0.4684, Val Acc=83.74%\n",
      "Strategy: random_R0.9 - Epoch 22/1000: Train Loss=0.3897, Train Acc=86.26%, Val Loss=0.4626, Val Acc=83.62% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 23/1000: Train Loss=0.3817, Train Acc=86.46%, Val Loss=0.4641, Val Acc=83.72%\n",
      "Strategy: random_R0.9 - Epoch 24/1000: Train Loss=0.3796, Train Acc=86.46%, Val Loss=0.4650, Val Acc=83.84%\n",
      "Strategy: random_R0.9 - Epoch 25/1000: Train Loss=0.3705, Train Acc=86.84%, Val Loss=0.4613, Val Acc=83.84% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 26/1000: Train Loss=0.3678, Train Acc=87.00%, Val Loss=0.4600, Val Acc=83.88% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 27/1000: Train Loss=0.3696, Train Acc=86.88%, Val Loss=0.4581, Val Acc=84.04% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 28/1000: Train Loss=0.3620, Train Acc=87.23%, Val Loss=0.4576, Val Acc=84.28% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 29/1000: Train Loss=0.3617, Train Acc=87.09%, Val Loss=0.4562, Val Acc=84.54% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 30/1000: Train Loss=0.3554, Train Acc=87.46%, Val Loss=0.4560, Val Acc=84.18% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 31/1000: Train Loss=0.3563, Train Acc=87.25%, Val Loss=0.4587, Val Acc=84.08%\n",
      "Strategy: random_R0.9 - Epoch 32/1000: Train Loss=0.3527, Train Acc=87.59%, Val Loss=0.4584, Val Acc=84.38%\n",
      "Strategy: random_R0.9 - Epoch 33/1000: Train Loss=0.3538, Train Acc=87.48%, Val Loss=0.4567, Val Acc=84.06%\n",
      "Strategy: random_R0.9 - Epoch 34/1000: Train Loss=0.3472, Train Acc=87.77%, Val Loss=0.4542, Val Acc=84.28% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 35/1000: Train Loss=0.3466, Train Acc=87.62%, Val Loss=0.4566, Val Acc=84.16%\n",
      "Strategy: random_R0.9 - Epoch 36/1000: Train Loss=0.3411, Train Acc=88.00%, Val Loss=0.4535, Val Acc=84.18% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 37/1000: Train Loss=0.3386, Train Acc=87.98%, Val Loss=0.4545, Val Acc=84.24%\n",
      "Strategy: random_R0.9 - Epoch 38/1000: Train Loss=0.3356, Train Acc=88.04%, Val Loss=0.4518, Val Acc=84.18% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 39/1000: Train Loss=0.3345, Train Acc=88.08%, Val Loss=0.4541, Val Acc=84.16%\n",
      "Strategy: random_R0.9 - Epoch 40/1000: Train Loss=0.3329, Train Acc=88.23%, Val Loss=0.4524, Val Acc=84.50%\n",
      "Strategy: random_R0.9 - Epoch 41/1000: Train Loss=0.3296, Train Acc=88.30%, Val Loss=0.4502, Val Acc=84.68% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 42/1000: Train Loss=0.3254, Train Acc=88.37%, Val Loss=0.4527, Val Acc=84.36%\n",
      "Strategy: random_R0.9 - Epoch 43/1000: Train Loss=0.3238, Train Acc=88.62%, Val Loss=0.4475, Val Acc=84.68% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 44/1000: Train Loss=0.3267, Train Acc=88.44%, Val Loss=0.4448, Val Acc=84.56% (New best val_loss)\n",
      "Strategy: random_R0.9 - Epoch 45/1000: Train Loss=0.3222, Train Acc=88.64%, Val Loss=0.4486, Val Acc=84.42%\n",
      "Strategy: random_R0.9 - Epoch 46/1000: Train Loss=0.3235, Train Acc=88.45%, Val Loss=0.4499, Val Acc=84.44%\n",
      "Strategy: random_R0.9 - Epoch 47/1000: Train Loss=0.3179, Train Acc=88.74%, Val Loss=0.4503, Val Acc=84.50%\n",
      "Strategy: random_R0.9 - Epoch 48/1000: Train Loss=0.3190, Train Acc=88.64%, Val Loss=0.4520, Val Acc=84.76%\n",
      "Strategy: random_R0.9 - Epoch 49/1000: Train Loss=0.3112, Train Acc=88.91%, Val Loss=0.4591, Val Acc=84.40%\n",
      "Strategy: random_R0.9 - Epoch 50/1000: Train Loss=0.3145, Train Acc=88.61%, Val Loss=0.4504, Val Acc=84.66%\n",
      "Strategy: random_R0.9 - Epoch 51/1000: Train Loss=0.3118, Train Acc=88.86%, Val Loss=0.4555, Val Acc=84.46%\n",
      "Strategy: random_R0.9 - Epoch 52/1000: Train Loss=0.3123, Train Acc=88.79%, Val Loss=0.4503, Val Acc=84.52%\n",
      "Strategy: random_R0.9 - Epoch 53/1000: Train Loss=0.3073, Train Acc=89.09%, Val Loss=0.4537, Val Acc=84.68%\n",
      "Strategy: random_R0.9 - Epoch 54/1000: Train Loss=0.3095, Train Acc=88.99%, Val Loss=0.4486, Val Acc=84.42%\n",
      "Strategy: random_R0.9 - Epoch 55/1000: Train Loss=0.3048, Train Acc=89.03%, Val Loss=0.4513, Val Acc=84.82%\n",
      "Strategy: random_R0.9 - Epoch 56/1000: Train Loss=0.3014, Train Acc=89.28%, Val Loss=0.4558, Val Acc=84.60%\n",
      "Strategy: random_R0.9 - Epoch 57/1000: Train Loss=0.3050, Train Acc=89.15%, Val Loss=0.4555, Val Acc=84.48%\n",
      "Strategy: random_R0.9 - Epoch 58/1000: Train Loss=0.3014, Train Acc=89.18%, Val Loss=0.4550, Val Acc=84.72%\n",
      "Strategy: random_R0.9 - Epoch 59/1000: Train Loss=0.3041, Train Acc=89.09%, Val Loss=0.4581, Val Acc=84.66%\n",
      "Strategy: random_R0.9 - Epoch 60/1000: Train Loss=0.2984, Train Acc=89.28%, Val Loss=0.4581, Val Acc=84.50%\n",
      "Strategy: random_R0.9 - Epoch 61/1000: Train Loss=0.2964, Train Acc=89.38%, Val Loss=0.4549, Val Acc=84.60%\n",
      "Strategy: random_R0.9 - Epoch 62/1000: Train Loss=0.2974, Train Acc=89.28%, Val Loss=0.4543, Val Acc=85.02%\n",
      "Strategy: random_R0.9 - Epoch 63/1000: Train Loss=0.2934, Train Acc=89.46%, Val Loss=0.4536, Val Acc=84.84%\n",
      "Strategy: random_R0.9 - Epoch 64/1000: Train Loss=0.2891, Train Acc=89.61%, Val Loss=0.4649, Val Acc=84.66%\n",
      "Early stopping triggered for 'random_R0.9' after 64 epochs. No improvement in 'val_loss' for 20 epochs.\n",
      "Loading best model weights from epoch 44 with val_loss: 0.4448\n",
      "Training for 'random_R0.9' finished. Loading best recorded model state with val_loss: 0.4448\n",
      "✅ Fine-tuning curves for random_R0.9 saved.\n",
      "--- Evaluating Fine-tuned Model (random @ Ratio 0.90) on TEST SET ---\n",
      "Metrics for 'random' @ Ratio 0.90 (Fine-tuned, on Test Set): {'macs': 4220136.0, 'params': 791365, 'size_mib': 3.018817901611328, 'accuracy': 84.36, 'loss': 0.4779323546409607}\n",
      "✅ Model saved as ONNX to ./output_final_ratio_experiment/random/model_R0.9_final.onnx\n",
      "✅ MACs vs. Ratio by Strategy plot saved to ./output_final_ratio_experiment\n",
      "✅ Loss vs. Ratio by Strategy plot saved to ./output_final_ratio_experiment\n",
      "✅ Accuracy vs. Ratio by Strategy plot saved to ./output_final_ratio_experiment\n",
      "\n",
      "All ratio-based pruning experiments completed successfully!\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "238badca29395cae",
   "metadata": {},
   "source": [
    "### Load the saved Onnx model and convert to Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "229d26f48f444268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T12:24:13.022499Z",
     "start_time": "2025-04-10T12:24:12.993796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ONNX model loaded and verified.\n",
      "✅ ONNX model converted to PyTorch.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from onnx2torch import convert\n",
    "\n",
    "# Step 1: Load the ONNX model\n",
    "onnx_model_path = './output/strategies/mobilenetv2_bn_scale_final.onnx'\n",
    "onnx_model = onnx.load(onnx_model_path)\n",
    "onnx.checker.check_model(onnx_model)  # Verify the ONNX model\n",
    "print(\"✅ ONNX model loaded and verified.\")\n",
    "\n",
    "# Step 2: Convert ONNX to PyTorch\n",
    "torch_model = convert(onnx_model)\n",
    "print(\"✅ ONNX model converted to PyTorch.\")\n",
    "tp.utils.print_tool.before_pruning(torch_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de5ca7f1456a3d2",
   "metadata": {},
   "source": [
    "### Load the converted Pytorch model and fine-tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dea4c672dce55",
   "metadata": {},
   "source": [
    "### Gr: prune with threshold"
   ]
  },
  {
   "cell_type": "code",
   "id": "59ea3f26d421e293",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T15:56:58.835119Z",
     "start_time": "2025-05-22T15:56:58.825868Z"
    }
   },
   "source": [
    "#def gr_prune_model_with_threshold(model, example_input, target_macs, target_size_mb, strategy, max_iterative_steps=20, max_sparsity=0.9):\n",
    "def gr_prune_model_by_ratio(model_to_prune, example_input_device, strategy_config, target_pruning_ratio,\n",
    "                            iterative_steps_config=5,  # For non-Taylor pruners or overall iterations\n",
    "                            iterative_steps_taylor=5 # For the outer loop of backward passes for Taylor\n",
    "                           ):\n",
    "    model = copy.deepcopy(model_to_prune)\n",
    "    model.to(example_input_device.device)\n",
    "    initial_macs, _ = calculate_macs(model, example_input_device)\n",
    "    print(f\"Initial MACs before pruning for ratio {target_pruning_ratio:.2f}: {initial_macs / 1e9:.3f} G\")\n",
    "\n",
    "    ignored_layers_list = []\n",
    "    if hasattr(model, 'fc'):\n",
    "        ignored_layers_list = [model.fc]\n",
    "    else:\n",
    "        print(\"Warning: model.fc not found. Pruning might affect classifier.\")\n",
    "\n",
    "    if target_pruning_ratio == 0.0:\n",
    "        print(\"Target pruning ratio is 0.0. No pruning applied.\")\n",
    "        return model\n",
    "\n",
    "    if isinstance(strategy_config['importance'], tp.importance.TaylorImportance):\n",
    "        print(f\"Applying TaylorImportance with target ratio: {target_pruning_ratio:.2f} using manual backward passes in eval mode.\")\n",
    "\n",
    "        # For this approach, the pruner is initialized to apply a portion of the pruning\n",
    "        # in each step of our manual loop, similar to your original working snippet.\n",
    "        # The pruner's own `iterative_steps` should be 1 because we are controlling the iteration.\n",
    "        sparsity_per_manual_step = target_pruning_ratio / iterative_steps_taylor\n",
    "        # Ensure some sparsity if target > 0 and steps are too many\n",
    "        if sparsity_per_manual_step == 0 and target_pruning_ratio > 0 :\n",
    "             sparsity_per_manual_step = target_pruning_ratio\n",
    "\n",
    "        # This pruner instance is for ONE application within our manual loop\n",
    "        pruner_for_taylor_step = strategy_config['pruner'](\n",
    "            model,\n",
    "            example_input_device,\n",
    "            importance=strategy_config['importance'],\n",
    "            iterative_steps=1,  # Pruner itself does one application based on current grads\n",
    "            ch_sparsity=sparsity_per_manual_step, # Target for THIS single pruner.step() call\n",
    "            root_module_types=[nn.Conv2d],\n",
    "            ignored_layers=ignored_layers_list\n",
    "        )\n",
    "\n",
    "        # Keep model in EVAL mode for forward/backward to try and avoid BN error\n",
    "        # This relies on requires_grad=True for parameters.\n",
    "        model.eval() # Explicitly set to eval mode\n",
    "\n",
    "        for i in range(iterative_steps_taylor):\n",
    "            # Ensure gradients are zeroed for this step's computation\n",
    "            model.zero_grad()\n",
    "            # Parameters should retain requires_grad=True unless explicitly turned off\n",
    "            for param in model.parameters(): # Ensure gradients are enabled if they were somehow turned off\n",
    "                 if not param.requires_grad:\n",
    "                      param.requires_grad_(True)\n",
    "\n",
    "            # Forward pass in eval mode\n",
    "            loss = model(example_input_device.clone()).mean()\n",
    "\n",
    "            try:\n",
    "                # Backward pass (still in eval mode for BNs)\n",
    "                loss.backward()\n",
    "            except Exception as e:\n",
    "                print(f\"Error during loss.backward() at Taylor step {i+1} (model in eval mode): {e}\")\n",
    "                raise\n",
    "\n",
    "            # Pruner step using the gradients computed above\n",
    "            # The pruner might internally switch parts of the model to train if absolutely necessary,\n",
    "            # but typically it just consumes the gradients.\n",
    "            print(f\"  Taylor Manual Step {i+1}/{iterative_steps_taylor} (target overall ratio: {target_pruning_ratio:.2f})\")\n",
    "            groups_to_prune = list(pruner_for_taylor_step.step(interactive=True)) # Get groups based on current step's sparsity target\n",
    "            if not groups_to_prune and target_pruning_ratio > 0: # If positive target but no groups\n",
    "                 print(f\"  No more groups to prune at Taylor step {i+1} based on ch_sparsity={sparsity_per_manual_step:.3f}.\")\n",
    "                 # We might want to break if we expect more pruning to happen for the overall target\n",
    "                 # This depends on how pruner_for_taylor_step.step() handles reaching its *own* iterative_steps=1.\n",
    "                 # If it can be called multiple times meaningfully to achieve more pruning, then continue.\n",
    "                 # If it only effectively prunes once based on initial sparsity, this loop structure needs rethink.\n",
    "                 # Let's assume for now that calling it multiple times could achieve more if candidates exist.\n",
    "\n",
    "            for g in groups_to_prune:\n",
    "                g.prune()\n",
    "\n",
    "            macs_after_step, _ = calculate_macs(model, example_input_device)\n",
    "            print(f\"  MACs after Taylor step {i+1}: {macs_after_step / 1e9:.3f} G\")\n",
    "\n",
    "            # Check if overall target MACs or effective sparsity is reached (optional premature exit)\n",
    "            # This requires defining what the MACs target would be for `target_pruning_ratio`.\n",
    "            # For simplicity, we run all `iterative_steps_taylor_manual_loop`\n",
    "\n",
    "            # Zero gradients again IF parameters are shared across pruner re-initialization\n",
    "            # But here pruner_for_taylor_step is initialized once. Grads should be cleared by model.zero_grad() at loop start.\n",
    "\n",
    "        # After the loop, model remains in eval() mode. This is usually fine.\n",
    "\n",
    "    else: # For non-Taylor strategies\n",
    "        print(f\"Applying {strategy_config['importance'].__class__.__name__} with target ratio: {target_pruning_ratio:.2f} \"\n",
    "              f\"using pruner's {iterative_steps_config} iterative_steps.\")\n",
    "\n",
    "        # Set model to eval for non-Taylor pruning as well for consistency,\n",
    "        # as most pruners expect eval mode for graph analysis.\n",
    "        model.eval()\n",
    "\n",
    "        pruner = strategy_config['pruner'](\n",
    "            model,\n",
    "            example_input_device,\n",
    "            importance=strategy_config['importance'],\n",
    "            iterative_steps=iterative_steps_config,\n",
    "            ch_sparsity=target_pruning_ratio,\n",
    "            root_module_types=[nn.Conv2d],\n",
    "            ignored_layers=ignored_layers_list\n",
    "        )\n",
    "        pruner.step()\n",
    "\n",
    "    final_macs, _ = calculate_macs(model, example_input_device)\n",
    "    reduction = (initial_macs - final_macs) / initial_macs * 100 if initial_macs > 0 else 0\n",
    "    print(f\"After pruning for ratio {target_pruning_ratio:.2f}: MACs {final_macs / 1e9:.3f} G (Reduction: {reduction:.2f}%)\")\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "ed9159eb03e0d570",
   "metadata": {},
   "source": [
    "### Gem: Prune with threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "572d5d540d81ce45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:15:38.633900Z",
     "start_time": "2025-04-29T03:15:38.623094Z"
    }
   },
   "outputs": [],
   "source": [
    "import time # Optional: for adding time limits or tracking\n",
    "\n",
    "# Assume calculate_macs is defined as before:\n",
    "# def calculate_macs(model, example_input):\n",
    "#     macs, params = tp.utils.count_ops_and_params(model, example_input)\n",
    "#     return macs, params\n",
    "\n",
    "def gem_prune_model_by_threshold(model, example_input, target_macs, target_params, strategy, max_iterations=100, step_ch_sparsity=0.1):\n",
    "    \"\"\"\n",
    "    Prunes the model iteratively until both MACs and parameter count are below\n",
    "    the specified thresholds, or max_iterations is reached.\n",
    "\n",
    "    Args:\n",
    "        model: The PyTorch model to prune.\n",
    "        example_input: Example input tensor for MACs calculation and pruner.\n",
    "        target_macs: The desired maximum MAC count.\n",
    "        target_params: The desired maximum parameter count.\n",
    "        strategy: Dictionary containing 'pruner' and 'importance'.\n",
    "        max_iterations (int): Safety limit for the number of pruning steps.\n",
    "        step_ch_sparsity (float): Channel sparsity target for each individual pruning step.\n",
    "                                  Influences how many candidates `pruner.step` proposes.\n",
    "                                  Smaller values lead to potentially finer steps.\n",
    "\n",
    "    Returns:\n",
    "        The pruned model.\n",
    "    \"\"\"\n",
    "    device = example_input.device\n",
    "    model.to(device) # Ensure model is on the correct device\n",
    "\n",
    "    print(f\"--- Starting Pruning (Strategy: {strategy['importance'].__class__.__name__}) ---\")\n",
    "    print(f\"Target MACs: {target_macs:,.0f}, Target Params: {target_params:,.0f}\")\n",
    "\n",
    "    # Instantiate the pruner\n",
    "    # Note: 'iterative_steps' in init is less critical here as the while loop controls iteration.\n",
    "    pruner = strategy['pruner'](\n",
    "        model,\n",
    "        example_input,\n",
    "        importance=strategy['importance'],\n",
    "        ch_sparsity=step_ch_sparsity, # Target sparsity *per step*\n",
    "        root_module_types=[nn.Conv2d], # Focus pruning on Conv layers\n",
    "        ignored_layers=[model.fc], # Don't prune the final classifier\n",
    "        # Optional: other pruner args like round_to might be useful depending on strategy/model\n",
    "        # round_to=8, # Example: commonly used for hardware efficiency\n",
    "    )\n",
    "\n",
    "    # Get initial state\n",
    "    current_macs, current_params = calculate_macs(model, example_input)\n",
    "    initial_macs, initial_params = current_macs, current_params # Keep for logging\n",
    "    print(f\"Initial | MACs: {current_macs:,.0f}, Params: {current_params:,.0f}\")\n",
    "\n",
    "    iteration = 0\n",
    "    model.eval() # Ensure model is in eval mode for pruning logic unless Taylor\n",
    "\n",
    "    while (current_macs > target_macs or current_params > target_params) and iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        macs_before_step = current_macs\n",
    "        params_before_step = current_params\n",
    "\n",
    "        # --- Special handling for Importance methods requiring gradients ---\n",
    "        if isinstance(strategy['importance'], (tp.importance.TaylorImportance, tp.importance.GroupHessianImportance)):\n",
    "             model.train() # Need gradients\n",
    "             # Ensure requires_grad is True if it was turned off\n",
    "             for param in model.parameters():\n",
    "                 param.requires_grad_(True)\n",
    "\n",
    "             loss = model(example_input).mean() # Use mean or sum as dummy loss\n",
    "             try:\n",
    "                 loss.backward() # Calculate gradients needed for importance\n",
    "             except Exception as e:\n",
    "                 print(f\"Error during backward pass for importance calc (Iter {iteration}): {e}\")\n",
    "                 # Decide how to handle: break, skip step, etc.\n",
    "                 break # Safer to stop if backward fails\n",
    "\n",
    "        # --- Perform one step of interactive pruning ---\n",
    "        try:\n",
    "            # Get the next set of pruning candidates based on current importance\n",
    "            pruning_groups = list(pruner.step(interactive=True))\n",
    "        except Exception as e:\n",
    "             print(f\"Error during pruner.step() (Iter {iteration}): {e}\")\n",
    "             # Handle potential errors during dependency analysis or importance scoring\n",
    "             break # Stop if pruner step fails\n",
    "\n",
    "        if not pruning_groups:\n",
    "            print(f\"Iteration {iteration}: Pruner found no more candidates. Stopping.\")\n",
    "            break # No more structures can be pruned according to the strategy/dependencies\n",
    "\n",
    "        # --- Apply the pruning ---\n",
    "        for group in pruning_groups:\n",
    "            group.prune()\n",
    "\n",
    "        # --- Clean up gradients if calculated ---\n",
    "        if isinstance(strategy['importance'], (tp.importance.TaylorImportance, tp.importance.GroupHessianImportance)):\n",
    "            # Zero gradients to prevent interference with potential future training/fine-tuning\n",
    "            model.zero_grad()\n",
    "            model.eval() # Switch back to eval mode after grad calculation\n",
    "\n",
    "        # --- Recalculate metrics ---\n",
    "        # It's crucial to recalculate AFTER pruning is applied\n",
    "        current_macs, current_params = calculate_macs(model, example_input)\n",
    "\n",
    "        # --- Log progress ---\n",
    "        print(\n",
    "            f\"Iter {iteration: >3}/{max_iterations} | \"\n",
    "            f\"MACs: {macs_before_step:,.0f} -> {current_macs:,.0f} \"\n",
    "            f\"({(macs_before_step-current_macs)/macs_before_step*100:+.1f}%) | \"\n",
    "            f\"Params: {params_before_step:,.0f} -> {current_params:,.0f} \"\n",
    "            f\"({(params_before_step-current_params)/params_before_step*100:+.1f}%)\"\n",
    "        )\n",
    "\n",
    "        # --- Check for Stagnation (optional but recommended) ---\n",
    "        if current_macs >= macs_before_step and current_params >= params_before_step:\n",
    "            print(f\"Iteration {iteration}: No reduction in MACs or Params this step. Stopping to prevent loop.\")\n",
    "            # This might happen if the only prunable groups left have negligible impact\n",
    "            # or if there's an issue with the importance/pruning logic.\n",
    "            break\n",
    "\n",
    "    # --- Final Status Report ---\n",
    "    print(f\"--- Finished Pruning (Strategy: {strategy['importance'].__class__.__name__}) ---\")\n",
    "    if iteration >= max_iterations:\n",
    "        print(f\"Warning: Reached maximum pruning iterations ({max_iterations}).\")\n",
    "\n",
    "    final_macs, final_params = calculate_macs(model, example_input)\n",
    "    print(f\"Initial | MACs: {initial_macs:,.0f}, Params: {initial_params:,.0f}\")\n",
    "    print(f\"Final   | MACs: {final_macs:,.0f}, Params: {final_params:,.0f}\")\n",
    "    print(f\"Target  | MACs: {target_macs:,.0f}, Params: {target_params:,.0f}\")\n",
    "\n",
    "    macs_reduction = (initial_macs - final_macs) / initial_macs * 100 if initial_macs > 0 else 0\n",
    "    params_reduction = (initial_params - final_params) / initial_params * 100 if initial_params > 0 else 0\n",
    "    print(f\"Reduction | MACs: {macs_reduction:.2f}%, Params: {params_reduction:.2f}%\")\n",
    "\n",
    "    if final_macs > target_macs or final_params > target_params:\n",
    "         print(\"Warning: Pruning finished, but target threshold(s) were not fully met.\")\n",
    "\n",
    "    model.eval() # Ensure model is in eval mode finally\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
