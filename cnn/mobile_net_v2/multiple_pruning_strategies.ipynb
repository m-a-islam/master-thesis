{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "377de838",
   "metadata": {},
   "source": [
    "## import necessary libraries for pruning"
   ]
  },
  {
   "cell_type": "code",
   "id": "7b6381473b81b890",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:15:49.354822Z",
     "start_time": "2025-04-29T03:15:46.811721Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_pruning as tp\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "from torch_pruning.pruner.algorithms.scheduler import linear_scheduler\n",
    "from torchsummary import summary\n",
    "\n",
    "from cnn.resNet.resnet_example import get_data_loaders\n",
    "import torch\n",
    "from torch import nn"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "631981174f5d8d8a",
   "metadata": {},
   "source": [
    "### Seed Network"
   ]
  },
  {
   "cell_type": "code",
   "id": "248e7c99c6815764",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:15:51.764211Z",
     "start_time": "2025-04-29T03:15:51.759063Z"
    }
   },
   "source": [
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, expansion=6):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.use_res_connect = self.stride == 1 and in_channels == out_channels\n",
    "\n",
    "        # Standard PyTorch layers (NO torch_pruning wrappers needed)\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels * expansion, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels * expansion)\n",
    "        self.relu = nn.ReLU6(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels * expansion, in_channels * expansion, kernel_size=3,\n",
    "            stride=stride, padding=1, groups=in_channels * expansion, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels * expansion)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels * expansion, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x if self.use_res_connect else None\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.use_res_connect:\n",
    "            return identity + out\n",
    "        else:\n",
    "            return out"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "6431a8ad17e1d446",
   "metadata": {},
   "source": [
    "### Mask Network"
   ]
  },
  {
   "cell_type": "code",
   "id": "4da304cf4cf9f871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:15:54.320986Z",
     "start_time": "2025-04-29T03:15:54.313909Z"
    }
   },
   "source": [
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        # --- Remove mask-related parameters ---\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU6(inplace=True)\n",
    "\n",
    "        # Define blocks (no mask_index or mask)\n",
    "        self.block1 = InvertedResidual(32, 16, stride=1)\n",
    "        self.block2 = InvertedResidual(16, 24, stride=2)\n",
    "        self.block3 = InvertedResidual(24, 32, stride=2)\n",
    "        self.block4 = InvertedResidual(32, 64, stride=2)\n",
    "        self.block5 = InvertedResidual(64, 96, stride=1)\n",
    "        self.block6 = InvertedResidual(96, 160, stride=2)\n",
    "        self.block7 = InvertedResidual(160, 320, stride=1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(1280)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(1280, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # --- Remove mask-based block skipping ---\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "        x = self.block7(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "4ad82bf3520f8612",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:15:58.160784Z",
     "start_time": "2025-04-29T03:15:58.123707Z"
    }
   },
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "7ebb1e087d2f0cd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:15:59.461235Z",
     "start_time": "2025-04-29T03:15:59.456692Z"
    }
   },
   "source": [
    "def save_model_as_onnx(model, example_input, output_path):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    # Export to ONNX\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        example_input,\n",
    "        output_path,\n",
    "        export_params=True,\n",
    "        opset_version=13,\n",
    "        input_names=['input'],\n",
    "        output_names=['output'],\n",
    "        dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    "    )\n",
    "    print(f\"âœ… Model saved as ONNX to {output_path}\")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "3e9a817a37b770da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:16:00.637497Z",
     "start_time": "2025-04-29T03:16:00.633170Z"
    }
   },
   "source": [
    "def calculate_macs(model, example_input):\n",
    "    macs, params = tp.utils.count_ops_and_params(model, example_input)\n",
    "    return macs, params"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "5b29391c83349f69",
   "metadata": {},
   "source": [
    "### compare results of different pruning strategies"
   ]
  },
  {
   "cell_type": "code",
   "id": "becad7e59744f0dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:16:02.236858Z",
     "start_time": "2025-04-29T03:16:02.233151Z"
    }
   },
   "source": [
    "def compare_results(results):\n",
    "    print(\"\\n=== Pruning Strategy Comparison ===\")\n",
    "    print(f\"{'Strategy':<12} | {'MACs':<12} | {'Size (MB)':<10} | {'Accuracy (%)':<12}\")\n",
    "    print(\"-\" * 55)\n",
    "    for strategy, metrics in results.items():\n",
    "        print(f\"{strategy:<12} | {metrics['macs']:.2e} | {metrics['size_mb']:>9.2f} | {metrics['accuracy']:>12.2f}\")"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### compare and plot results",
   "id": "df0e1911de55ade6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:16:03.957228Z",
     "start_time": "2025-04-29T03:16:03.950675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def compare_results_and_plot(results, output_dir='output'):\n",
    "    \"\"\"\n",
    "    Print a comparison table and generate bar charts for MACs, model size, and accuracy\n",
    "    for each pruning strategy, including the initial model.\n",
    "    \"\"\"\n",
    "    # Print comparison table\n",
    "    print(\"\\n=== Pruning Strategy Comparison ===\")\n",
    "    print(f\"{'Strategy':<12} | {'MACs':<12} | {'Size (MB)':<10} | {'Accuracy (%)':<12}\")\n",
    "    print(\"-\" * 55)\n",
    "    for strategy, metrics in results.items():\n",
    "        print(f\"{strategy:<12} | {metrics['macs']:.2e} | {metrics['size_mb']:>9.2f} | {metrics['accuracy']:>12.2f}\")\n",
    "\n",
    "    # Generate bar charts\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    strategies = ['initial'] + [s for s in results if s != 'initial']\n",
    "    metrics = ['macs', 'size_mb', 'accuracy']\n",
    "    titles = {\n",
    "        'macs': 'MACs Comparison',\n",
    "        'size_mb': 'Model Size (MB) Comparison',\n",
    "        'accuracy': 'Accuracy (%) Comparison'\n",
    "    }\n",
    "    y_labels = {\n",
    "        'macs': 'MACs (Millions)',\n",
    "        'size_mb': 'Size (MB)',\n",
    "        'accuracy': 'Accuracy (%)'\n",
    "    }\n",
    "\n",
    "    colors = plt.cm.tab10(range(len(strategies)))\n",
    "    for metric in metrics:\n",
    "        values = [results[strategy][metric] / 1e6 if metric == 'macs' else results[strategy][metric]\n",
    "                  for strategy in strategies]  # Convert MACs to millions\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        bars = plt.bar(strategies, values, color=colors)\n",
    "        plt.xlabel('Strategy')\n",
    "        plt.ylabel(y_labels[metric])\n",
    "        plt.title(titles[metric])\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "        # Add value labels\n",
    "        for bar in bars:\n",
    "            yval = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., yval, f'{yval:.2f}', ha='center', va='bottom')\n",
    "\n",
    "        # Add initial model reference line\n",
    "        initial_value = results['initial'][metric] / 1e6 if metric == 'macs' else results['initial'][metric]\n",
    "        plt.axhline(y=initial_value, color='r', linestyle='--', label='Initial')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f'{metric}_comparison.png'))\n",
    "        plt.close()"
   ],
   "id": "5feb4387794b8311",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "23869493d2f36a72",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "615130e04992f7ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:16:06.055631Z",
     "start_time": "2025-04-29T03:16:06.051783Z"
    }
   },
   "source": [
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "bbd2e296738ea559",
   "metadata": {},
   "source": [
    "### Utility function to save the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "b7f8aa766a2fa06a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:16:09.236088Z",
     "start_time": "2025-04-29T03:16:09.229096Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "def save_model(model, path, example_input=None):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    torch.save(model.state_dict(), path)\n",
    "    if example_input is not None:\n",
    "        onnx_path = path.replace('.pth', '.onnx')\n",
    "        save_model_as_onnx(model, example_input, onnx_path)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "89740bc4e512ecde",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "5484dc87c1b63c28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:16:11.100110Z",
     "start_time": "2025-04-29T03:16:11.095824Z"
    }
   },
   "source": [
    "def evaluate_model(model, test_loader, example_input, device):\n",
    "    model.eval()\n",
    "    # Calculate metrics\n",
    "    macs, _ = calculate_macs(model, example_input)\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    size_mb = params * 4 / 1e6\n",
    "\n",
    "    # Calculate accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = [d.to(device) for d in data]\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return {\n",
    "        'macs': macs,\n",
    "        'size_mb': size_mb,\n",
    "        'accuracy': 100 * correct / total\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "78f7147c66b6d346",
   "metadata": {},
   "source": [
    "### Prune the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "6532a7494fc3fcbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:16:15.066099Z",
     "start_time": "2025-04-29T03:16:15.061199Z"
    }
   },
   "source": [
    "def prune_model(model, example_input, target_macs, strategy, iterative_steps=5):\n",
    "    #, iterative_pruning_ratio_scheduler=linear_scheduler()):\n",
    "    if isinstance(strategy['importance'], tp.importance.TaylorImportance):\n",
    "        pruning_ratio = 0.1\n",
    "    else:\n",
    "        pruning_ratio = 0.5\n",
    "\n",
    "    pruner = strategy['pruner'](\n",
    "        model,\n",
    "        example_input,\n",
    "        importance=strategy['importance'],\n",
    "        iterative_steps=iterative_steps,\n",
    "        ch_sparsity=pruning_ratio,  # Initial sparsity\n",
    "        #iterative_pruning_ratio_scheduler=iterative_pruning_ratio_scheduler,\n",
    "        root_module_types=[nn.Conv2d],\n",
    "        ignored_layers=[model.fc],\n",
    "    )\n",
    "\n",
    "    current_macs, base_nparams = calculate_macs(model, example_input)\n",
    "    # while current_macs > target_macs:\n",
    "    #     pruner.step()\n",
    "    #     current_macs = calculate_macs(model, example_input)\n",
    "\n",
    "\n",
    "    for i in range(iterative_steps):\n",
    "            if isinstance(strategy['importance'], tp.importance.TaylorImportance):\n",
    "                loss = model(example_input).sum() # a dummy loss for TaylorImportance\n",
    "                loss.backward()\n",
    "            for g in pruner.step(interactive=True):\n",
    "                g.prune()\n",
    "            macs, nparams = tp.utils.count_ops_and_params(model, example_input)\n",
    "            #print(model(example_input).shape)\n",
    "            print(\n",
    "                \"  Iter %d/%d, Params: %.2f M => %.2f M\"\n",
    "                % (i + 1, iterative_steps, base_nparams / 1e6, nparams / 1e6)\n",
    "            )\n",
    "            print(\n",
    "                \"  Iter %d/%d, MACs: %.2f G => %.2f G\"\n",
    "                % (i + 1, iterative_steps, current_macs / 1e9, macs / 1e9)\n",
    "            )\n",
    "\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "6adb22651c74e5f0",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "a6e1edc8a36e5260",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:16:19.488416Z",
     "start_time": "2025-04-29T03:16:19.481910Z"
    }
   },
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, device, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in train_loader:\n",
    "            inputs, labels = [d.to(device) for d in data]\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}: Loss={epoch_loss:.4f}, Accuracy={epoch_acc:.2f}%\")\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "b26416e6ff76416a",
   "metadata": {},
   "source": [
    "### Main workflow"
   ]
  },
  {
   "cell_type": "code",
   "id": "bdf93b3196076098",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:16:22.218733Z",
     "start_time": "2025-04-29T03:16:22.207538Z"
    }
   },
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'strategies': {\n",
    "            'magnitude': {\n",
    "                'pruner': tp.pruner.MagnitudePruner,\n",
    "                'importance': tp.importance.MagnitudeImportance(p=2),\n",
    "            },\n",
    "            'bn_scale': {\n",
    "                'pruner': tp.pruner.BNScalePruner,\n",
    "                'importance': tp.importance.BNScaleImportance(),\n",
    "            },\n",
    "            # todo: check the examples for the following strategies, why it is giving error\n",
    "            'group_norm': {\n",
    "                'pruner': tp.pruner.GroupNormPruner,\n",
    "                'importance': tp.importance.GroupMagnitudeImportance(p=1),\n",
    "            },\n",
    "            'random': {\n",
    "                'pruner': tp.pruner.MagnitudePruner,\n",
    "                'importance': tp.importance.RandomImportance(),\n",
    "            },\n",
    "            'Taylor': {\n",
    "                'pruner': tp.pruner.MagnitudePruner,\n",
    "                'importance': tp.importance.TaylorImportance()\n",
    "            },\n",
    "            'Hessian': {\n",
    "                'pruner': tp.pruner.MagnitudePruner,\n",
    "                'importance': tp.importance.GroupHessianImportance()\n",
    "            },\n",
    "            'lamp': {\n",
    "                'pruner': tp.pruner.MagnitudePruner,\n",
    "                'importance': tp.importance.LAMPImportance(p=2)\n",
    "            },\n",
    "            'geometry': {\n",
    "                'pruner': tp.pruner.MagnitudePruner,\n",
    "                'importance': tp.importance.FPGMImportance()\n",
    "            },\n",
    "            #todo: implement growing reg pruning\n",
    "        },\n",
    "        #todo: different types of schedulers can be added\n",
    "        #'iterative_pruning_ratio_scheduler': linear_scheduler(),\n",
    "        'target_macs_sparsity': 0.5,\n",
    "        'train_epochs': 10,\n",
    "        'fine_tune_epochs': 20,\n",
    "        'data_dir': './data',\n",
    "        'output_dir': './output/strategies',\n",
    "        'iterative_steps': 5,\n",
    "    }\n",
    "\n",
    "    # Initialize model and data\n",
    "    model = MobileNetV2(num_classes=10).to(device)\n",
    "    train_loader, test_loader = get_data_loaders(config['data_dir'])\n",
    "    example_input = torch.randn(1, 3, 32, 32).to(device) #fixed input\n",
    "\n",
    "    # Workflow execution\n",
    "    initial_model_path = os.path.join(config['output_dir'], \"mobilenetv2_initial.pth\")\n",
    "\n",
    "    if not os.path.exists(initial_model_path):\n",
    "        # 1. Initial training\n",
    "        model = train_model(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            criterion=nn.CrossEntropyLoss().to(device),\n",
    "            optimizer=optim.Adam(model.parameters(), lr=0.001),\n",
    "            device=device,\n",
    "            num_epochs=config['train_epochs']\n",
    "        )\n",
    "        save_model(model, initial_model_path, example_input)\n",
    "\n",
    "    # 2. Pruning and evaluation workflow\n",
    "    results = {}\n",
    "    initial_metrics = evaluate_model(model, test_loader, example_input, device)\n",
    "    results['initial'] = initial_metrics\n",
    "\n",
    "    # Pruning and evaluation workflow\n",
    "    initial_macs, initial_params = calculate_macs(model, example_input)\n",
    "    target_macs = initial_macs * config['target_macs_sparsity']\n",
    "    print(f\"initial value: target_macs={target_macs:.2f}\")\n",
    "    for strategy_name in config['strategies']:\n",
    "        # 2a. Prepare fresh model for each strategy\n",
    "        model_copy = load_model(MobileNetV2(num_classes=10).to(device), initial_model_path)\n",
    "\n",
    "        # 2b. Perform pruning\n",
    "        \"\"\" this it normal pruning without threshold\n",
    "        pruned_model = prune_model(\n",
    "            model=model_copy,\n",
    "            example_input=example_input,\n",
    "            target_macs=target_macs,\n",
    "            strategy=config['strategies'][strategy_name],\n",
    "            iterative_steps=config['iterative_steps'],\n",
    "            #iterative_pruning_ratio_scheduler=config['iterative_pruning_ratio_scheduler'],\n",
    "        ) \"\"\"\n",
    "\n",
    "        pruned_model = gr_prune_model_with_threshold(\n",
    "            model=model_copy,\n",
    "            example_input=example_input,\n",
    "            target_macs=1e9,\n",
    "            target_size_mb=5,\n",
    "            strategy=config['strategies'][strategy_name],\n",
    "            iterative_steps=config['iterative_steps']\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        target_macs_value = 3.0e6\n",
    "        target_params_value = 5.0e6\n",
    "        pruned_model = gem_prune_model_by_threshold(\n",
    "            model=model_copy,\n",
    "            example_input=example_input,\n",
    "            target_macs=target_macs_value,     # <-- Pass target MACs\n",
    "            target_params=target_params_value, # <-- Pass target Params\n",
    "            strategy=config['strategies'][strategy_name],\n",
    "            max_iterations=100, # Adjust as needed\n",
    "            step_ch_sparsity=0.1 # Tune this - smaller might be safer but slower\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "        # 2c. Save pruned model\n",
    "        pruned_path = os.path.join(config['output_dir'], f\"mobilenetv2_{strategy_name}_pruned.pth\")\n",
    "        save_model(pruned_model, pruned_path, example_input)\n",
    "\n",
    "        # 2d. Fine-tune\n",
    "        # todo: lr, more epochs, early stopping\n",
    "        fine_tuned_model = train_model(\n",
    "            model=pruned_model,\n",
    "            train_loader=train_loader,\n",
    "            criterion=nn.CrossEntropyLoss().to(device),\n",
    "            optimizer=optim.Adam(pruned_model.parameters(), lr=0.001),\n",
    "            device=device,\n",
    "            num_epochs=config['fine_tune_epochs']\n",
    "        )\n",
    "\n",
    "        # 2e. Evaluate\n",
    "        results[strategy_name] = evaluate_model(\n",
    "            model=fine_tuned_model,\n",
    "            test_loader=test_loader,\n",
    "            example_input=example_input,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # 2f. Save final model\n",
    "        final_path = os.path.join(config['output_dir'], f\"mobilenetv2_{strategy_name}_final.pth\")\n",
    "        save_model(fine_tuned_model, final_path, example_input)\n",
    "\n",
    "    # 3. Compare results\n",
    "    compare_results_and_plot(results, output_dir=config['output_dir'])\n",
    "    print(\"Workflow completed successfully!\")"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "6d51f760-3726-4028-98a7-02e0105ebd82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:26:14.986520Z",
     "start_time": "2025-04-29T03:16:44.331248Z"
    }
   },
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset directory: /home/muis/thesis/github-repo/master-thesis/cnn/mobile_net_v2/data\n",
      "Epoch 1/10: Loss=1.6614, Accuracy=39.16%\n",
      "Epoch 2/10: Loss=1.3093, Accuracy=53.03%\n",
      "Epoch 3/10: Loss=1.1322, Accuracy=59.75%\n",
      "Epoch 4/10: Loss=0.9907, Accuracy=65.03%\n",
      "Epoch 5/10: Loss=0.8971, Accuracy=68.39%\n",
      "Epoch 6/10: Loss=0.8192, Accuracy=71.20%\n",
      "Epoch 7/10: Loss=0.7558, Accuracy=73.63%\n",
      "Epoch 8/10: Loss=0.7031, Accuracy=75.17%\n",
      "Epoch 9/10: Loss=0.6546, Accuracy=77.06%\n",
      "Epoch 10/10: Loss=0.6158, Accuracy=78.24%\n",
      "âœ… Model saved as ONNX to ./output/strategies/mobilenetv2_initial.onnx\n",
      "initial value: target_macs=3029893.00\n",
      "--- Starting Pruning (Strategy: MagnitudeImportance) ---\n",
      "Target MACs: 3,000,000, Target Params: 5,000,000\n",
      "Initial | MACs: 6,059,786, Params: 1,169,642\n",
      "Iter   1/100 | MACs: 6,059,786 -> 4,924,394 (+18.7%) | Params: 1,169,642 -> 950,314 (+18.8%)\n",
      "Iteration 2: Pruner found no more candidates. Stopping.\n",
      "--- Finished Pruning (Strategy: MagnitudeImportance) ---\n",
      "Initial | MACs: 6,059,786, Params: 1,169,642\n",
      "Final   | MACs: 4,924,394, Params: 950,314\n",
      "Target  | MACs: 3,000,000, Params: 5,000,000\n",
      "Reduction | MACs: 18.74%, Params: 18.75%\n",
      "Warning: Pruning finished, but target threshold(s) were not fully met.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muis/.virtualenvs/master-thesis/lib/python3.12/site-packages/torch_pruning/pruner/algorithms/base_pruner.py:87: UserWarning: ch_sparsity is deprecated in v1.3.0. Please use pruning_ratio.\n",
      "  warnings.warn(\n",
      "/home/muis/.virtualenvs/master-thesis/lib/python3.12/site-packages/torch_pruning/pruner/algorithms/base_pruner.py:407: UserWarning: Pruning exceed the maximum iterative steps, no pruning will be performed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved as ONNX to ./output/strategies/mobilenetv2_magnitude_pruned.onnx\n",
      "Epoch 1/20: Loss=0.6750, Accuracy=76.34%\n",
      "Epoch 2/20: Loss=0.6054, Accuracy=78.79%\n",
      "Epoch 3/20: Loss=0.5644, Accuracy=80.39%\n",
      "Epoch 4/20: Loss=0.5401, Accuracy=80.95%\n",
      "Epoch 5/20: Loss=0.5067, Accuracy=82.10%\n",
      "Epoch 6/20: Loss=0.4807, Accuracy=83.06%\n",
      "Epoch 7/20: Loss=0.4550, Accuracy=84.01%\n",
      "Epoch 8/20: Loss=0.4325, Accuracy=84.81%\n",
      "Epoch 9/20: Loss=0.4146, Accuracy=85.24%\n",
      "Epoch 10/20: Loss=0.3927, Accuracy=86.04%\n",
      "Epoch 11/20: Loss=0.3773, Accuracy=86.65%\n",
      "Epoch 12/20: Loss=0.3663, Accuracy=86.93%\n",
      "Epoch 13/20: Loss=0.3462, Accuracy=87.70%\n",
      "Epoch 14/20: Loss=0.3234, Accuracy=88.44%\n",
      "Epoch 15/20: Loss=0.3160, Accuracy=88.74%\n",
      "Epoch 16/20: Loss=0.2987, Accuracy=89.34%\n",
      "Epoch 17/20: Loss=0.2916, Accuracy=89.60%\n",
      "Epoch 18/20: Loss=0.2796, Accuracy=89.94%\n",
      "Epoch 19/20: Loss=0.2654, Accuracy=90.63%\n",
      "Epoch 20/20: Loss=0.2586, Accuracy=90.67%\n",
      "âœ… Model saved as ONNX to ./output/strategies/mobilenetv2_magnitude_final.onnx\n",
      "--- Starting Pruning (Strategy: BNScaleImportance) ---\n",
      "Target MACs: 3,000,000, Target Params: 5,000,000\n",
      "Initial | MACs: 6,059,786, Params: 1,169,642\n",
      "Iter   1/100 | MACs: 6,059,786 -> 4,924,394 (+18.7%) | Params: 1,169,642 -> 950,314 (+18.8%)\n",
      "Iteration 2: Pruner found no more candidates. Stopping.\n",
      "--- Finished Pruning (Strategy: BNScaleImportance) ---\n",
      "Initial | MACs: 6,059,786, Params: 1,169,642\n",
      "Final   | MACs: 4,924,394, Params: 950,314\n",
      "Target  | MACs: 3,000,000, Params: 5,000,000\n",
      "Reduction | MACs: 18.74%, Params: 18.75%\n",
      "Warning: Pruning finished, but target threshold(s) were not fully met.\n",
      "âœ… Model saved as ONNX to ./output/strategies/mobilenetv2_bn_scale_pruned.onnx\n",
      "Epoch 1/20: Loss=0.6762, Accuracy=76.27%\n",
      "Epoch 2/20: Loss=0.6038, Accuracy=78.83%\n",
      "Epoch 3/20: Loss=0.5698, Accuracy=79.94%\n",
      "Epoch 4/20: Loss=0.5346, Accuracy=81.26%\n",
      "Epoch 5/20: Loss=0.5007, Accuracy=82.22%\n",
      "Epoch 6/20: Loss=0.4808, Accuracy=83.02%\n",
      "Epoch 7/20: Loss=0.4588, Accuracy=83.83%\n",
      "Epoch 8/20: Loss=0.4334, Accuracy=84.53%\n",
      "Epoch 9/20: Loss=0.4140, Accuracy=85.27%\n",
      "Epoch 10/20: Loss=0.3950, Accuracy=85.91%\n",
      "Epoch 11/20: Loss=0.3706, Accuracy=86.81%\n",
      "Epoch 12/20: Loss=0.3609, Accuracy=87.32%\n",
      "Epoch 13/20: Loss=0.3419, Accuracy=87.72%\n",
      "Epoch 14/20: Loss=0.3288, Accuracy=88.48%\n",
      "Epoch 15/20: Loss=0.3151, Accuracy=88.85%\n",
      "Epoch 16/20: Loss=0.2999, Accuracy=89.20%\n",
      "Epoch 17/20: Loss=0.2822, Accuracy=89.95%\n",
      "Epoch 18/20: Loss=0.2767, Accuracy=90.12%\n",
      "Epoch 19/20: Loss=0.2641, Accuracy=90.51%\n",
      "Epoch 20/20: Loss=0.2543, Accuracy=90.80%\n",
      "âœ… Model saved as ONNX to ./output/strategies/mobilenetv2_bn_scale_final.onnx\n",
      "--- Starting Pruning (Strategy: GroupMagnitudeImportance) ---\n",
      "Target MACs: 3,000,000, Target Params: 5,000,000\n",
      "Initial | MACs: 6,059,786, Params: 1,169,642\n",
      "Iter   1/100 | MACs: 6,059,786 -> 4,924,394 (+18.7%) | Params: 1,169,642 -> 950,314 (+18.8%)\n",
      "Iteration 2: Pruner found no more candidates. Stopping.\n",
      "--- Finished Pruning (Strategy: GroupMagnitudeImportance) ---\n",
      "Initial | MACs: 6,059,786, Params: 1,169,642\n",
      "Final   | MACs: 4,924,394, Params: 950,314\n",
      "Target  | MACs: 3,000,000, Params: 5,000,000\n",
      "Reduction | MACs: 18.74%, Params: 18.75%\n",
      "Warning: Pruning finished, but target threshold(s) were not fully met.\n",
      "âœ… Model saved as ONNX to ./output/strategies/mobilenetv2_group_norm_pruned.onnx\n",
      "Epoch 1/20: Loss=0.6718, Accuracy=76.54%\n",
      "Epoch 2/20: Loss=0.6036, Accuracy=78.76%\n",
      "Epoch 3/20: Loss=0.5620, Accuracy=80.11%\n",
      "Epoch 4/20: Loss=0.5293, Accuracy=81.25%\n",
      "Epoch 5/20: Loss=0.5037, Accuracy=82.26%\n",
      "Epoch 6/20: Loss=0.4731, Accuracy=83.48%\n",
      "Epoch 7/20: Loss=0.4493, Accuracy=84.21%\n",
      "Epoch 8/20: Loss=0.4289, Accuracy=84.83%\n",
      "Epoch 9/20: Loss=0.4096, Accuracy=85.55%\n",
      "Epoch 10/20: Loss=0.3903, Accuracy=86.07%\n",
      "Epoch 11/20: Loss=0.3708, Accuracy=86.94%\n",
      "Epoch 12/20: Loss=0.3583, Accuracy=87.25%\n",
      "Epoch 13/20: Loss=0.3322, Accuracy=88.15%\n",
      "Epoch 14/20: Loss=0.3214, Accuracy=88.45%\n",
      "Epoch 15/20: Loss=0.3106, Accuracy=88.93%\n",
      "Epoch 16/20: Loss=0.2959, Accuracy=89.29%\n",
      "Epoch 17/20: Loss=0.2812, Accuracy=89.95%\n",
      "Epoch 18/20: Loss=0.2710, Accuracy=90.17%\n",
      "Epoch 19/20: Loss=0.2622, Accuracy=90.54%\n",
      "Epoch 20/20: Loss=0.2487, Accuracy=91.17%\n",
      "âœ… Model saved as ONNX to ./output/strategies/mobilenetv2_group_norm_final.onnx\n",
      "--- Starting Pruning (Strategy: RandomImportance) ---\n",
      "Target MACs: 3,000,000, Target Params: 5,000,000\n",
      "Initial | MACs: 6,059,786, Params: 1,169,642\n",
      "Iter   1/100 | MACs: 6,059,786 -> 4,924,394 (+18.7%) | Params: 1,169,642 -> 950,314 (+18.8%)\n",
      "Iteration 2: Pruner found no more candidates. Stopping.\n",
      "--- Finished Pruning (Strategy: RandomImportance) ---\n",
      "Initial | MACs: 6,059,786, Params: 1,169,642\n",
      "Final   | MACs: 4,924,394, Params: 950,314\n",
      "Target  | MACs: 3,000,000, Params: 5,000,000\n",
      "Reduction | MACs: 18.74%, Params: 18.75%\n",
      "Warning: Pruning finished, but target threshold(s) were not fully met.\n",
      "âœ… Model saved as ONNX to ./output/strategies/mobilenetv2_random_pruned.onnx\n",
      "Epoch 1/20: Loss=0.7167, Accuracy=74.83%\n",
      "Epoch 2/20: Loss=0.6221, Accuracy=78.20%\n",
      "Epoch 3/20: Loss=0.5792, Accuracy=79.52%\n",
      "Epoch 4/20: Loss=0.5477, Accuracy=80.78%\n",
      "Epoch 5/20: Loss=0.5181, Accuracy=81.59%\n",
      "Epoch 6/20: Loss=0.4898, Accuracy=82.84%\n",
      "Epoch 7/20: Loss=0.4623, Accuracy=83.48%\n",
      "Epoch 8/20: Loss=0.4399, Accuracy=84.42%\n",
      "Epoch 9/20: Loss=0.4182, Accuracy=85.21%\n",
      "Epoch 10/20: Loss=0.4035, Accuracy=85.68%\n",
      "Epoch 11/20: Loss=0.3748, Accuracy=86.67%\n",
      "Epoch 12/20: Loss=0.3601, Accuracy=87.14%\n",
      "Epoch 13/20: Loss=0.3512, Accuracy=87.42%\n",
      "Epoch 14/20: Loss=0.3272, Accuracy=88.37%\n",
      "Epoch 15/20: Loss=0.3216, Accuracy=88.55%\n",
      "Epoch 16/20: Loss=0.3038, Accuracy=89.19%\n",
      "Epoch 17/20: Loss=0.2890, Accuracy=89.67%\n",
      "Epoch 18/20: Loss=0.2843, Accuracy=89.94%\n",
      "Epoch 19/20: Loss=0.2675, Accuracy=90.43%\n",
      "Epoch 20/20: Loss=0.2608, Accuracy=90.62%\n",
      "âœ… Model saved as ONNX to ./output/strategies/mobilenetv2_random_final.onnx\n",
      "--- Starting Pruning (Strategy: TaylorImportance) ---\n",
      "Target MACs: 3,000,000, Target Params: 5,000,000\n",
      "Initial | MACs: 6,059,786, Params: 1,169,642\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 576, 1, 1])",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[18]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[34m__name__\u001B[39m == \u001B[33m\"\u001B[39m\u001B[33m__main__\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 107\u001B[39m, in \u001B[36mmain\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    105\u001B[39m target_macs_value = \u001B[32m3.0e6\u001B[39m\n\u001B[32m    106\u001B[39m target_params_value = \u001B[32m5.0e6\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m107\u001B[39m pruned_model = \u001B[43mgem_prune_model_by_threshold\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    108\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_copy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    109\u001B[39m \u001B[43m    \u001B[49m\u001B[43mexample_input\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexample_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    110\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtarget_macs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtarget_macs_value\u001B[49m\u001B[43m,\u001B[49m\u001B[43m     \u001B[49m\u001B[38;5;66;43;03m# <-- Pass target MACs\u001B[39;49;00m\n\u001B[32m    111\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtarget_params\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtarget_params_value\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# <-- Pass target Params\u001B[39;49;00m\n\u001B[32m    112\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstrategy\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mstrategies\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43mstrategy_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    113\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_iterations\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# Adjust as needed\u001B[39;49;00m\n\u001B[32m    114\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstep_ch_sparsity\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.1\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# Tune this - smaller might be safer but slower\u001B[39;49;00m\n\u001B[32m    115\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    117\u001B[39m \u001B[38;5;66;03m# 2c. Save pruned model\u001B[39;00m\n\u001B[32m    118\u001B[39m pruned_path = os.path.join(config[\u001B[33m'\u001B[39m\u001B[33moutput_dir\u001B[39m\u001B[33m'\u001B[39m], \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mmobilenetv2_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstrategy_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m_pruned.pth\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 66\u001B[39m, in \u001B[36mgem_prune_model_by_threshold\u001B[39m\u001B[34m(model, example_input, target_macs, target_params, strategy, max_iterations, step_ch_sparsity)\u001B[39m\n\u001B[32m     63\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m param \u001B[38;5;129;01min\u001B[39;00m model.parameters():\n\u001B[32m     64\u001B[39m     param.requires_grad_(\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m---> \u001B[39m\u001B[32m66\u001B[39m loss = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexample_input\u001B[49m\u001B[43m)\u001B[49m.mean() \u001B[38;5;66;03m# Use mean or sum as dummy loss\u001B[39;00m\n\u001B[32m     67\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     68\u001B[39m     loss.backward() \u001B[38;5;66;03m# Calculate gradients needed for importance\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.virtualenvs/master-thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.virtualenvs/master-thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 34\u001B[39m, in \u001B[36mMobileNetV2.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     32\u001B[39m x = \u001B[38;5;28mself\u001B[39m.block4(x)\n\u001B[32m     33\u001B[39m x = \u001B[38;5;28mself\u001B[39m.block5(x)\n\u001B[32m---> \u001B[39m\u001B[32m34\u001B[39m x = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mblock6\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     35\u001B[39m x = \u001B[38;5;28mself\u001B[39m.block7(x)\n\u001B[32m     37\u001B[39m x = \u001B[38;5;28mself\u001B[39m.conv2(x)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.virtualenvs/master-thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.virtualenvs/master-thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 29\u001B[39m, in \u001B[36mInvertedResidual.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     26\u001B[39m out = \u001B[38;5;28mself\u001B[39m.relu(out)\n\u001B[32m     28\u001B[39m out = \u001B[38;5;28mself\u001B[39m.conv2(out)\n\u001B[32m---> \u001B[39m\u001B[32m29\u001B[39m out = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbn2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     30\u001B[39m out = \u001B[38;5;28mself\u001B[39m.relu(out)\n\u001B[32m     32\u001B[39m out = \u001B[38;5;28mself\u001B[39m.conv3(out)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.virtualenvs/master-thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.virtualenvs/master-thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.virtualenvs/master-thesis/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193\u001B[39m, in \u001B[36m_BatchNorm.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    186\u001B[39m     bn_training = (\u001B[38;5;28mself\u001B[39m.running_mean \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m.running_var \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    188\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    189\u001B[39m \u001B[33;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001B[39;00m\n\u001B[32m    190\u001B[39m \u001B[33;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001B[39;00m\n\u001B[32m    191\u001B[39m \u001B[33;03mused for normalization (i.e. in eval mode when buffers are not None).\u001B[39;00m\n\u001B[32m    192\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m193\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbatch_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    194\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    195\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001B[39;49;00m\n\u001B[32m    196\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrunning_mean\u001B[49m\n\u001B[32m    197\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtrack_running_stats\u001B[49m\n\u001B[32m    198\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    199\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrunning_var\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtrack_running_stats\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    200\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    201\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    202\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbn_training\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    203\u001B[39m \u001B[43m    \u001B[49m\u001B[43mexponential_average_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    204\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    205\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.virtualenvs/master-thesis/lib/python3.12/site-packages/torch/nn/functional.py:2820\u001B[39m, in \u001B[36mbatch_norm\u001B[39m\u001B[34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001B[39m\n\u001B[32m   2807\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m   2808\u001B[39m         batch_norm,\n\u001B[32m   2809\u001B[39m         (\u001B[38;5;28minput\u001B[39m, running_mean, running_var, weight, bias),\n\u001B[32m   (...)\u001B[39m\u001B[32m   2817\u001B[39m         eps=eps,\n\u001B[32m   2818\u001B[39m     )\n\u001B[32m   2819\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m training:\n\u001B[32m-> \u001B[39m\u001B[32m2820\u001B[39m     \u001B[43m_verify_batch_size\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2822\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m torch.batch_norm(\n\u001B[32m   2823\u001B[39m     \u001B[38;5;28minput\u001B[39m,\n\u001B[32m   2824\u001B[39m     weight,\n\u001B[32m   (...)\u001B[39m\u001B[32m   2831\u001B[39m     torch.backends.cudnn.enabled,\n\u001B[32m   2832\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.virtualenvs/master-thesis/lib/python3.12/site-packages/torch/nn/functional.py:2786\u001B[39m, in \u001B[36m_verify_batch_size\u001B[39m\u001B[34m(size)\u001B[39m\n\u001B[32m   2784\u001B[39m     size_prods *= size[i + \u001B[32m2\u001B[39m]\n\u001B[32m   2785\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m size_prods == \u001B[32m1\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m2786\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   2787\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mExpected more than 1 value per channel when training, got input size \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msize\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m   2788\u001B[39m     )\n",
      "\u001B[31mValueError\u001B[39m: Expected more than 1 value per channel when training, got input size torch.Size([1, 576, 1, 1])"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load the saved Onnx model and convert to Pytorch model",
   "id": "238badca29395cae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T12:24:13.022499Z",
     "start_time": "2025-04-10T12:24:12.993796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from onnx2torch import convert\n",
    "\n",
    "# Step 1: Load the ONNX model\n",
    "onnx_model_path = './output/strategies/mobilenetv2_bn_scale_final.onnx'\n",
    "onnx_model = onnx.load(onnx_model_path)\n",
    "onnx.checker.check_model(onnx_model)  # Verify the ONNX model\n",
    "print(\"âœ… ONNX model loaded and verified.\")\n",
    "\n",
    "# Step 2: Convert ONNX to PyTorch\n",
    "torch_model = convert(onnx_model)\n",
    "print(\"âœ… ONNX model converted to PyTorch.\")\n",
    "tp.utils.print_tool.before_pruning(torch_model)\n"
   ],
   "id": "229d26f48f444268",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ONNX model loaded and verified.\n",
      "âœ… ONNX model converted to PyTorch.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T12:24:21.518145Z",
     "start_time": "2025-04-10T12:24:21.512261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchinfo import summary\n",
    "print(summary(torch_model))"
   ],
   "id": "38ba67685c8f9c69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "GraphModule                                             --\n",
      "â”œâ”€Conv2d: 1-1                                           448\n",
      "â”œâ”€OnnxConstant: 1-2                                     --\n",
      "â”œâ”€OnnxConstant: 1-3                                     --\n",
      "â”œâ”€ReLU6: 1-4                                            --\n",
      "â”œâ”€Conv2d: 1-5                                           1,632\n",
      "â”œâ”€OnnxConstant: 1-6                                     --\n",
      "â”œâ”€OnnxConstant: 1-7                                     --\n",
      "â”œâ”€ReLU6: 1-8                                            --\n",
      "â”œâ”€Conv2d: 1-9                                           960\n",
      "â”œâ”€OnnxConstant: 1-10                                    --\n",
      "â”œâ”€OnnxConstant: 1-11                                    --\n",
      "â”œâ”€ReLU6: 1-12                                           --\n",
      "â”œâ”€Conv2d: 1-13                                          776\n",
      "â”œâ”€Conv2d: 1-14                                          432\n",
      "â”œâ”€OnnxConstant: 1-15                                    --\n",
      "â”œâ”€OnnxConstant: 1-16                                    --\n",
      "â”œâ”€ReLU6: 1-17                                           --\n",
      "â”œâ”€Conv2d: 1-18                                          480\n",
      "â”œâ”€OnnxConstant: 1-19                                    --\n",
      "â”œâ”€OnnxConstant: 1-20                                    --\n",
      "â”œâ”€ReLU6: 1-21                                           --\n",
      "â”œâ”€Conv2d: 1-22                                          588\n",
      "â”œâ”€Conv2d: 1-23                                          936\n",
      "â”œâ”€OnnxConstant: 1-24                                    --\n",
      "â”œâ”€OnnxConstant: 1-25                                    --\n",
      "â”œâ”€ReLU6: 1-26                                           --\n",
      "â”œâ”€Conv2d: 1-27                                          720\n",
      "â”œâ”€OnnxConstant: 1-28                                    --\n",
      "â”œâ”€OnnxConstant: 1-29                                    --\n",
      "â”œâ”€ReLU6: 1-30                                           --\n",
      "â”œâ”€Conv2d: 1-31                                          1,168\n",
      "â”œâ”€Conv2d: 1-32                                          1,632\n",
      "â”œâ”€OnnxConstant: 1-33                                    --\n",
      "â”œâ”€OnnxConstant: 1-34                                    --\n",
      "â”œâ”€ReLU6: 1-35                                           --\n",
      "â”œâ”€Conv2d: 1-36                                          960\n",
      "â”œâ”€OnnxConstant: 1-37                                    --\n",
      "â”œâ”€OnnxConstant: 1-38                                    --\n",
      "â”œâ”€ReLU6: 1-39                                           --\n",
      "â”œâ”€Conv2d: 1-40                                          3,104\n",
      "â”œâ”€Conv2d: 1-41                                          6,336\n",
      "â”œâ”€OnnxConstant: 1-42                                    --\n",
      "â”œâ”€OnnxConstant: 1-43                                    --\n",
      "â”œâ”€ReLU6: 1-44                                           --\n",
      "â”œâ”€Conv2d: 1-45                                          1,920\n",
      "â”œâ”€OnnxConstant: 1-46                                    --\n",
      "â”œâ”€OnnxConstant: 1-47                                    --\n",
      "â”œâ”€ReLU6: 1-48                                           --\n",
      "â”œâ”€Conv2d: 1-49                                          9,264\n",
      "â”œâ”€Conv2d: 1-50                                          14,112\n",
      "â”œâ”€OnnxConstant: 1-51                                    --\n",
      "â”œâ”€OnnxConstant: 1-52                                    --\n",
      "â”œâ”€ReLU6: 1-53                                           --\n",
      "â”œâ”€Conv2d: 1-54                                          2,880\n",
      "â”œâ”€OnnxConstant: 1-55                                    --\n",
      "â”œâ”€OnnxConstant: 1-56                                    --\n",
      "â”œâ”€ReLU6: 1-57                                           --\n",
      "â”œâ”€Conv2d: 1-58                                          23,120\n",
      "â”œâ”€Conv2d: 1-59                                          38,880\n",
      "â”œâ”€OnnxConstant: 1-60                                    --\n",
      "â”œâ”€OnnxConstant: 1-61                                    --\n",
      "â”œâ”€ReLU6: 1-62                                           --\n",
      "â”œâ”€Conv2d: 1-63                                          4,800\n",
      "â”œâ”€OnnxConstant: 1-64                                    --\n",
      "â”œâ”€OnnxConstant: 1-65                                    --\n",
      "â”œâ”€ReLU6: 1-66                                           --\n",
      "â”œâ”€Conv2d: 1-67                                          76,960\n",
      "â”œâ”€Conv2d: 1-68                                          103,040\n",
      "â”œâ”€OnnxConstant: 1-69                                    --\n",
      "â”œâ”€OnnxConstant: 1-70                                    --\n",
      "â”œâ”€ReLU6: 1-71                                           --\n",
      "â”œâ”€OnnxGlobalAveragePoolWithKnownInputShape: 1-72        --\n",
      "â”œâ”€Flatten: 1-73                                         --\n",
      "â”œâ”€Linear: 1-74                                          6,410\n",
      "================================================================================\n",
      "Total params: 301,558\n",
      "Trainable params: 301,558\n",
      "Non-trainable params: 0\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T10:39:54.201742Z",
     "start_time": "2025-04-10T10:39:54.150874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from torchinfo import summary\n",
    "print(summary(torch_model))\n",
    "#tp.utils.print_tool.after_pruning(torch_model)\n"
   ],
   "id": "4d1dd20bc238d90a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "GraphModule                                             --\n",
      "â”œâ”€Conv2d: 1-1                                           896\n",
      "â”œâ”€OnnxConstant: 1-2                                     --\n",
      "â”œâ”€OnnxConstant: 1-3                                     --\n",
      "â”œâ”€ReLU6: 1-4                                            --\n",
      "â”œâ”€Conv2d: 1-5                                           6,336\n",
      "â”œâ”€OnnxConstant: 1-6                                     --\n",
      "â”œâ”€OnnxConstant: 1-7                                     --\n",
      "â”œâ”€ReLU6: 1-8                                            --\n",
      "â”œâ”€Conv2d: 1-9                                           1,920\n",
      "â”œâ”€OnnxConstant: 1-10                                    --\n",
      "â”œâ”€OnnxConstant: 1-11                                    --\n",
      "â”œâ”€ReLU6: 1-12                                           --\n",
      "â”œâ”€Conv2d: 1-13                                          3,088\n",
      "â”œâ”€Conv2d: 1-14                                          1,632\n",
      "â”œâ”€OnnxConstant: 1-15                                    --\n",
      "â”œâ”€OnnxConstant: 1-16                                    --\n",
      "â”œâ”€ReLU6: 1-17                                           --\n",
      "â”œâ”€Conv2d: 1-18                                          960\n",
      "â”œâ”€OnnxConstant: 1-19                                    --\n",
      "â”œâ”€OnnxConstant: 1-20                                    --\n",
      "â”œâ”€ReLU6: 1-21                                           --\n",
      "â”œâ”€Conv2d: 1-22                                          2,328\n",
      "â”œâ”€Conv2d: 1-23                                          3,600\n",
      "â”œâ”€OnnxConstant: 1-24                                    --\n",
      "â”œâ”€OnnxConstant: 1-25                                    --\n",
      "â”œâ”€ReLU6: 1-26                                           --\n",
      "â”œâ”€Conv2d: 1-27                                          1,440\n",
      "â”œâ”€OnnxConstant: 1-28                                    --\n",
      "â”œâ”€OnnxConstant: 1-29                                    --\n",
      "â”œâ”€ReLU6: 1-30                                           --\n",
      "â”œâ”€Conv2d: 1-31                                          4,640\n",
      "â”œâ”€Conv2d: 1-32                                          6,336\n",
      "â”œâ”€OnnxConstant: 1-33                                    --\n",
      "â”œâ”€OnnxConstant: 1-34                                    --\n",
      "â”œâ”€ReLU6: 1-35                                           --\n",
      "â”œâ”€Conv2d: 1-36                                          1,920\n",
      "â”œâ”€OnnxConstant: 1-37                                    --\n",
      "â”œâ”€OnnxConstant: 1-38                                    --\n",
      "â”œâ”€ReLU6: 1-39                                           --\n",
      "â”œâ”€Conv2d: 1-40                                          12,352\n",
      "â”œâ”€Conv2d: 1-41                                          24,960\n",
      "â”œâ”€OnnxConstant: 1-42                                    --\n",
      "â”œâ”€OnnxConstant: 1-43                                    --\n",
      "â”œâ”€ReLU6: 1-44                                           --\n",
      "â”œâ”€Conv2d: 1-45                                          3,840\n",
      "â”œâ”€OnnxConstant: 1-46                                    --\n",
      "â”œâ”€OnnxConstant: 1-47                                    --\n",
      "â”œâ”€ReLU6: 1-48                                           --\n",
      "â”œâ”€Conv2d: 1-49                                          36,960\n",
      "â”œâ”€Conv2d: 1-50                                          55,872\n",
      "â”œâ”€OnnxConstant: 1-51                                    --\n",
      "â”œâ”€OnnxConstant: 1-52                                    --\n",
      "â”œâ”€ReLU6: 1-53                                           --\n",
      "â”œâ”€Conv2d: 1-54                                          5,760\n",
      "â”œâ”€OnnxConstant: 1-55                                    --\n",
      "â”œâ”€OnnxConstant: 1-56                                    --\n",
      "â”œâ”€ReLU6: 1-57                                           --\n",
      "â”œâ”€Conv2d: 1-58                                          92,320\n",
      "â”œâ”€Conv2d: 1-59                                          154,560\n",
      "â”œâ”€OnnxConstant: 1-60                                    --\n",
      "â”œâ”€OnnxConstant: 1-61                                    --\n",
      "â”œâ”€ReLU6: 1-62                                           --\n",
      "â”œâ”€Conv2d: 1-63                                          9,600\n",
      "â”œâ”€OnnxConstant: 1-64                                    --\n",
      "â”œâ”€OnnxConstant: 1-65                                    --\n",
      "â”œâ”€ReLU6: 1-66                                           --\n",
      "â”œâ”€Conv2d: 1-67                                          307,520\n",
      "â”œâ”€Conv2d: 1-68                                          410,880\n",
      "â”œâ”€OnnxConstant: 1-69                                    --\n",
      "â”œâ”€OnnxConstant: 1-70                                    --\n",
      "â”œâ”€ReLU6: 1-71                                           --\n",
      "â”œâ”€OnnxGlobalAveragePoolWithKnownInputShape: 1-72        --\n",
      "â”œâ”€Flatten: 1-73                                         --\n",
      "â”œâ”€Linear: 1-74                                          12,810\n",
      "================================================================================\n",
      "Total params: 1,162,530\n",
      "Trainable params: 1,162,530\n",
      "Non-trainable params: 0\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load the converted Pytorch model and fine-tune",
   "id": "8de5ca7f1456a3d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:41:44.435126Z",
     "start_time": "2025-04-09T13:37:33.019618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader, test_loader = get_data_loaders('./data')\n",
    "# Example usage\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch_model = torch_model.to(device)\n",
    "\n",
    "tp.utils.print_tool.before_pruning(torch_model)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(torch_model.parameters(), lr=0.001)\n",
    "num_epochs = 50\n",
    "\n",
    "fine_tuned_model = train_model(torch_model, train_loader, criterion, optimizer, device, num_epochs)"
   ],
   "id": "e1ece7efcc1c6179",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset directory: /home/muis/thesis/github-repo/master-thesis/cnn/mobile_net_v2/data\n",
      "Epoch 1/50: Loss=0.6039, Accuracy=78.76%\n",
      "Epoch 2/50: Loss=0.6009, Accuracy=78.70%\n",
      "Epoch 3/50: Loss=0.5960, Accuracy=78.91%\n",
      "Epoch 4/50: Loss=0.5975, Accuracy=78.81%\n",
      "Epoch 5/50: Loss=0.5957, Accuracy=78.92%\n",
      "Epoch 6/50: Loss=0.5969, Accuracy=78.82%\n",
      "Epoch 7/50: Loss=0.6109, Accuracy=78.42%\n",
      "Epoch 8/50: Loss=0.6080, Accuracy=78.65%\n",
      "Epoch 9/50: Loss=0.6081, Accuracy=78.52%\n",
      "Epoch 10/50: Loss=0.6090, Accuracy=78.53%\n",
      "Epoch 11/50: Loss=0.6294, Accuracy=77.73%\n",
      "Epoch 12/50: Loss=0.6354, Accuracy=77.75%\n",
      "Epoch 13/50: Loss=0.6369, Accuracy=77.76%\n",
      "Epoch 14/50: Loss=0.6398, Accuracy=77.80%\n",
      "Epoch 15/50: Loss=0.6449, Accuracy=77.49%\n",
      "Epoch 16/50: Loss=0.6451, Accuracy=77.21%\n",
      "Epoch 17/50: Loss=0.6569, Accuracy=76.93%\n",
      "Epoch 18/50: Loss=0.6594, Accuracy=76.96%\n",
      "Epoch 19/50: Loss=0.6644, Accuracy=76.68%\n",
      "Epoch 20/50: Loss=0.6890, Accuracy=76.04%\n",
      "Epoch 21/50: Loss=0.7159, Accuracy=75.11%\n",
      "Epoch 22/50: Loss=0.7258, Accuracy=74.65%\n",
      "Epoch 23/50: Loss=0.7349, Accuracy=74.31%\n",
      "Epoch 24/50: Loss=0.7270, Accuracy=74.58%\n",
      "Epoch 25/50: Loss=0.7467, Accuracy=74.14%\n",
      "Epoch 26/50: Loss=0.7675, Accuracy=73.00%\n",
      "Epoch 27/50: Loss=0.8084, Accuracy=72.25%\n",
      "Epoch 28/50: Loss=0.7989, Accuracy=72.42%\n",
      "Epoch 29/50: Loss=0.8117, Accuracy=72.01%\n",
      "Epoch 30/50: Loss=0.8219, Accuracy=71.50%\n",
      "Epoch 31/50: Loss=0.8353, Accuracy=71.06%\n",
      "Epoch 32/50: Loss=0.8406, Accuracy=70.78%\n",
      "Epoch 33/50: Loss=0.8447, Accuracy=71.01%\n",
      "Epoch 34/50: Loss=0.8858, Accuracy=69.39%\n",
      "Epoch 35/50: Loss=0.8922, Accuracy=69.14%\n",
      "Epoch 36/50: Loss=0.8901, Accuracy=69.15%\n",
      "Epoch 37/50: Loss=0.8982, Accuracy=68.85%\n",
      "Epoch 38/50: Loss=0.9320, Accuracy=67.87%\n",
      "Epoch 39/50: Loss=0.9501, Accuracy=67.43%\n",
      "Epoch 40/50: Loss=0.9214, Accuracy=68.09%\n",
      "Epoch 41/50: Loss=0.9657, Accuracy=66.49%\n",
      "Epoch 42/50: Loss=1.0036, Accuracy=65.34%\n",
      "Epoch 43/50: Loss=1.1095, Accuracy=61.36%\n",
      "Epoch 44/50: Loss=1.0304, Accuracy=64.18%\n",
      "Epoch 45/50: Loss=1.0052, Accuracy=65.13%\n",
      "Epoch 46/50: Loss=1.0153, Accuracy=64.64%\n",
      "Epoch 47/50: Loss=1.0694, Accuracy=63.06%\n",
      "Epoch 48/50: Loss=1.0667, Accuracy=62.99%\n",
      "Epoch 49/50: Loss=1.0831, Accuracy=62.41%\n",
      "Epoch 50/50: Loss=1.1073, Accuracy=61.28%\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Plotting params results",
   "id": "4a2269b7d3b40915"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:05:22.667967Z",
     "start_time": "2025-04-10T13:05:22.317180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data: Total parameters for each model\n",
    "strategies = ['Initial', 'Magnitude', 'BN Scale', 'Group Norm', 'Random', 'Taylor', 'Hessian', 'Lamp']\n",
    "params = [\n",
    "    1162530,  # Initial model (from your query)\n",
    "    305350,   # Magnitude (from output: 0.31M after pruning, assuming final tuned model)\n",
    "    301558,   # BN Scale (from your query and output: 0.31M after pruning)\n",
    "    305350,   # Group Norm (from output: 0.31M after pruning, assuming similar to magnitude)\n",
    "    305350,   # Random (from output: 0.31M after pruning, assuming similar to magnitude)\n",
    "    949650,   # Taylor (from output: 0.95M after pruning)\n",
    "    1162530,  # Hessian (from output: 1.17M, no reduction observed)\n",
    "    305350    # Lamp (from output: 0.31M after pruning)\n",
    "]\n",
    "initial_params = params[0]\n",
    "\n",
    "# Calculate percentage reduction for each strategy\n",
    "reductions = [((initial_params - p) / initial_params * 100) for p in params]\n",
    "\n",
    "# Colors for each strategy\n",
    "colors = ['gray', 'blue', 'green', 'red', 'purple', 'orange', 'brown', 'pink']\n",
    "\n",
    "# Create bar chart\n",
    "plt.figure(figsize=(14, 8))\n",
    "bars = plt.bar(strategies, params, color=colors)\n",
    "\n",
    "# Add value labels and percentage reduction\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:,}\\n({reductions[i]:.1f}%)' if i > 0 else f'{height:,}',\n",
    "             ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Add horizontal line for initial parameters\n",
    "plt.axhline(y=initial_params, color='gray', linestyle='--', label='Initial Parameters')\n",
    "\n",
    "# Customize the chart\n",
    "plt.xlabel('Pruning Strategy')\n",
    "plt.ylabel('Total Parameters')\n",
    "plt.title('Comparison of Total Parameters Across Pruning Strategies')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the chart to a file (since we're not displaying it interactively)\n",
    "plt.savefig('output/pruning_comparison.png')"
   ],
   "id": "4e570a6196c46943",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### comparison for MACs, params, size_mb",
   "id": "ed3546bf41b88f86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:12:58.906564Z",
     "start_time": "2025-04-10T14:12:58.499793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data: Metrics for each model\n",
    "strategies = ['Initial', 'Magnitude', 'BN Scale', 'Group Norm', 'Random', 'Taylor', 'Hessian', 'Lamp']\n",
    "metrics = {\n",
    "    'params': [1162530, 305350, 301558, 305350, 305350, 949650, 1162530, 305350],  # Total parameters\n",
    "    'macs': [6060000, 1840000, 1840000, 1840000, 1840000, 4920000, 6060000, 1840000],  # MACs\n",
    "    'size_mb': [4.68, 1.22, 1.22, 1.22, 1.22, 3.80, 4.68, 1.22]  # Model size in MB\n",
    "}\n",
    "initial_metrics = {k: v[0] for k, v in metrics.items()}\n",
    "\n",
    "# Calculate percentage reductions\n",
    "reductions = {k: [((initial_metrics[k] - v) / initial_metrics[k] * 100) for v in values] for k, values in metrics.items()}\n",
    "\n",
    "# Colors for each strategy\n",
    "colors = ['gray', 'blue', 'green', 'red', 'purple', 'orange', 'brown', 'pink']\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 18))\n",
    "\n",
    "# Plot each metric\n",
    "for i, (metric_name, values) in enumerate(metrics.items()):\n",
    "    ax = axes[i]\n",
    "    bars = ax.bar(strategies, values, color=colors)\n",
    "\n",
    "    # Add value labels and percentage reduction\n",
    "    for j, bar in enumerate(bars):\n",
    "        height = bar.get_height()\n",
    "        label = f'{height:,}' if metric_name != 'size_mb' else f'{height:.2f}'\n",
    "        if j > 0:\n",
    "            label += f'\\n({reductions[metric_name][j]:.1f}%)'\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height, label, ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    # Add horizontal line for initial metric\n",
    "    ax.axhline(y=initial_metrics[metric_name], color='gray', linestyle='--', label='Initial')\n",
    "\n",
    "    # Customize subplot\n",
    "    ax.set_xlabel('Pruning Strategy')\n",
    "    ax.set_ylabel(metric_name.replace('_', ' ').title())\n",
    "    ax.set_title(f'Comparison of {metric_name.replace(\"_\", \" \").title()} Across Pruning Strategies')\n",
    "    ax.set_xticks(range(len(strategies)))\n",
    "    ax.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "\n",
    "# Adjust layout and save\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/pruning_metrics_comparison.png')"
   ],
   "id": "24effc323e5da8",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T19:10:40.275735Z",
     "start_time": "2025-04-15T19:10:39.666362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "epochs = list(range(1, 11))\n",
    "train_acc = [18.48, 21.53, 21.21, 23.94, 26.32, 29.75, 31.91, 34.05, 36.34, 36.77]\n",
    "valid_acc = [21.93, 20.94, 22.23, 25.33, 27.88, 30.41, 33.33, 35.23, 37.02, 38.57]\n",
    "test_acc = [21.90, 21.01, 22.10, 24.86, 27.84, 31.08, 33.47, 35.38, 37.53, 38.45]\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "bar_width = 0.25\n",
    "x = np.arange(len(epochs))\n",
    "\n",
    "# Create bars\n",
    "plt.bar(x - bar_width, train_acc, bar_width, label='Train Accuracy', color='skyblue')\n",
    "plt.bar(x, valid_acc, bar_width, label='Validation Accuracy', color='lightgreen')\n",
    "plt.bar(x + bar_width, test_acc, bar_width, label='Test Accuracy', color='salmon')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Model Accuracy per Epoch')\n",
    "plt.xticks(x, epochs)\n",
    "plt.legend()\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('darts_accuracy_bar_plot.png')"
   ],
   "id": "6946f1a5fde43aaf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Gr: prune with threshold",
   "id": "77dea4c672dce55"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T22:44:49.695761Z",
     "start_time": "2025-04-28T22:44:49.686055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#def gr_prune_model_with_threshold(model, example_input, target_macs, target_size_mb, strategy, max_iterative_steps=20, max_sparsity=0.9):\n",
    "def gr_prune_model_with_threshold(model, example_input, target_macs, target_size_mb, strategy, iterative_steps=5):\n",
    "    \"\"\"\n",
    "    Prune the model based on the specified strategy and targets.\n",
    "    \"\"\"\n",
    "    # Calculate initial metrics\n",
    "    current_macs, nparams = tp.utils.count_ops_and_params(model, example_input)\n",
    "    current_size_mb = sum(p.numel() * p.element_size() for p in model.parameters()) / (1024 ** 2)\n",
    "\n",
    "    print(f\"Initial MACs: {current_macs / 1e9:.3f} G, Size: {current_size_mb:.2f} MB\")\n",
    "\n",
    "    # Define pruning ratio (adjust based on targets if needed)\n",
    "    pruning_ratio = 0.5  # Example: 50% sparsity, adjust as needed\n",
    "\n",
    "    if isinstance(strategy['importance'], tp.importance.TaylorImportance):\n",
    "        # TaylorImportance requires gradients per step\n",
    "        pruner = strategy['pruner'](\n",
    "            model,\n",
    "            example_input,\n",
    "            importance=strategy['importance'],\n",
    "            iterative_steps=1,  # Handle iterations manually\n",
    "            ch_sparsity=pruning_ratio / iterative_steps,  # Prune a portion each step\n",
    "            root_module_types=[nn.Conv2d],\n",
    "            ignored_layers=[model.fc]\n",
    "        )\n",
    "        for i in range(iterative_steps):\n",
    "            model.zero_grad()\n",
    "            loss = model(example_input).sum()  # Dummy loss for gradients\n",
    "            loss.backward()\n",
    "            pruner.step()  # Apply pruning for this step\n",
    "            current_macs, _ = tp.utils.count_ops_and_params(model, example_input)\n",
    "            current_size_mb = sum(p.numel() * p.element_size() for p in model.parameters()) / (1024 ** 2)\n",
    "            print(f\"Step {i+1}/{iterative_steps}: MACs {current_macs / 1e9:.3f} G, Size {current_size_mb:.2f} MB\")\n",
    "            if current_macs <= target_macs and current_size_mb <= target_size_mb:\n",
    "                print(f\"Targets reached at step {i+1}\")\n",
    "                break\n",
    "            model.zero_grad()\n",
    "    else:\n",
    "        # Other strategies can prune in one go with iterative_steps\n",
    "        pruner = strategy['pruner'](\n",
    "            model,\n",
    "            example_input,\n",
    "            importance=strategy['importance'],\n",
    "            iterative_steps=iterative_steps,\n",
    "            ch_sparsity=pruning_ratio,\n",
    "            root_module_types=[nn.Conv2d],\n",
    "            ignored_layers=[model.fc]\n",
    "        )\n",
    "        pruner.step()  # Perform pruning over all steps\n",
    "        current_macs, _ = tp.utils.count_ops_and_params(model, example_input)\n",
    "        current_size_mb = sum(p.numel() * p.element_size() for p in model.parameters()) / (1024 ** 2)\n",
    "        print(f\"After pruning: MACs {current_macs / 1e9:.3f} G, Size {current_size_mb:.2f} MB\")\n",
    "\n",
    "    # Final check\n",
    "    if current_macs <= target_macs and current_size_mb <= target_size_mb:\n",
    "        print(\"Pruning targets achieved.\")\n",
    "    else:\n",
    "        print(\"Warning: Pruning targets not fully achieved.\")\n",
    "\n",
    "    return model"
   ],
   "id": "59ea3f26d421e293",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Gem: Prune with threshold",
   "id": "ed9159eb03e0d570"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:15:38.633900Z",
     "start_time": "2025-04-29T03:15:38.623094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time # Optional: for adding time limits or tracking\n",
    "\n",
    "# Assume calculate_macs is defined as before:\n",
    "# def calculate_macs(model, example_input):\n",
    "#     macs, params = tp.utils.count_ops_and_params(model, example_input)\n",
    "#     return macs, params\n",
    "\n",
    "def gem_prune_model_by_threshold(model, example_input, target_macs, target_params, strategy, max_iterations=100, step_ch_sparsity=0.1):\n",
    "    \"\"\"\n",
    "    Prunes the model iteratively until both MACs and parameter count are below\n",
    "    the specified thresholds, or max_iterations is reached.\n",
    "\n",
    "    Args:\n",
    "        model: The PyTorch model to prune.\n",
    "        example_input: Example input tensor for MACs calculation and pruner.\n",
    "        target_macs: The desired maximum MAC count.\n",
    "        target_params: The desired maximum parameter count.\n",
    "        strategy: Dictionary containing 'pruner' and 'importance'.\n",
    "        max_iterations (int): Safety limit for the number of pruning steps.\n",
    "        step_ch_sparsity (float): Channel sparsity target for each individual pruning step.\n",
    "                                  Influences how many candidates `pruner.step` proposes.\n",
    "                                  Smaller values lead to potentially finer steps.\n",
    "\n",
    "    Returns:\n",
    "        The pruned model.\n",
    "    \"\"\"\n",
    "    device = example_input.device\n",
    "    model.to(device) # Ensure model is on the correct device\n",
    "\n",
    "    print(f\"--- Starting Pruning (Strategy: {strategy['importance'].__class__.__name__}) ---\")\n",
    "    print(f\"Target MACs: {target_macs:,.0f}, Target Params: {target_params:,.0f}\")\n",
    "\n",
    "    # Instantiate the pruner\n",
    "    # Note: 'iterative_steps' in init is less critical here as the while loop controls iteration.\n",
    "    pruner = strategy['pruner'](\n",
    "        model,\n",
    "        example_input,\n",
    "        importance=strategy['importance'],\n",
    "        ch_sparsity=step_ch_sparsity, # Target sparsity *per step*\n",
    "        root_module_types=[nn.Conv2d], # Focus pruning on Conv layers\n",
    "        ignored_layers=[model.fc], # Don't prune the final classifier\n",
    "        # Optional: other pruner args like round_to might be useful depending on strategy/model\n",
    "        # round_to=8, # Example: commonly used for hardware efficiency\n",
    "    )\n",
    "\n",
    "    # Get initial state\n",
    "    current_macs, current_params = calculate_macs(model, example_input)\n",
    "    initial_macs, initial_params = current_macs, current_params # Keep for logging\n",
    "    print(f\"Initial | MACs: {current_macs:,.0f}, Params: {current_params:,.0f}\")\n",
    "\n",
    "    iteration = 0\n",
    "    model.eval() # Ensure model is in eval mode for pruning logic unless Taylor\n",
    "\n",
    "    while (current_macs > target_macs or current_params > target_params) and iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        macs_before_step = current_macs\n",
    "        params_before_step = current_params\n",
    "\n",
    "        # --- Special handling for Importance methods requiring gradients ---\n",
    "        if isinstance(strategy['importance'], (tp.importance.TaylorImportance, tp.importance.GroupHessianImportance)):\n",
    "             model.train() # Need gradients\n",
    "             # Ensure requires_grad is True if it was turned off\n",
    "             for param in model.parameters():\n",
    "                 param.requires_grad_(True)\n",
    "\n",
    "             loss = model(example_input).mean() # Use mean or sum as dummy loss\n",
    "             try:\n",
    "                 loss.backward() # Calculate gradients needed for importance\n",
    "             except Exception as e:\n",
    "                 print(f\"Error during backward pass for importance calc (Iter {iteration}): {e}\")\n",
    "                 # Decide how to handle: break, skip step, etc.\n",
    "                 break # Safer to stop if backward fails\n",
    "\n",
    "        # --- Perform one step of interactive pruning ---\n",
    "        try:\n",
    "            # Get the next set of pruning candidates based on current importance\n",
    "            pruning_groups = list(pruner.step(interactive=True))\n",
    "        except Exception as e:\n",
    "             print(f\"Error during pruner.step() (Iter {iteration}): {e}\")\n",
    "             # Handle potential errors during dependency analysis or importance scoring\n",
    "             break # Stop if pruner step fails\n",
    "\n",
    "        if not pruning_groups:\n",
    "            print(f\"Iteration {iteration}: Pruner found no more candidates. Stopping.\")\n",
    "            break # No more structures can be pruned according to the strategy/dependencies\n",
    "\n",
    "        # --- Apply the pruning ---\n",
    "        for group in pruning_groups:\n",
    "            group.prune()\n",
    "\n",
    "        # --- Clean up gradients if calculated ---\n",
    "        if isinstance(strategy['importance'], (tp.importance.TaylorImportance, tp.importance.GroupHessianImportance)):\n",
    "            # Zero gradients to prevent interference with potential future training/fine-tuning\n",
    "            model.zero_grad()\n",
    "            model.eval() # Switch back to eval mode after grad calculation\n",
    "\n",
    "        # --- Recalculate metrics ---\n",
    "        # It's crucial to recalculate AFTER pruning is applied\n",
    "        current_macs, current_params = calculate_macs(model, example_input)\n",
    "\n",
    "        # --- Log progress ---\n",
    "        print(\n",
    "            f\"Iter {iteration: >3}/{max_iterations} | \"\n",
    "            f\"MACs: {macs_before_step:,.0f} -> {current_macs:,.0f} \"\n",
    "            f\"({(macs_before_step-current_macs)/macs_before_step*100:+.1f}%) | \"\n",
    "            f\"Params: {params_before_step:,.0f} -> {current_params:,.0f} \"\n",
    "            f\"({(params_before_step-current_params)/params_before_step*100:+.1f}%)\"\n",
    "        )\n",
    "\n",
    "        # --- Check for Stagnation (optional but recommended) ---\n",
    "        if current_macs >= macs_before_step and current_params >= params_before_step:\n",
    "            print(f\"Iteration {iteration}: No reduction in MACs or Params this step. Stopping to prevent loop.\")\n",
    "            # This might happen if the only prunable groups left have negligible impact\n",
    "            # or if there's an issue with the importance/pruning logic.\n",
    "            break\n",
    "\n",
    "    # --- Final Status Report ---\n",
    "    print(f\"--- Finished Pruning (Strategy: {strategy['importance'].__class__.__name__}) ---\")\n",
    "    if iteration >= max_iterations:\n",
    "        print(f\"Warning: Reached maximum pruning iterations ({max_iterations}).\")\n",
    "\n",
    "    final_macs, final_params = calculate_macs(model, example_input)\n",
    "    print(f\"Initial | MACs: {initial_macs:,.0f}, Params: {initial_params:,.0f}\")\n",
    "    print(f\"Final   | MACs: {final_macs:,.0f}, Params: {final_params:,.0f}\")\n",
    "    print(f\"Target  | MACs: {target_macs:,.0f}, Params: {target_params:,.0f}\")\n",
    "\n",
    "    macs_reduction = (initial_macs - final_macs) / initial_macs * 100 if initial_macs > 0 else 0\n",
    "    params_reduction = (initial_params - final_params) / initial_params * 100 if initial_params > 0 else 0\n",
    "    print(f\"Reduction | MACs: {macs_reduction:.2f}%, Params: {params_reduction:.2f}%\")\n",
    "\n",
    "    if final_macs > target_macs or final_params > target_params:\n",
    "         print(\"Warning: Pruning finished, but target threshold(s) were not fully met.\")\n",
    "\n",
    "    model.eval() # Ensure model is in eval mode finally\n",
    "    return model"
   ],
   "id": "572d5d540d81ce45",
   "outputs": [],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
