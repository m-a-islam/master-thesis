{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "377de838",
   "metadata": {},
   "source": [
    "## import necessary libraries for pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b6381473b81b890",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T21:32:23.116240Z",
     "start_time": "2025-04-07T21:32:20.692996Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_pruning as tp\n",
    "from torch import optim\n",
    "from cnn.resNet.resnet_example import get_data_loaders\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631981174f5d8d8a",
   "metadata": {},
   "source": [
    "### Seed Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "248e7c99c6815764",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T21:50:53.260972Z",
     "start_time": "2025-04-07T21:50:53.253748Z"
    }
   },
   "outputs": [],
   "source": [
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, expansion=6):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.use_res_connect = self.stride == 1 and in_channels == out_channels\n",
    "\n",
    "        # Standard PyTorch layers (NO torch_pruning wrappers needed)\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels * expansion, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels * expansion)\n",
    "        self.relu = nn.ReLU6(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels * expansion, in_channels * expansion, kernel_size=3,\n",
    "            stride=stride, padding=1, groups=in_channels * expansion, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels * expansion)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels * expansion, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x if self.use_res_connect else None\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.use_res_connect:\n",
    "            return identity + out\n",
    "        else:\n",
    "            return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6431a8ad17e1d446",
   "metadata": {},
   "source": [
    "### Mask Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4da304cf4cf9f871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T21:50:56.329573Z",
     "start_time": "2025-04-07T21:50:56.321210Z"
    }
   },
   "outputs": [],
   "source": [
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        # --- Remove mask-related parameters ---\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU6(inplace=True)\n",
    "\n",
    "        # Define blocks (no mask_index or mask)\n",
    "        self.block1 = InvertedResidual(32, 16, stride=1)\n",
    "        self.block2 = InvertedResidual(16, 24, stride=2)\n",
    "        self.block3 = InvertedResidual(24, 32, stride=2)\n",
    "        self.block4 = InvertedResidual(32, 64, stride=2)\n",
    "        self.block5 = InvertedResidual(64, 96, stride=1)\n",
    "        self.block6 = InvertedResidual(96, 160, stride=2)\n",
    "        self.block7 = InvertedResidual(160, 320, stride=1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(1280)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(1280, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # --- Remove mask-based block skipping ---\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "        x = self.block7(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ad82bf3520f8612",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T21:33:03.119819Z",
     "start_time": "2025-04-07T21:33:03.075645Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ebb1e087d2f0cd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T21:51:03.166843Z",
     "start_time": "2025-04-07T21:51:03.162957Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model_as_onnx(model, example_input, output_path):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    # Export to ONNX\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        example_input,\n",
    "        output_path,\n",
    "        export_params=True,\n",
    "        opset_version=13,\n",
    "        input_names=['input'],\n",
    "        output_names=['output'],\n",
    "        dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    "    )\n",
    "    print(f\"âœ… Model saved as ONNX to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e9a817a37b770da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T21:52:52.003566Z",
     "start_time": "2025-04-07T21:52:52.000175Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_macs(model, example_input):\n",
    "    macs, params = tp.utils.count_ops_and_params(model, example_input)\n",
    "    return macs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b29391c83349f69",
   "metadata": {},
   "source": [
    "### compare results of different pruning strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "becad7e59744f0dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T21:34:48.621390Z",
     "start_time": "2025-04-07T21:34:48.616977Z"
    }
   },
   "outputs": [],
   "source": [
    "def compare_results(results):\n",
    "    print(\"\\n=== Pruning Strategy Comparison ===\")\n",
    "    print(f\"{'Strategy':<12} | {'MACs':<12} | {'Size (MB)':<10} | {'Accuracy (%)':<12}\")\n",
    "    print(\"-\" * 55)\n",
    "    for strategy, metrics in results.items():\n",
    "        print(f\"{strategy:<12} | {metrics['macs']:.2e} | {metrics['size_mb']:>9.2f} | {metrics['accuracy']:>12.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23869493d2f36a72",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "615130e04992f7ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T21:34:51.749630Z",
     "start_time": "2025-04-07T21:34:51.744596Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd2e296738ea559",
   "metadata": {},
   "source": [
    "### Utility function to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7f8aa766a2fa06a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T21:35:50.646253Z",
     "start_time": "2025-04-07T21:35:50.642471Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_model(model, path, example_input=None):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    torch.save(model.state_dict(), path)\n",
    "    if example_input is not None:\n",
    "        onnx_path = path.replace('.pth', '.onnx')\n",
    "        save_model_as_onnx(model, example_input, onnx_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89740bc4e512ecde",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5484dc87c1b63c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, example_input, device):\n",
    "    model.eval()\n",
    "    # Calculate metrics\n",
    "    macs = calculate_macs(model, example_input)\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    size_mb = params * 4 / 1e6\n",
    "\n",
    "    # Calculate accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = [d.to(device) for d in data]\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return {\n",
    "        'macs': macs,\n",
    "        'size_mb': size_mb,\n",
    "        'accuracy': 100 * correct / total\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f7147c66b6d346",
   "metadata": {},
   "source": [
    "### Prune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6532a7494fc3fcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model(model, example_input, target_macs, strategy):\n",
    "    pruner = strategy['pruner'](\n",
    "        model,\n",
    "        example_input,\n",
    "        importance=strategy['importance'],\n",
    "        ch_sparsity=0.5,  # Initial sparsity\n",
    "        root_module_types=[nn.Conv2d],\n",
    "        ignored_layers=[model.fc],\n",
    "    )\n",
    "\n",
    "    current_macs = calculate_macs(model, example_input)\n",
    "    while current_macs > target_macs:\n",
    "        pruner.step()\n",
    "        current_macs = calculate_macs(model, example_input)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adb22651c74e5f0",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6e1edc8a36e5260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, device, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in train_loader:\n",
    "            inputs, labels = [d.to(device) for d in data]\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}: Loss={epoch_loss:.4f}, Accuracy={epoch_acc:.2f}%\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26416e6ff76416a",
   "metadata": {},
   "source": [
    "### Main workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdf93b3196076098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'strategies': {\n",
    "            'magnitude': {\n",
    "                'pruner': tp.pruner.MagnitudePruner,\n",
    "                'importance': tp.importance.MagnitudeImportance(p=2),\n",
    "            },\n",
    "            'bn_scale': {\n",
    "                'pruner': tp.pruner.BNScalePruner,\n",
    "                'importance': tp.importance.BNScaleImportance(),\n",
    "            },\n",
    "            'group_norm': {\n",
    "                'pruner': tp.pruner.GroupNormPruner,\n",
    "                'importance': tp.pruner.MagnitudePruner,\n",
    "            },\n",
    "            'random': {\n",
    "                'pruner': tp.pruner.MagnitudePruner,\n",
    "                'importance': tp.importance.RandomImportance(),\n",
    "            },\n",
    "            'Taylor': {\n",
    "                'pruner': tp.pruner.MagnitudePruner,\n",
    "                'importance': tp.importance.TaylorImportance\n",
    "            }\n",
    "        },\n",
    "        'target_macs_sparsity': 0.5,  # 50% MACs reduction\n",
    "        'train_epochs': 10,\n",
    "        'fine_tune_epochs': 10,\n",
    "        'data_dir': './data',\n",
    "        'output_dir': './output/strategies'\n",
    "    }\n",
    "\n",
    "    # Initialize model and data\n",
    "    model = MobileNetV2(num_classes=10).to(device)\n",
    "    train_loader, test_loader = get_data_loaders(config['data_dir'])\n",
    "    example_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "\n",
    "    # Workflow execution\n",
    "    initial_model_path = os.path.join(config['output_dir'], \"mobilenetv2_initial.pth\")\n",
    "\n",
    "    if not os.path.exists(initial_model_path):\n",
    "        # 1. Initial training\n",
    "        model = train_model(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            criterion=nn.CrossEntropyLoss().to(device),\n",
    "            optimizer=optim.Adam(model.parameters(), lr=0.001),\n",
    "            device=device,\n",
    "            num_epochs=config['train_epochs']\n",
    "        )\n",
    "        save_model(model, initial_model_path, example_input)\n",
    "\n",
    "    # 2. Pruning and evaluation workflow\n",
    "    results = {}\n",
    "    initial_macs = calculate_macs(model, example_input)\n",
    "    target_macs = initial_macs * config['target_macs_sparsity']\n",
    "\n",
    "    for strategy_name in config['strategies']:\n",
    "        # 2a. Prepare fresh model for each strategy\n",
    "        model_copy = load_model(MobileNetV2(num_classes=10).to(device), initial_model_path)\n",
    "\n",
    "        # 2b. Perform pruning\n",
    "        pruned_model = prune_model(\n",
    "            model=model_copy,\n",
    "            example_input=example_input,\n",
    "            target_macs=target_macs,\n",
    "            strategy=config['strategies'][strategy_name]\n",
    "        )\n",
    "\n",
    "        # 2c. Save pruned model\n",
    "        pruned_path = os.path.join(config['output_dir'], f\"mobilenetv2_{strategy_name}_pruned.pth\")\n",
    "        save_model(pruned_model, pruned_path, example_input)\n",
    "\n",
    "        # 2d. Fine-tune\n",
    "        fine_tuned_model = train_model(\n",
    "            model=pruned_model,\n",
    "            train_loader=train_loader,\n",
    "            criterion=nn.CrossEntropyLoss().to(device),\n",
    "            optimizer=optim.Adam(pruned_model.parameters(), lr=0.001),\n",
    "            device=device,\n",
    "            num_epochs=config['fine_tune_epochs']\n",
    "        )\n",
    "\n",
    "        # 2e. Evaluate\n",
    "        results[strategy_name] = evaluate_model(\n",
    "            model=fine_tuned_model,\n",
    "            test_loader=test_loader,\n",
    "            example_input=example_input,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # 2f. Save final model\n",
    "        final_path = os.path.join(config['output_dir'], f\"mobilenetv2_{strategy_name}_final.pth\")\n",
    "        save_model(fine_tuned_model, final_path, example_input)\n",
    "\n",
    "    # 3. Compare results\n",
    "    compare_results(results)\n",
    "    print(\"Workflow completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d51f760-3726-4028-98a7-02e0105ebd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset directory: /home/muis/thesis/github-repo/master-thesis/cnn/mobile_net_v2/data\n",
      "Epoch 1/10: Loss=1.6741, Accuracy=38.71%\n",
      "Epoch 2/10: Loss=1.3152, Accuracy=52.66%\n",
      "Epoch 3/10: Loss=1.1487, Accuracy=59.19%\n",
      "Epoch 4/10: Loss=1.0226, Accuracy=64.05%\n",
      "Epoch 5/10: Loss=0.9199, Accuracy=67.70%\n",
      "Epoch 6/10: Loss=0.8450, Accuracy=70.55%\n",
      "Epoch 7/10: Loss=0.7806, Accuracy=72.95%\n",
      "Epoch 8/10: Loss=0.7230, Accuracy=74.84%\n",
      "Epoch 9/10: Loss=0.6744, Accuracy=76.38%\n",
      "Epoch 10/10: Loss=0.6311, Accuracy=77.80%\n",
      "âœ… Model saved as ONNX to ./output/strategies/mobilenetv2_initial.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muis/.virtualenvs/master-thesis/lib/python3.12/site-packages/torch_pruning/pruner/algorithms/base_pruner.py:87: UserWarning: ch_sparsity is deprecated in v1.3.0. Please use pruning_ratio.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved as ONNX to ./output/strategies/mobilenetv2_magnitude_pruned.onnx\n",
      "Epoch 1/10: Loss=1.1878, Accuracy=58.87%\n",
      "Epoch 2/10: Loss=0.9177, Accuracy=67.76%\n",
      "Epoch 3/10: Loss=0.8290, Accuracy=70.86%\n",
      "Epoch 4/10: Loss=0.7796, Accuracy=72.63%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad46ea6-97a2-4d9a-9465-f8076bb0ef3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
